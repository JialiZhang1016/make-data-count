{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add\n",
    "- post_validate.py : remove fp\n",
    "- predict.py : use llb to predict primary or secondary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "eae4b221-a822-451f-8f4b-134c3f9bfe2c",
    "_uuid": "b1883565-f717-4130-a662-5bb541f45ea1",
    "execution": {
     "iopub.execute_input": "2025-09-08T08:36:05.357284Z",
     "iopub.status.busy": "2025-09-08T08:36:05.356949Z",
     "iopub.status.idle": "2025-09-08T08:36:06.113244Z",
     "shell.execute_reply": "2025-09-08T08:36:06.111199Z",
     "shell.execute_reply.started": "2025-09-08T08:36:05.357249Z"
    },
    "papermill": {
     "duration": 20.083729,
     "end_time": "2025-07-30T12:43:50.835737",
     "exception": false,
     "start_time": "2025-07-30T12:43:30.752008",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n",
      "\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m Skipping \u001b[1mtensorflow\u001b[0m as it is not installed\n",
      "\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m No packages to uninstall\n",
      "\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m5 packages\u001b[0m \u001b[2min 193ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! uv pip uninstall --system 'tensorflow'\n",
    "! uv pip install --system --no-index --find-links='/kaggle/input/latest-mdc-whls/whls' 'pymupdf' 'vllm' 'triton' 'logits-processor-zoo' 'numpy<2'\n",
    "! mkdir -p /tmp/src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "34135540-31fa-4d24-8934-acb1e0711a4f",
    "_uuid": "92f33014-02d3-41cb-b906-ffeb89a3f353",
    "execution": {
     "iopub.execute_input": "2025-09-08T08:36:06.116580Z",
     "iopub.status.busy": "2025-09-08T08:36:06.116183Z",
     "iopub.status.idle": "2025-09-08T08:36:06.127549Z",
     "shell.execute_reply": "2025-09-08T08:36:06.125839Z",
     "shell.execute_reply.started": "2025-09-08T08:36:06.116533Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.018527,
     "end_time": "2025-07-30T12:43:50.864121",
     "exception": false,
     "start_time": "2025-07-30T12:43:50.845594",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/src/helpers.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /tmp/src/helpers.py\n",
    "import logging, os, kagglehub, inspect\n",
    "from pathlib import Path\n",
    "import polars as pl\n",
    "\n",
    "IS_KAGGLE_ENV = sum(['KAGGLE' in k for k in os.environ]) > 0\n",
    "IS_KAGGLE_SUBMISSION = bool(os.getenv(\"KAGGLE_IS_COMPETITION_RERUN\"))\n",
    "COMP_DIR = Path(('/kaggle/input/make-data-count-finding-data-references' if IS_KAGGLE_SUBMISSION else kagglehub.competition_download('make-data-count-finding-data-references')))\n",
    "PDF_DIR = COMP_DIR / ('test' if IS_KAGGLE_SUBMISSION else 'train') / 'PDF'\n",
    "XML_DIR = COMP_DIR / ('test' if IS_KAGGLE_SUBMISSION else 'train') / 'XML'\n",
    "WORKING_DIR = Path(('/kaggle/working/' if IS_KAGGLE_ENV else '.working/'))\n",
    "\n",
    "\n",
    "\n",
    "DOI_LINK = 'https://doi.org/'\n",
    "\n",
    "DEFAULT_LOG_LEVEL = os.getenv(\"LOG_LEVEL\", \"DEBUG\").upper() if not IS_KAGGLE_SUBMISSION else \"WARNING\"\n",
    "LOG_FILE_PATH = os.getenv(\"LOG_FILE\", \"logs/project.log\")\n",
    "LOG_DIR = Path(LOG_FILE_PATH).parent\n",
    "\n",
    "LOG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "LOG_FORMAT = \"%(levelname)s %(asctime)s  [%(filename)s:%(lineno)d - %(funcName)s()] %(message)s\"\n",
    "LOG_DATEFMT = \"%Y-%m-%d %H:%M:%S\"\n",
    "\n",
    "def get_logger(name=None):\n",
    "    if name is None:\n",
    "        frame = inspect.currentframe()\n",
    "        if frame is None or frame.f_back is None:\n",
    "            name = \"__main__\"\n",
    "        else:\n",
    "            name = frame.f_back.f_globals.get(\"__name__\", \"__main__\")\n",
    "\n",
    "    logger = logging.getLogger(name)\n",
    "\n",
    "    if not logger.handlers:\n",
    "        logger.setLevel(DEFAULT_LOG_LEVEL)\n",
    "        formatter = logging.Formatter(fmt=LOG_FORMAT, datefmt=LOG_DATEFMT)\n",
    "        ch = logging.StreamHandler()\n",
    "        ch.setLevel(DEFAULT_LOG_LEVEL)\n",
    "        ch.setFormatter(formatter)\n",
    "        fh = logging.FileHandler(LOG_FILE_PATH)\n",
    "        fh.setLevel(DEFAULT_LOG_LEVEL)\n",
    "        fh.setFormatter(formatter)\n",
    "        logger.addHandler(ch)\n",
    "        logger.addHandler(fh)\n",
    "        logger.propagate = False\n",
    "    return logger\n",
    "\n",
    "def is_doi_link(name: str) -> pl.Expr:\n",
    "    return pl.col(name).str.starts_with(DOI_LINK).and_(\n",
    "        ~pl.col(name).str.contains(r\"/dl\\.\")\n",
    "    )\n",
    "\n",
    "def string_normalization(name: str) -> pl.Expr:\n",
    "    return pl.col(name).str.normalize(\"NFKC\").str.replace_all(r\"[^\\p{Ascii}]\", '').str.replace_all(r\"https?://zenodo\\.org/record/(\\d+)\", r\" 10.5281/zenodo.$1 \")\n",
    "\n",
    "def get_df(parse_dir: str):\n",
    "    records = []\n",
    "    txt_files = list(Path(parse_dir).glob('*.txt'))\n",
    "    for txt_file in txt_files:\n",
    "        id_ = txt_file.stem\n",
    "        with open(txt_file, 'r') as f:\n",
    "            text = f.read()\n",
    "        records.append({'article_id': id_, 'text': text})\n",
    "    return pl.DataFrame(records).with_columns(string_normalization('text').alias('text'))\n",
    "\n",
    "def assume_type(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    return (\n",
    "        df.with_columns(pl.when(is_doi_link('dataset_id').or_(pl.col('dataset_id').str.starts_with('SAMN'))).then(pl.lit('Primary')).otherwise(pl.lit('Secondary')).alias('type'))\n",
    "    )\n",
    "\n",
    "def score(df, gt, on, tag='all'):\n",
    "    hits = gt.join(df, on=on)\n",
    "    tp = hits.height\n",
    "    fp = df.height - tp\n",
    "    fn = gt.height - tp\n",
    "    f1 = 2 * tp / (2 * tp + fp + fn) if (2 * tp + fp + fn) != 0 else 0.0\n",
    "    return f\"{tag} - f1: {f1:.4f} [{tp}/{fp}/{fn}]\"\n",
    "\n",
    "def evaluate(df, on=['article_id', 'dataset_id']):\n",
    "    gt = pl.read_csv(COMP_DIR/'train_labels.csv').filter(pl.col('type')!='Missing')\n",
    "    return (\n",
    "        score(df, gt, on),\n",
    "        score(df.filter(is_doi_link('dataset_id')), gt.filter(is_doi_link('dataset_id')), on, 'doi'),\n",
    "        score(df.filter(~is_doi_link('dataset_id')), gt.filter(~is_doi_link('dataset_id')), on, 'acc'),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "98be0899-3cad-423b-a3db-313209068df0",
    "_uuid": "84859532-6acd-4011-b783-d0d24257a19b",
    "execution": {
     "iopub.execute_input": "2025-09-08T08:36:06.129466Z",
     "iopub.status.busy": "2025-09-08T08:36:06.129051Z",
     "iopub.status.idle": "2025-09-08T08:36:06.153654Z",
     "shell.execute_reply": "2025-09-08T08:36:06.152185Z",
     "shell.execute_reply.started": "2025-09-08T08:36:06.129431Z"
    },
    "papermill": {
     "duration": 0.014728,
     "end_time": "2025-07-30T12:43:50.888086",
     "exception": false,
     "start_time": "2025-07-30T12:43:50.873358",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/src/parse.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /tmp/src/parse.py\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import pymupdf\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "from helpers import get_logger, PDF_DIR, XML_DIR\n",
    "\n",
    "l = get_logger()\n",
    "\n",
    "def pdf_to_txt(output_dir: Path):\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    pdf_files = list(PDF_DIR.glob(\"*.pdf\")) + list(PDF_DIR.glob(\"*.PDF\"))\n",
    "    existing_txt_files = {f.stem for f in output_dir.glob(\"*.txt\")}\n",
    "    pdf_count = len(pdf_files)\n",
    "    for pdf_file in pdf_files:\n",
    "        txt_file = output_dir / f\"{pdf_file.stem}.txt\"\n",
    "        if pdf_file.stem in existing_txt_files:\n",
    "            continue\n",
    "        try:\n",
    "            text = \"\"\n",
    "            with pymupdf.open(pdf_file) as doc:\n",
    "                for page in doc:\n",
    "                    text += page.get_text()\n",
    "            txt_file.write_text(text, encoding='utf-8')\n",
    "        except Exception:\n",
    "            pass\n",
    "    return pdf_count\n",
    "\n",
    "def detect_xml_style(root):\n",
    "    if '}' in root.tag and 'http://www.tei-c.org/ns/1.0' in root.tag:\n",
    "        return 'tei'\n",
    "    html_tags = {'html', 'body', 'div', 'p', 'span', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6'}\n",
    "    for elem in root.iter():\n",
    "        if elem.tag in html_tags:\n",
    "            return 'html'\n",
    "    return 'generic'\n",
    "\n",
    "def get_block_elements(style):\n",
    "    if style == 'tei':\n",
    "        return {\n",
    "            'p', 'head', 'title', 'abstract', 'div', 'item', 'list', 'table',\n",
    "            'row', 'cell', 'note', 'quote', 'lg', 'l', 'sp', 'speaker'\n",
    "        }\n",
    "    elif style == 'html':\n",
    "        return {\n",
    "            'p', 'div', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'ul', 'ol', 'li',\n",
    "            'table', 'tr', 'td', 'th', 'blockquote', 'pre', 'section', 'article',\n",
    "            'header', 'footer', 'nav', 'aside'\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            'paragraph', 'section', 'title', 'abstract', 'item', 'list', 'entry',\n",
    "            'cell', 'note', 'block'\n",
    "        }\n",
    "\n",
    "def extract_text_with_structure(element, style, block_elements, short_content_threshold=50):\n",
    "    text_parts = []\n",
    "    if element.text and element.text.strip():\n",
    "        cleaned_text = re.sub(r'\\s+', ' ', element.text.strip())\n",
    "        text_parts.append(cleaned_text)\n",
    "    for child in element:\n",
    "        child_text = extract_text_with_structure(child, style, block_elements, short_content_threshold)\n",
    "        if child_text:\n",
    "            text_parts.append(child_text)\n",
    "    if element.tail and element.tail.strip():\n",
    "        cleaned_tail = re.sub(r'\\s+', ' ', element.tail.strip())\n",
    "        text_parts.append(cleaned_tail)\n",
    "    if '}' in element.tag:\n",
    "        tag_name = element.tag.split('}', 1)[1]\n",
    "    else:\n",
    "        tag_name = element.tag\n",
    "    result_text = ' '.join(text_parts)\n",
    "    if tag_name in block_elements:\n",
    "        if len(result_text) < short_content_threshold:\n",
    "            return result_text + ' '\n",
    "        else:\n",
    "            return result_text + '\\n\\n'\n",
    "    else:\n",
    "        return result_text + ' '\n",
    "\n",
    "def convert_xml_to_txt(xml_file_path, txt_file_path):\n",
    "    try:\n",
    "        tree = ET.parse(xml_file_path)\n",
    "        root = tree.getroot()\n",
    "        style = detect_xml_style(root)\n",
    "        l.info(f\"Detected XML style: {style}\")\n",
    "        block_elements = get_block_elements(style)\n",
    "        short_content_threshold = 50\n",
    "        structured_text = extract_text_with_structure(root, style, block_elements, short_content_threshold)\n",
    "        with open(txt_file_path, 'w', encoding='utf-8') as txt_file:\n",
    "            txt_file.write(structured_text)\n",
    "        return True\n",
    "    except ET.ParseError as e:\n",
    "        l.error(f\"Error: Could not parse file {xml_file_path}. It may not be valid XML. Error: {e}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        l.error(f\"Unknown error processing file {xml_file_path}: {e}\")\n",
    "        return False\n",
    "\n",
    "def batch_convert_xml_folder(input_folder, output_folder):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    xml_files = glob.glob(os.path.join(input_folder, \"*.xml\"))\n",
    "    xml_count = len(xml_files)\n",
    "    overwrite_count = 0\n",
    "    for xml_file in xml_files:\n",
    "        original_filename = os.path.splitext(os.path.basename(xml_file))[0]\n",
    "        txt_file_path = os.path.join(output_folder, original_filename + \".txt\")\n",
    "        if os.path.exists(txt_file_path):\n",
    "            overwrite_count += 1\n",
    "        if convert_xml_to_txt(xml_file, txt_file_path):\n",
    "            l.info(f\"Converted: {original_filename}.xml -> {original_filename}.txt\")\n",
    "    return xml_count, overwrite_count\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    # In a notebook environment, you might need to handle args differently,\n",
    "    # but for a script file, this is fine.\n",
    "    # We can pass arguments via a list to parse_args() if not running from CLI.\n",
    "    # For now, keeping as is to match the file structure.\n",
    "    parser.add_argument('--pdf-dir', type=Path, default=PDF_DIR, help='Directory containing PDF files')\n",
    "    parser.add_argument('--xml-dir', type=Path, default=XML_DIR, help='Directory containing XML files')\n",
    "    parser.add_argument('--output-dir', type=Path, default=Path('/tmp/train_parse'), help='Directory to save text files')\n",
    "    \n",
    "    # When running in a notebook, you might call main with specific args\n",
    "    # so we prevent parse_args() from looking at sys.argv\n",
    "    args = parser.parse_args(args=[]) \n",
    "\n",
    "    # Process PDFs\n",
    "    pdf_count = pdf_to_txt(args.output_dir)\n",
    "    l.info(f\"Found and processed {pdf_count} PDF files.\")\n",
    "\n",
    "    # Process XMLs\n",
    "    xml_count, overwrite_count = batch_convert_xml_folder(args.xml_dir, str(args.output_dir))\n",
    "    l.info(f\"Found and processed {xml_count} XML files.\")\n",
    "    l.info(f\"Overwrote {overwrite_count} text files from XML conversions.\")\n",
    "\n",
    "    # Print summary to terminal\n",
    "    print(f\"Processed {pdf_count} PDF files.\")\n",
    "    print(f\"Processed {xml_count} XML files.\")\n",
    "    print(f\"Overwrote {overwrite_count} text files from XML conversions.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "01632e8b-2a68-4dec-9606-f91214a8c020",
    "_uuid": "5210e49f-e5ab-45c6-b673-f0bd08dc1877",
    "execution": {
     "iopub.execute_input": "2025-09-08T08:36:06.156197Z",
     "iopub.status.busy": "2025-09-08T08:36:06.155783Z",
     "iopub.status.idle": "2025-09-08T08:36:06.178727Z",
     "shell.execute_reply": "2025-09-08T08:36:06.177387Z",
     "shell.execute_reply.started": "2025-09-08T08:36:06.156165Z"
    },
    "papermill": {
     "duration": 0.016232,
     "end_time": "2025-07-30T12:43:50.913072",
     "exception": false,
     "start_time": "2025-07-30T12:43:50.89684",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/src/check_parse.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /tmp/src/check_parse.py\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "from helpers import *\n",
    "\n",
    "l=get_logger()\n",
    "\n",
    "def gt_dataset_id_normalization(name:str) -> pl.Expr:\n",
    "    return (\n",
    "        pl.when(is_doi_link(name))\n",
    "        .then(pl.col(name).str.split(DOI_LINK).list.last())\n",
    "        .otherwise(name)\n",
    "        .str.to_lowercase()\n",
    "    )\n",
    "\n",
    "def main():\n",
    "    if IS_KAGGLE_SUBMISSION:\n",
    "        l.debug('skipping check_parse for submission')\n",
    "        return\n",
    "    df = (\n",
    "        get_df('/tmp/train_parse')\n",
    "        .with_columns(pl.col('text').str.replace_all('\\s+', '').str.to_lowercase().alias('text'))\n",
    "    )\n",
    "\n",
    "    gt = (\n",
    "        pl.read_csv(COMP_DIR/'train_labels.csv')\n",
    "        .filter(pl.col('article_id').is_in(df['article_id']))\n",
    "        .filter(pl.col('type')!='Missing')\n",
    "        .with_columns(gt_dataset_id_normalization('dataset_id').alias('norm_id'))\n",
    "    )\n",
    "\n",
    "    l.info(f\"pymupdf misses: {gt.join(df, on='article_id').with_columns(hit=pl.col('text').str.contains(pl.col('norm_id'), literal=True)).filter(~pl.col('hit')).height} dataset_ids\")\n",
    "\n",
    "if __name__=='__main__': main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "83084a3e-ab3e-4c24-9045-7bc81df72e34",
    "_uuid": "5a79e391-1a5c-4264-9aa5-747cb657a266",
    "execution": {
     "iopub.execute_input": "2025-09-08T08:36:06.180537Z",
     "iopub.status.busy": "2025-09-08T08:36:06.180223Z",
     "iopub.status.idle": "2025-09-08T08:36:06.213314Z",
     "shell.execute_reply": "2025-09-08T08:36:06.211925Z",
     "shell.execute_reply.started": "2025-09-08T08:36:06.180510Z"
    },
    "papermill": {
     "duration": 0.019717,
     "end_time": "2025-07-30T12:43:50.939863",
     "exception": false,
     "start_time": "2025-07-30T12:43:50.920146",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/src/getid.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /tmp/src/getid.py\n",
    "import re\n",
    "import polars as pl\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "from helpers import *\n",
    "\n",
    "COMPILED_PATTERNS = {\n",
    "    # 'ref_header_patterns': [re.compile(r'\\b(R\\s*E\\s*F\\s*E\\s*R\\s*E\\s*N\\s*C\\s*E\\s*S|BIBLIOGRAPHY|LITERATURE CITED|WORKS CITED|CITED WORKS|ACKNOWLEDGEMENTS)\\b[:\\s]*', re.IGNORECASE)],    \n",
    "    'ref_header_patterns': [re.compile(r'\\b(R\\s*E\\s*F\\s*E\\s*R\\s*E\\s*N\\s*C\\s*E\\s*S|BIBLIOGRAPHY|LITERATURE CITED|WORKS CITED|CITED WORKS|ACKNOWLEDGEMENTS|REFERENCES AND NOTES)\\b[:\\s]*', re.IGNORECASE)],\n",
    "    'citation_pattern': re.compile(r'^\\s*(\\[\\d+\\]|\\(\\d+\\)|\\d+\\.|\\d+\\)|\\d+(?=\\s|$))\\s*'),\n",
    "    'first_citation_patterns': [\n",
    "        re.compile(r'^\\s*\\[1\\]\\s*'),\n",
    "        re.compile(r'^\\s*\\(1\\)\\s*'),\n",
    "        re.compile(r'^\\s*1\\.\\s*'),\n",
    "        re.compile(r'^\\s*1\\)\\s*'),\n",
    "        re.compile(r'^\\s*1(?=\\s|$)'),\n",
    "    ],\n",
    "}\n",
    "\n",
    "l = get_logger()\n",
    "\n",
    "def find_last_reference_header(text: str, header_patterns: list[re.Pattern]) -> Optional[int]:\n",
    "    last_match_idx = None\n",
    "    for pattern in header_patterns:\n",
    "        matches = list(pattern.finditer(text))\n",
    "        if matches:\n",
    "            last_match_idx = matches[-1].start()\n",
    "    return last_match_idx\n",
    "\n",
    "def find_last_first_citation(text: str) -> Optional[int]:\n",
    "    lines = text.splitlines()\n",
    "    last_match_line = None\n",
    "    for line_num, line in enumerate(lines):\n",
    "        line = line.strip()\n",
    "        for pattern in COMPILED_PATTERNS['first_citation_patterns']:\n",
    "            if pattern.match(line):\n",
    "                next_lines = lines[line_num:line_num+3]\n",
    "                if any(COMPILED_PATTERNS['citation_pattern'].match(l.strip()) for l in next_lines[1:]):\n",
    "                    last_match_line = line_num\n",
    "                break\n",
    "    return last_match_line\n",
    "\n",
    "def find_reference_start(text: str) -> Optional[int]:\n",
    "    lines = text.splitlines()\n",
    "    last_first_citation = find_last_first_citation(text)\n",
    "    if last_first_citation is not None:\n",
    "        return last_first_citation\n",
    "    start_search_idx = int(len(lines) * 0.5)\n",
    "    for i in range(start_search_idx, len(lines)):\n",
    "        line = lines[i].strip()\n",
    "        if COMPILED_PATTERNS['citation_pattern'].match(line):\n",
    "            next_lines = lines[i:i+3]\n",
    "            if sum(1 for l in next_lines if COMPILED_PATTERNS['citation_pattern'].match(l.strip())) >= 2:\n",
    "                for j in range(i, max(-1, i-10), -1):\n",
    "                    if not COMPILED_PATTERNS['citation_pattern'].match(lines[j].strip()):\n",
    "                        return j + 1\n",
    "                return max(0, i-10)\n",
    "    return None\n",
    "\n",
    "def split_text_and_references(text: str) -> Tuple[str, str]:\n",
    "    header_idx = find_last_reference_header(text, COMPILED_PATTERNS['ref_header_patterns'])\n",
    "    if header_idx is not None:\n",
    "        header_idx2 = find_last_reference_header(text[:header_idx].strip(), COMPILED_PATTERNS['ref_header_patterns'])\n",
    "        if header_idx2 is not None:\n",
    "            header_idx3 = find_last_reference_header(text[:header_idx2].strip(), COMPILED_PATTERNS['ref_header_patterns'])\n",
    "            if header_idx3 is not None:\n",
    "                return text[:header_idx3].strip(), text[header_idx3:].strip()\n",
    "            return text[:header_idx2].strip(), text[header_idx2:].strip()\n",
    "        return text[:header_idx].strip(), text[header_idx:].strip()\n",
    "    ref_start_line = find_reference_start(text)\n",
    "    if ref_start_line is not None:\n",
    "        lines = text.splitlines()\n",
    "        body = '\\n'.join(lines[:ref_start_line])\n",
    "        refs = '\\n'.join(lines[ref_start_line:])\n",
    "        return body.strip(), refs.strip()\n",
    "    return text.strip(), ''\n",
    "\n",
    "def get_splits(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    bodies, refs = [], []\n",
    "    for raw_text in df['text']:\n",
    "        main, ref = split_text_and_references(raw_text)\n",
    "        bodies.append(main)\n",
    "        refs.append(ref)\n",
    "    return df.with_columns(pl.Series('body', bodies), pl.Series('ref', refs))\n",
    "\n",
    "def tidy_extraction(df) -> pl.DataFrame:\n",
    "    bad_ids = [f'{DOI_LINK}{e}' for e in ['10.5061/dryad', '10.5281/zenodo', '10.6073/pasta']]\n",
    "    \n",
    "    # 学术论文DOI前缀黑名单 (从post_filter.py移植)\n",
    "    PAPER_PREFIXES = [\n",
    "        \"10.1038\",\"10.1007\",\"10.1126\",\"10.1016\",\"10.1101\",\"10.1021\",\"10.1145\",\"10.1177\",\n",
    "        \"10.1093\",\"10.1080\",\"10.1111\",\"10.1098\",\"10.1103\",\"10.1186\",\"10.1371\",\"10.7554\",\n",
    "        \"10.1039\",\"10.1002\",\"10.3390\",\"10.1073\",\"10.1097\",\"10.15252\",\"10.1136\",\"10.1091\",\n",
    "        \"10.1523\", \"10.1152\", \"10.1128\", \"10.1155\", \"10.1242\", \"10.1182\", \"10.1012\",\"10.1023\",\n",
    "        \"10.1001\",\"10.1006\",\"10.1017\",\"10.1029\",\"10.1034\",\"10.1037\",\"10.1042\",\"10.1044\",\"10.1046\",\n",
    "        \"10.1053\",\"10.1056\",\"10.1061\",\"10.1063\",\"10.5194\",\"10.1029\",\"10.5194\",\"10.1175\",\"10.2307\",\n",
    "        \"10.3389\",\"10.1590\",\"10.1130\",\"10.1088\",\"10.1146\",\"10.1890\",\"10.1017\",\"10.1086\",\"10.3133\",\n",
    "        \"10.1046\",\"10.1109\",\"10.1140\",\"10.3354\",\"10.1534\",\"10.1023\",\"10.6084\",\"10.1158\",\"10.1139\",\n",
    "        \"10.1006\",\"10.4319\",\"10.1785\",\"10.1099\",\"10.1143\",\"10.1089\",\"10.1104\",\"10.1074\",\"10.3897\",\n",
    "        \"10.1071\",\"10.1056\",\"10.1121\",\"10.3201\",\"10.3109\",\"10.18637\",\"10.1061\",\"10.1364\",\"10.1163\",\n",
    "        \"10.1144\",\"10.1159\",\"10.1063\",\"10.1161\",\"10.1113\",\"10.7717\",\"10.1515\",\"10.1001\",\"10.11646\",\n",
    "        \"10.1108\",\"10.1115\",\"10.6070\",\"10.1617\",\"10.1306\",\"10.1645\",\"10.14379\",\"10.1899\",\"10.4271\",\n",
    "        \"10.1210\",\"10.4161\",\"10.21105\",\"10.1183\",\"10.14411\",\"10.12688\",\"10.1148\",\"10.1105\",\"10.3892\",\n",
    "        \"10.18632\",\"10.3945\",\"10.1107\",\"10.1659\",\"10.1162\",\"10.1586\",\"10.3322\",\"10.1641\",\"10.2147\",\n",
    "        \"10.1603\",\"10.1067\",\"10.1201\",\"10.5441\",\"10.48550\",\"10.1200\",\"10.5860\",\"10.1078\",\"10.3168\",\n",
    "        \"10.2217\",\"10.1127\",\"10.2193\",\"10.1164\",\"10.5027\",\"10.17161\",\"10.2136\",\"10.1142\",\"10.7589\",\n",
    "        \"10.1292\",\"10.13155\",\"10.1053\",\"10.1554\",\"10.3920\",\"10.2337\",\"10.5065\",\"10.1037\",\"10.2134\",\n",
    "        \"10.1248\",\"10.1044\",\"10.17600\",\"10.5479\",\"10.5751\",\"10.2110\",\"10.3174\",\"10.1212\",\"10.17660\",\n",
    "        \"10.1530\",\"10.4067\",\"10.1172\",\"10.1094\",\"10.1674\",\"10.18194\",\"10.1042\",\"10.4103\",\"10.1190\",\n",
    "        \"10.2174\",\"10.1117\",\"10.3233\",\"10.1577\",\"10.2737\",\"10.4172\",\"10.2475\",\"10.3732\",\"10.15454\",\n",
    "        \"10.1643\",\"10.1214\",\"10.1642\",\"10.13039\",\"10.2135\",\"10.1084\",\"10.4049\",\"10.1124\",\"10.1261\",\n",
    "        \"10.5155\",\"10.1118\",\"10.1083\",\"10.3324\",\"10.7326\",\"10.1055\",\"10.1270\",\"10.1213\",\"10.3835\",\n",
    "        \"10.1385\",\"10.3171\",\"10.1373\",\"10.1637\",\"10.4269\",\"10.2478\",\"10.1096\",\"10.1137\",\"10.1378\",\n",
    "        \"10.4143\",\"10.26197\",\"10.1194\",\"10.7150\",\"10.13140\",\"10.1246\",\"10.2987\",\"10.2144\",\"10.4315\",\n",
    "        \"10.1593\",\"10.2202\",\"10.1196\",\"10.1110\",\"10.1134\",\"10.3748\",\"10.21273\",\"10.1503\",\"10.1517\",\"10.1215\"\n",
    "    ]\n",
    "    \n",
    "    # 创建学术论文DOI过滤函数\n",
    "    def is_paper_prefix_func(dataset_id: str) -> bool:\n",
    "        \"\"\"检查是否为学术论文DOI前缀\"\"\"\n",
    "        for prefix in PAPER_PREFIXES:\n",
    "            if dataset_id.startswith(f\"{DOI_LINK}{prefix}\"):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    doi_df = (\n",
    "        df.with_columns(pl.col('text').str.extract_all(r'10\\s*\\.\\s*\\d{4,9}\\s*/\\s*\\S+').alias('match'))\n",
    "        .explode('match')\n",
    "        .drop_nulls('match')\n",
    "        .with_columns(\n",
    "            pl.col('match').str.replace_all(r'\\s+', '')\n",
    "                           .str.replace(r'[^A-Za-z0-9]+$', '')\n",
    "                           .str.to_lowercase()\n",
    "                           .alias('dataset_id')\n",
    "        )\n",
    "        .group_by('article_id', 'dataset_id')\n",
    "        .agg('match')\n",
    "        .with_columns((DOI_LINK + pl.col('dataset_id')).alias('dataset_id'))\n",
    "        # 排除学术论文DOI前缀\n",
    "        .filter(~pl.col('dataset_id').map_elements(is_paper_prefix_func, return_dtype=pl.Boolean))\n",
    "    )\n",
    "\n",
    "    REGEX_IDS = (\n",
    "        r\"(?i)\\b(?:\"\n",
    "        r\"CHEMBL\\d+|\"\n",
    "        r\"E-GEOD-\\d+|E-PROT-\\d+|E-MTAB-\\d+|E-MEXP-\\d+|EMPIAR-\\d+|\"\n",
    "        r\"ENSBTAG\\d+|ENSOARG\\d+|\"\n",
    "        r\"EPI_ISL_\\d{5,}|EPI\\d{6,7}|\"\n",
    "        r\"HPA\\d+|CP\\d{6}|IPR\\d{6}|PF\\d{5}|BX\\d{6}|KX\\d{6}|K0\\d{4}|CAB\\d{6}|\"\n",
    "        r\"NC_\\d{6}\\.\\d{1}|NM_\\d{9}|\"\n",
    "        r\"PRJNA\\d+|PRJEB\\d+|PRJDB\\d+|PXD\\d+|SAMN\\d+|\"\n",
    "        r\"GSE\\d+|GSM\\d+|GPL\\d+|\"\n",
    "        r\"PDB\\s?[1-9][A-Z0-9]{3}|HMDB\\d+|\"\n",
    "        r\"dryad\\.[^\\s\\\"<>]+|pasta\\/[^\\s\\\"<>]+|\"\n",
    "        r\"(?:SR[PRX]|STH|ERR|DRR|DRX|DRP|ERP|ERX)\\d+|\"\n",
    "        r\"CVCL_[A-Z0-9]{4}|\"\n",
    "        r\"[1-5]\\.(?:10|20|30|40|50|60|70|80|90)\\.\\d{2,4}\\.\\d{2,4}\"\n",
    "        r\")\"\n",
    "    )\n",
    "\n",
    "    acc_df = (\n",
    "        df.with_columns(\n",
    "            pl.col('text').str.extract_all(REGEX_IDS).alias('match')\n",
    "        )\n",
    "        .explode('match')\n",
    "        .drop_nulls('match')\n",
    "        .with_columns(\n",
    "            pl.col('match').str.replace_all(r'\\s+', '')\n",
    "                           .str.replace(r'[^A-Za-z0-9]+$', '')\n",
    "                           .str.replace(r'(?i)^PDB', '')\n",
    "                           .alias('dataset_id')\n",
    "        )\n",
    "        .group_by('article_id', 'dataset_id')\n",
    "        .agg('match')\n",
    "        .with_columns(\n",
    "            pl.when(pl.col('dataset_id').str.starts_with('dryad.'))\n",
    "              .then(f'{DOI_LINK}10.5061/' + pl.col('dataset_id'))\n",
    "              .otherwise('dataset_id')\n",
    "              .alias('dataset_id')\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.when(pl.col('dataset_id').str.starts_with('pasta/'))\n",
    "              .then(f'{DOI_LINK}10.6073/' + pl.col('dataset_id'))\n",
    "              .otherwise('dataset_id')\n",
    "              .alias('dataset_id')\n",
    "        )\n",
    "    )\n",
    "\n",
    "    df = pl.concat([doi_df, acc_df])\n",
    "    \n",
    "    # ======== 智能过滤策略 ========\n",
    "    # 1. 基本过滤（保留所有可能的匹配）\n",
    "    df = df.unique(['article_id', 'dataset_id'])\n",
    "    \n",
    "    # 2. 添加置信度评分而不是直接过滤\n",
    "    def calculate_confidence(dataset_id):\n",
    "        \"\"\"为每个ID计算置信度分数\"\"\"\n",
    "        score = 0.5  # 基础分数\n",
    "        \n",
    "        # 高置信度模式\n",
    "        high_confidence_patterns = [\n",
    "            r'10\\.\\d{4,9}/',  # DOI格式\n",
    "            r'chebi\\.org',    # 已知仓库\n",
    "            r'ensembl\\.org',\n",
    "            r'GSE\\d+',\n",
    "            r'PRJNA\\d+',\n",
    "            r'CHEMBL\\d+',\n",
    "            r'PXD\\d+',\n",
    "        ]\n",
    "        \n",
    "        # 低置信度模式（可能误判）\n",
    "        low_confidence_patterns = [\n",
    "            r'^\\d+$',  # 纯数字\n",
    "            r'^\\d+\\.\\d+$',  # 简单小数\n",
    "            r'^[A-Z]{1,2}\\d{1,3}$',  # 短字母数字组合\n",
    "            r'^Figure\\s+\\d+',  # 图表引用\n",
    "            r'^Table\\s+\\d+',  # 表格引用\n",
    "        ]\n",
    "        \n",
    "        # 应用规则\n",
    "        for pattern in high_confidence_patterns:\n",
    "            if re.search(pattern, dataset_id, re.IGNORECASE):\n",
    "                score += 0.3\n",
    "        \n",
    "        for pattern in low_confidence_patterns:\n",
    "            if re.search(pattern, dataset_id, re.IGNORECASE):\n",
    "                score -= 0.4\n",
    "        \n",
    "        # 确保分数在0-1之间\n",
    "        return max(0.1, min(1.0, score))\n",
    "    \n",
    "    # 添加置信度列\n",
    "    confidence_scores = [calculate_confidence(id) for id in df['dataset_id'].to_list()]\n",
    "    df = df.with_columns(pl.Series('confidence', confidence_scores))\n",
    "    \n",
    "    # 3. 应用智能过滤（只过滤明显错误的匹配）\n",
    "    df = (\n",
    "        df\n",
    "        # 排除明显错误的匹配（置信度极低）\n",
    "        .filter(pl.col('confidence') > 0.2)\n",
    "        # 弱化自身引用过滤\n",
    "        .filter(\n",
    "            ~pl.col('dataset_id').str.replace(\"https?://\", \"\")\n",
    "            .str.contains(pl.col('article_id').str.replace('_','/'))\n",
    "        )\n",
    "        # 更精确的坏ID过滤\n",
    "        .filter(~pl.col('dataset_id').is_in(bad_ids))\n",
    "    )\n",
    "    \n",
    "    # 保留原有的match去重\n",
    "    df = df.with_columns(pl.col('match').list.unique())\n",
    "    # ======== 智能过滤结束 ========\n",
    "    return df\n",
    "\n",
    "def get_context_window(text: str, substring: str, window: int = 100) -> str:\n",
    "    idx = text.find(substring)\n",
    "    if idx == -1:\n",
    "        raise ValueError\n",
    "    start = max(idx - window, 0)\n",
    "    end = min(idx + len(substring) + window, len(text))\n",
    "    return text[start:end]\n",
    "\n",
    "def get_window_df(text_df, ids_df):\n",
    "    df = ids_df.join(text_df, on='article_id')\n",
    "    windows = []\n",
    "    for text, match_ids in df.select('text', 'match').rows():\n",
    "        windows.append(get_context_window(text, match_ids[0]))\n",
    "    return df.with_columns(pl.Series('window', windows)).select('article_id', 'dataset_id', 'window')\n",
    "\n",
    "def preprocess_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Preprocessing text for better ID extraction:\n",
    "    1. Replace punctuation (commas, parentheses) with spaces to help ID extraction\n",
    "    2. Join lines that were likely broken during text extraction\n",
    "    \"\"\"\n",
    "    # Step 1: Replace punctuation with spaces\n",
    "    cleaned_text = re.sub(r'[,()]', ' ', text)\n",
    "    \n",
    "    # Step 2: Join broken lines (original logic)\n",
    "    lines = cleaned_text.split('\\n')\n",
    "    processed_lines = []\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        line = lines[i]\n",
    "        # Heuristic: If a line ends with a common DOI prefix part or a hyphen,\n",
    "        # it might be a broken line.\n",
    "        if (line.strip().endswith('/') or line.strip().endswith('-')) and i + 1 < len(lines):\n",
    "            # Join with the next line\n",
    "            processed_lines.append(line.strip() + lines[i+1].strip())\n",
    "            i += 2 # Skip the next line as it has been merged\n",
    "        else:\n",
    "            processed_lines.append(line)\n",
    "            i += 1\n",
    "    return '\\n'.join(processed_lines)\n",
    "\n",
    "def main(input_dir: str, parquet_dir: str, output_dir: str) -> None:\n",
    "    text_df = get_df(input_dir)\n",
    "\n",
    "    # !!! ADD THIS PREPROCESSING STEP !!!\n",
    "    original_texts = text_df['text'].to_list()\n",
    "    preprocessed_texts = [preprocess_text(t) for t in original_texts]\n",
    "    text_df = text_df.with_columns(pl.Series(\"text\", preprocessed_texts))\n",
    "\n",
    "    df = get_splits(text_df)\n",
    "    df = tidy_extraction(df)\n",
    "    df = get_window_df(text_df, df)\n",
    "    df.write_parquet(parquet_dir)\n",
    "    df = assume_type(df)\n",
    "    df.select(['article_id', 'dataset_id', 'type']).with_row_index(name='row_id').write_csv(output_dir)\n",
    "    \n",
    "    if not IS_KAGGLE_SUBMISSION:\n",
    "        print(\"*\"*10)\n",
    "        results = evaluate(df)\n",
    "        for r in results: l.info(r)\n",
    "        print(\"*\"*10)\n",
    "        results = evaluate(df, on=['article_id', 'dataset_id', 'type'])\n",
    "        for r in results: l.info(r)\n",
    "\n",
    "if __name__=='__main__': \n",
    "    # In a Kaggle environment, you would typically get these paths from environment variables\n",
    "    # or predefined constants, but for this script structure, we keep the local-style setup.\n",
    "    # The actual execution in the notebook will likely call main() with different paths.\n",
    "    \n",
    "    # For local execution:\n",
    "    # input_dir = './temp/parse'\n",
    "    # parquet_dir = './temp/extracted.parquet'\n",
    "    # output_dir = './temp/submission.csv'\n",
    "    # main(input_dir, parquet_dir, output_dir)\n",
    "    \n",
    "    # For Kaggle notebook execution (mimicking the original main function's behavior):\n",
    "    main(\n",
    "        input_dir='/tmp/train_parse',\n",
    "        parquet_dir='/tmp/extracted.parquet',\n",
    "        output_dir='/kaggle/working/submission.csv'\n",
    "    )\n",
    "\n",
    "# def main():\n",
    "#     text_df = get_df('/tmp/train_parse')\n",
    "#     df = get_splits(text_df)\n",
    "#     df = tidy_extraction(df)\n",
    "        \n",
    "#     write_the_match(text_df,df)\n",
    "    \n",
    "#     df = get_window_df(text_df, df)\n",
    "#     df.write_parquet('/tmp/extracted.parquet')\n",
    "#     df = assume_type(df)\n",
    "#     df.select(['article_id', 'dataset_id', 'type']).with_row_index(name='row_id').write_csv('/kaggle/working/submission.csv')\n",
    "#     if not IS_KAGGLE_SUBMISSION:\n",
    "#         results = evaluate(df)\n",
    "#         for r in results: l.info(r)\n",
    "#         results = evaluate(df, on=['article_id', 'dataset_id', 'type'])\n",
    "#         for r in results: l.info(r)\n",
    "\n",
    "# if __name__=='__main__': main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "af30506a-e45e-4a3b-ba81-23dd154bde8d",
    "_uuid": "94fc4779-0b43-4058-ac64-f54a7ebd8a76",
    "execution": {
     "iopub.execute_input": "2025-09-08T08:36:06.214966Z",
     "iopub.status.busy": "2025-09-08T08:36:06.214590Z",
     "iopub.status.idle": "2025-09-08T08:36:06.240664Z",
     "shell.execute_reply": "2025-09-08T08:36:06.239281Z",
     "shell.execute_reply.started": "2025-09-08T08:36:06.214940Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.019658,
     "end_time": "2025-07-30T12:43:50.971551",
     "exception": false,
     "start_time": "2025-07-30T12:43:50.951893",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/src/llm_validate.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /tmp/src/llm_validate.py\n",
    "import polars as pl\n",
    "import os\n",
    "\n",
    "from helpers import *\n",
    "\n",
    "l = get_logger()\n",
    "\n",
    "SYS_PROMPT_CLASSIFY_DOI = \"\"\"\n",
    "1. Priority Rules (highest → lowest)\n",
    "1.1 Always classify as A (Data) if:\n",
    "DOI prefix matches a known data repository:\n",
    "\n",
    "Dryad: 10.5061\n",
    "\n",
    "Zenodo: 10.5281\n",
    "\n",
    "Dl: 10.15468\n",
    "\n",
    "ICPSR: 10.3886\n",
    "\n",
    "USGS data: 10.5066\n",
    "\n",
    "Mendeley Data: 10.17632\n",
    "\n",
    "Dataverse: 10.7910/DVN\n",
    "\n",
    "OpenNeuro: 10.18112/openneuro.\n",
    "\n",
    "PANGAEA: 10.1594/PANGAEA.\n",
    "\n",
    "\n",
    "2. Classify as B (Literature) if:\n",
    "DOI prefix belongs to a publisher (e.g., 10.1038, 10.1007, 10.1126, 10.1016, 10.1101, 10.1021, 10.1145, 10.1177, 10.1093, 10.1080, 10.1111, etc.).\n",
    "\n",
    "Context indicates a journal article, book, conference paper, preprint, protocol, or method paper, without any repository/data storage signal.\n",
    "\n",
    "Mentions only “supplementary material” or “supplementary information” without a repository.\n",
    "\n",
    "3. Ambiguous cases\n",
    "No repository prefix and no clear context → default to B.\n",
    "\n",
    "\n",
    "4. Output\n",
    "Only output:\n",
    "\n",
    "A → data repository / dataset\n",
    "\n",
    "B → literature / non-data resource\n",
    "\n",
    "Few-shot examples\n",
    "\n",
    "“Raw images are stored on Figshare (DOI 10.6084/m9.figshare.1234567).” → A\n",
    "\n",
    "“Sequence reads available under BioProject accession PRJNA765432.” → A\n",
    "\n",
    "“As described in Nature Methods (DOI 10.1038/s41592-020-0793-2).” → B\n",
    "\n",
    "“See Supplementary Data at Zenodo (10.5281/zenodo.987654).” → A\n",
    "\n",
    "“Method details published in J. Proteome Res. DOI: 10.1021/acs.jproteome.0c00845.” → B\n",
    "\n",
    "“Data uploaded to Dryad (10.5061/dryad.x1y2z3).” → A\n",
    "\n",
    "“Referenced paper: DOI 10.1101/2020.01.01.123456 (bioRxiv preprint).” → B\n",
    "\n",
    "“Metabolomics data in MetaboLights MTBLS1234.” → A\n",
    "\n",
    "“The MRI scans are deposited at OpenNeuro (DOI 10.18112/openneuro.ds000001.v1.0.0).” → A\n",
    "\n",
    "“Protein structure described in Science (DOI 10.1126/science.abc1234).” → B\n",
    "\"\"\".strip()\n",
    "\n",
    "def build_df():\n",
    "    df = pl.read_parquet('/tmp/extracted.parquet')\n",
    "    df.filter(~is_doi_link('dataset_id')).select('article_id', 'dataset_id').write_csv('/tmp/accid_sub.csv')\n",
    "    return df.filter(is_doi_link('dataset_id'))\n",
    "\n",
    "def build_prompt(tokenizer, df):\n",
    "    prompts = []\n",
    "    for doi, text in df.select('dataset_id', 'window').rows():\n",
    "        messages = [{'role':'system','content': SYS_PROMPT_CLASSIFY_DOI}, {'role':'user', 'content': text}]\n",
    "        prompts.append(tokenizer.apply_chat_template(messages, add_generation_prompt=True, tokenize=False))\n",
    "    return df.with_columns(pl.Series('prompt', prompts))\n",
    "\n",
    "if __name__=='__main__':\n",
    "    os.environ[\"VLLM_USE_V1\"] = \"0\"\n",
    "    import vllm\n",
    "    from logits_processor_zoo.vllm import MultipleChoiceLogitsProcessor\n",
    "    model_path = \"/kaggle/input/qwen2.5/transformers/32b-instruct-awq/1\"\n",
    "    llm = vllm.LLM(model_path, quantization='awq', tensor_parallel_size=2, gpu_memory_utilization=0.9, trust_remote_code=True, dtype=\"half\", enforce_eager=True, max_model_len=2048, disable_log_stats=True, disable_custom_all_reduce=True, enable_prefix_caching=True, task='generate')\n",
    "    tokenizer = llm.get_tokenizer()\n",
    "    df = build_df()\n",
    "    df = build_prompt(tokenizer, df)\n",
    "    prompts = df['prompt'].to_list()\n",
    "    mclp = MultipleChoiceLogitsProcessor(tokenizer, choices=[\"A\", \"B\"])\n",
    "    outputs = llm.generate(prompts, vllm.SamplingParams(seed=777, temperature=0.2, skip_special_tokens=True, max_tokens=1, logits_processors=[mclp], logprobs=len(mclp.choices)), use_tqdm=True)\n",
    "    logprobs = [{lp.decoded_token: lp.logprob for lp in list(lps)} for lps in [output.outputs[0].logprobs[0].values() for output in outputs]]\n",
    "    choices = [max(d, key=d.get) for d in logprobs]\n",
    "    types = {'A': True, 'B': False}\n",
    "    choices = [types[c] for c in choices]\n",
    "    df = df.with_columns(pl.Series('type', choices))\n",
    "    df.filter(pl.col('type')).select('article_id', 'dataset_id').write_csv('/tmp/doi_sub.csv')\n",
    "    df = pl.concat([pl.read_csv('/tmp/doi_sub.csv'), pl.read_csv('/tmp/accid_sub.csv')])\n",
    "    df = assume_type(df)\n",
    "    df.select(['article_id', 'dataset_id', 'type']).with_row_index(name='row_id').write_csv('/kaggle/working/submission.csv')\n",
    "    if not IS_KAGGLE_SUBMISSION:\n",
    "        results = evaluate(df)\n",
    "        for r in results: l.info(r) \n",
    "        results = evaluate(df, on=['article_id', 'dataset_id', 'type'])\n",
    "        for r in results: l.info(r)\n",
    "\n",
    "\n",
    "    \n",
    "    try:\n",
    "        del llm, tokenizer\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    import gc, torch\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-08T08:36:06.242849Z",
     "iopub.status.busy": "2025-09-08T08:36:06.242429Z",
     "iopub.status.idle": "2025-09-08T08:36:06.266298Z",
     "shell.execute_reply": "2025-09-08T08:36:06.264903Z",
     "shell.execute_reply.started": "2025-09-08T08:36:06.242811Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.018508,
     "end_time": "2025-07-30T12:43:51.002131",
     "exception": false,
     "start_time": "2025-07-30T12:43:50.983623",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/src/post_filter.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /tmp/src/post_filter.py\n",
    "import polars as pl\n",
    "from helpers import *\n",
    "\n",
    "\"\"\"\n",
    "Fourth essence: Post-filter to cut FP DOIs that look like literature.\n",
    "- Read /kaggle/working/submission.csv (output of llm_validate.py)\n",
    "- Join with /tmp/extracted.parquet to get context window\n",
    "- Drop DOI rows that (1) start with typical publisher prefixes AND (2) have no data-ish words nearby\n",
    "- Keep accessions untouched\n",
    "\"\"\"\n",
    "\n",
    "l = get_logger()\n",
    "\n",
    "PAPER_PREFIXES = [\n",
    "    \"10.5061\",\"10.5281\",\"10.17632\",\"10.1594\",\"10.15468\",\"10.17882\",\"10.7937\",\"10.7910\",\"10.6073\",\n",
    "    \"10.3886\",\"10.3334\",\"10.4121\",\"10.5066\",\"10.5067\",\"10.18150\",\"10.25377\",\"10.25387\",\"10.23642\",\"10.24381\",\"10.22033\"\n",
    "]\n",
    "\n",
    "CONTEXT_RE = r\"(?i)\\b(data(?:set)?|repository|archive|deposited|available|supplementary|raw(?:\\s+data)?|uploaded|hosted|stored|accession)\\b\"\n",
    "\n",
    "def is_paper_prefix(col: str = \"dataset_id\") -> pl.Expr:\n",
    "    expr = pl.lit(False)\n",
    "    for p in PAPER_PREFIXES:\n",
    "        expr = expr | pl.col(col).str.starts_with(f\"{DOI_LINK}{p}\")\n",
    "    return expr\n",
    "\n",
    "def main():\n",
    "    sub = pl.read_csv(\"/kaggle/working/submission.csv\")\n",
    "\n",
    "    # Normalize columns: drop row_id if present so concat widths match\n",
    "    if \"row_id\" in sub.columns:\n",
    "        sub = sub.drop(\"row_id\")\n",
    "\n",
    "    # Context windows\n",
    "    win = pl.read_parquet(\"/tmp/extracted.parquet\").select(\"article_id\", \"dataset_id\", \"window\")\n",
    "\n",
    "    # DOI & ACC split\n",
    "    doi_rows = sub.filter(is_doi_link(\"dataset_id\")).join(win, on=[\"article_id\", \"dataset_id\"], how=\"left\")\n",
    "    acc_rows = sub.filter(~is_doi_link(\"dataset_id\"))\n",
    "\n",
    "    keep_mask = (\n",
    "        (~is_paper_prefix(\"dataset_id\"))  # not a known paper prefix\n",
    "        | doi_rows[\"window\"].fill_null(\"\").str.contains(CONTEXT_RE)\n",
    "    )\n",
    "\n",
    "    kept_doi = doi_rows.filter(keep_mask).select(\"article_id\", \"dataset_id\", \"type\")\n",
    "    final = pl.concat([kept_doi, acc_rows.select(\"article_id\", \"dataset_id\", \"type\")])\n",
    "\n",
    "    # Re-eval & save\n",
    "    if not IS_KAGGLE_SUBMISSION:\n",
    "        for r in evaluate(final): l.info(r)\n",
    "        for r in evaluate(final, on=[\"article_id\", \"dataset_id\", \"type\"]): l.info(r)\n",
    "\n",
    "    final.with_row_index(\"row_id\").write_csv(\"/kaggle/working/submission.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-08T08:36:06.268270Z",
     "iopub.status.busy": "2025-09-08T08:36:06.267885Z",
     "iopub.status.idle": "2025-09-08T08:36:06.294407Z",
     "shell.execute_reply": "2025-09-08T08:36:06.293043Z",
     "shell.execute_reply.started": "2025-09-08T08:36:06.268241Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/src/post_validate.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /tmp/src/post_validate.py\n",
    "\n",
    "from helpers import *\n",
    "import polars as pl\n",
    "import os\n",
    "\n",
    "\n",
    "l = get_logger()\n",
    "\n",
    "\n",
    "PROMPT_CLASSIFY_CITATION_TYPE = '''\n",
    "# Role & Task\n",
    "You are an expert data citation analyst. Your task is to classify a given citation from a scientific paper into one of two categories: **A** (Data) or **B** (Not Data). Base your decision strictly on the provided abstract and the context of the citation.\n",
    "\n",
    "## Instructions\n",
    "1.  **Read the provided abstract** to understand the research context.\n",
    "2.  **Analyze the citation context** for key linguistic cues.\n",
    "3.  **Classify the citation** as either **A** or **B** based on the definitions below.\n",
    "4.  **Output only a single letter: A or B.** Do not output any other text, explanation, or formatting.\n",
    "\n",
    "## Category Definitions\n",
    "\n",
    "### **Category A: DATA**\n",
    "The citation points to a dataset. This includes:\n",
    "*   **Primary Data:** Raw or processed data that the current study's authors collected, generated, or created.\n",
    "*   **Secondary Data:** Data that was originally produced by other researchers but is being *used as a dataset* in the current study.\n",
    "*   **Key Phrases:** \"data are available at\", \"we collected\", \"we measured\", \"data were obtained from\", \"dataset\", \"downloaded from\", \"deposited in\", repository names (e.g., GenBank, Zenodo, Figshare, TCIA).\n",
    "\n",
    "### **Category B: NOT DATA**\n",
    "The citation points to a traditional scholarly publication or other non-data resource. This includes:\n",
    "*   Journal articles, books, conference proceedings, preprints, protocols, methods papers.\n",
    "*   **Key Phrases:** \"as described in\", \"according to\", \"previous study\", \"et al.\", \"paper\", \"article\", \"methodology\", \"was used for analysis\" (without indicating data access).\n",
    "*   Citations that provide background context or methodological description but do not serve as the source of the data used in the analysis.\n",
    "\n",
    "## Input Format\n",
    "You will be provided with the following three pieces of information:\n",
    "Paper Abstract: {abstract}\n",
    "Citation: {dataset_id}\n",
    "Citation Context: {context}\n",
    "\n",
    "## Critical Thinking Guidelines\n",
    "*   A DOI or URL can point to either data (A) or a paper (B). The context determines the classification.\n",
    "*   If the citation is used to describe the *source* of the data for the current study's analysis, it is likely **A**.\n",
    "*   If the citation is used to provide background, justify a method, or compare results, it is likely **B** (a reference to another paper).\n",
    "*   When in doubt, rely on the linguistic cues in the \"Citation Context\".\n",
    "\n",
    "## Examples for Pattern Recognition\n",
    "\n",
    "**Example 1 (Classify as A):**\n",
    "*   Context: \"Three out of four cohorts used in this study can be found on The Cancer Imaging Archive (TCIA)24: Canadian benchmark dataset23: https://doi.org/10.7937/K9/TCIA.2017.8oje5q00.\"\n",
    "*   **Reasoning:** The text states cohorts are \"used in this study\" and provides direct repository links. This is a clear case of citing external data for use.\n",
    "*   **Output:** A\n",
    "\n",
    "**Example 2 (Classify as B):**\n",
    "*   Context: \"data presented here are available at the SEANOE dataportal: https://doi.org/10.17882/94052 (ZooScan dataset Grandremy et al. 2023c)\"\n",
    "*   **Reasoning:** The phrase \"data presented here\" indicates this is the authors' own data being deposited, not a citation to an external source they are using. The \"(Author et al. Year)\" format is a classic literature citation style.\n",
    "*   **Output:** B\n",
    "\n",
    "**Example 3 (Classify as A):**\n",
    "*   Context: \"GBIF occurrence data: Vulpes vulpes: https://doi.org/10.15468/dl.wgtneb (28 May 2021).\"\n",
    "*   **Reasoning:** Explicitly names the data source (GBIF) and provides a direct access link/DOI for the specific dataset used.\n",
    "*   **Output:** A\n",
    "\n",
    "**Example 4 (Classify as B):**\n",
    "*   Context: \"North American soil NCBI SRA SRP035367 Smith & Peay [36] ITS2-Soil\"\n",
    "*   **Reasoning:** While it mentions a data repository ID (SRP035367), it couples it with a standard literature citation \"[36]\". The context suggests it is referencing the *paper* by Smith & Peay that describes the data, not directly citing the dataset itself for use.\n",
    "*   **Output:** B\n",
    "\n",
    "## Ready for Input\n",
    "Begin your analysis. Remember: Output only **A** or **B**.\n",
    "'''\n",
    "\n",
    "def get_context_window(text: str, substring: str, window: int = 600) -> str:\n",
    "    idx = text.find(substring)\n",
    "    if idx == -1:\n",
    "        return \"no context\", \"no abstraction\"\n",
    "    start = max(idx - window, 0)\n",
    "    end = min(idx + len(substring) + window, len(text))\n",
    "    return text[start:end] , text[:1000]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def find_context_win(tokenizer,df):\n",
    "    text_df = pl.read_parquet('/tmp/context_data.parquet')\n",
    "    # print(text_df)\n",
    "    df = df.join(text_df, on=[\"article_id\",\"dataset_id\"], how=\"inner\")\n",
    "    df = df.drop(\"type\")\n",
    "    print(df)\n",
    "\n",
    "    prompts = []\n",
    "    \n",
    "    for article_id,dataset_id,text,match in df.select([\"article_id\",\"dataset_id\",\"text\",'match']).rows():\n",
    "\n",
    "        context, abstract = get_context_window(text,match)\n",
    "        user_content = f\"\"\"\n",
    "        Paper Abstract: {abstract}\n",
    "        \n",
    "        Citation: {dataset_id}\n",
    "\n",
    "        \n",
    "        Citation Context: {context}\n",
    "        \"\"\"\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": PROMPT_CLASSIFY_CITATION_TYPE},\n",
    "            {\"role\": \"user\", \"content\": user_content.strip()}\n",
    "        ]\n",
    "        prompts.append(\n",
    "            tokenizer.apply_chat_template(messages, add_generation_prompt=True, tokenize=False)\n",
    "        )\n",
    "        \n",
    "    return df.with_columns(pl.Series(\"prompt\", prompts))\n",
    "\n",
    "    \n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    os.environ[\"VLLM_USE_V1\"] = \"0\"\n",
    "    MODEL_PATH = \"/kaggle/input/qwen2.5/transformers/32b-instruct-awq/1\"\n",
    "    import vllm\n",
    "    from logits_processor_zoo.vllm import MultipleChoiceLogitsProcessor\n",
    "\n",
    "    llm = vllm.LLM(\n",
    "        MODEL_PATH,\n",
    "        quantization='awq',\n",
    "        tensor_parallel_size=2,\n",
    "        gpu_memory_utilization=0.9,\n",
    "        trust_remote_code=True,\n",
    "        dtype=\"half\",\n",
    "        enforce_eager=True,\n",
    "        max_model_len=16384,\n",
    "        disable_log_stats=True, \n",
    "        disable_custom_all_reduce=True,\n",
    "        enable_prefix_caching=True,\n",
    "        task='generate')\n",
    "\n",
    "    tokenizer = llm.get_tokenizer()\n",
    "\n",
    "    df=pl.read_csv(\"/kaggle/working/submission.csv\")\n",
    "    \n",
    "    if \"row_id\" in df.columns:\n",
    "        df = df.drop(\"row_id\")\n",
    "\n",
    "    # print(df)\n",
    "\n",
    "    doi_df = df.filter(is_doi_link(\"dataset_id\"))\n",
    "    acc_df = df.filter(~is_doi_link(\"dataset_id\"))\n",
    "\n",
    "    # print(doi_df)\n",
    "\n",
    "    df = find_context_win(tokenizer,doi_df)\n",
    "\n",
    "    \n",
    "    \n",
    "    prompts = df['prompt'].to_list()\n",
    "    mclp = MultipleChoiceLogitsProcessor(tokenizer, choices=[\"A\", \"B\",\"C\"])\n",
    "    outputs = llm.generate(prompts, vllm.SamplingParams(seed=777, temperature=0.7, skip_special_tokens=True, max_tokens=1, logits_processors=[mclp], logprobs=len(mclp.choices)), use_tqdm=True)\n",
    "    logprobs = [{lp.decoded_token: lp.logprob for lp in list(lps)} for lps in [output.outputs[0].logprobs[0].values() for output in outputs]]\n",
    "    choices = [max(d, key=d.get) for d in logprobs]\n",
    "    types = {'A': True, 'B': False}\n",
    "    choices = [types[c] for c in choices]\n",
    "    df = df.with_columns(pl.Series('type', choices))\n",
    "    df.filter(pl.col('type')).select('article_id', 'dataset_id').write_csv('/tmp/doi_sub.csv')\n",
    "    df = pl.concat([pl.read_csv('/tmp/doi_sub.csv'), pl.read_csv('/tmp/accid_sub.csv')])\n",
    "    df = assume_type(df)\n",
    "    df.select(['article_id', 'dataset_id', 'type']).with_row_index(name='row_id').write_csv('/kaggle/working/submission.csv')\n",
    "    # print(df)\n",
    "    if not IS_KAGGLE_SUBMISSION:\n",
    "        results = evaluate(df)\n",
    "        for r in results: l.info(r) \n",
    "        results = evaluate(df, on=['article_id', 'dataset_id', 'type'])\n",
    "        for r in results: l.info(r)\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        del llm, tokenizer\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    import gc, torch\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-08T08:36:06.296759Z",
     "iopub.status.busy": "2025-09-08T08:36:06.296355Z",
     "iopub.status.idle": "2025-09-08T08:36:06.321939Z",
     "shell.execute_reply": "2025-09-08T08:36:06.319905Z",
     "shell.execute_reply.started": "2025-09-08T08:36:06.296733Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/src/predict.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /tmp/src/predict.py\n",
    "\n",
    "from helpers import *\n",
    "import polars as pl\n",
    "import os\n",
    "\n",
    "\n",
    "l = get_logger()\n",
    "\n",
    "\n",
    "PROMPT_CLASSIFY_CITATION_TYPE = '''\n",
    "# Role & Task\n",
    "You are an expert data citation analyst. Your task is to classify a given citation from a scientific paper into one of two categories based on the context: **A (Primary Data)** or **B (Secondary Data)**.\n",
    "\n",
    "## Instructions\n",
    "1.  **Read the provided abstract** to understand the research context.\n",
    "2.  **Analyze the citation context** for key linguistic cues.\n",
    "3.  **Classify the citation** as either **A** or **B** based on the definitions below.\n",
    "4.  **Output only a single letter: A or B.** Do not output any other text, explanation, or formatting.\n",
    "\n",
    "## Category Definitions\n",
    "\n",
    "### **Category A: PRIMARY DATA**\n",
    "The data was generated, collected, or created by the **authors of the current study**. This is *their* data.\n",
    "*   **Key Phrases:** \"we collected\", \"we generated\", \"our data\", \"data are available at [URL/DOI]\", \"data have been deposited\", \"this study presents\", \"supplementary data\".\n",
    "\n",
    "### **Category B: SECONDARY DATA**\n",
    "The data was produced by **other researchers** or external sources and is being reused or analyzed by the current study's authors.\n",
    "*   **Key Phrases:** \"data were obtained from\", \"publicly available data\", \"previously published data\", \"retrieved from\", \"downloaded from\", \"[Dataset Name] dataset\", \"database\", citing a specific external source.\n",
    "\n",
    "## Input Format\n",
    "You will be provided with the following three pieces of information:\n",
    "Paper Abstract: {abstract}\n",
    "Citation: {dataset_id}\n",
    "Citation Context: {context}\n",
    "\n",
    "\n",
    "## Decision Framework\n",
    "Answer these questions based on the **Citation Context**:\n",
    "\n",
    "1.  **Who is the source of the data?**\n",
    "    *   If the context implies the **authors themselves** are the source (e.g., \"we,\" \"our\"), classify as **A**.\n",
    "    *   If the context names an **external source** (e.g., a repository, another study, a database), classify as **B**.\n",
    "\n",
    "2.  **What is the action being described?**\n",
    "    *   **A (Primary)** actions: *depositing, making available, presenting* their own data.\n",
    "    *   **B (Secondary)** actions: *using, obtaining, accessing, downloading, analyzing* existing data from elsewhere.\n",
    "\n",
    "## Examples for Pattern Recognition\n",
    "\n",
    "**Example 1 (Classify as B):**\n",
    "*   Context: \"Three out of four cohorts **used in this study** can be found on The Cancer Imaging Archive (TCIA)24: Canadian benchmark dataset23: https://doi.org/10.7937/K9/TCIA.2017.8oje5q00.\"\n",
    "*   **Reasoning:** The authors are describing external datasets they **used** (a Secondary action). The source is TCIA, not themselves.\n",
    "*   **Output:** B\n",
    "\n",
    "**Example 2 (Classify as A):**\n",
    "*   Context: \"Additional research data **supporting this publication are available** at 10.25377/sussex.21184705.\"\n",
    "*   **Reasoning:** The authors are stating the availability of data that **supports their own publication**. The source is implied to be themselves.\n",
    "*   **Output:** A\n",
    "\n",
    "**Example 3 (Classify as B):**\n",
    "*   Context: \"GBIF occurrence data: Vulpes vulpes: https://doi.org/10.15468/dl.wgtneb (28 May 2021).\"\n",
    "*   **Reasoning:** The data is explicitly sourced from an external repository (GBIF). The authors are referring to data they reused.\n",
    "*   **Output:** B\n",
    "\n",
    "**Example 4 (Classify as A):**\n",
    "*   Context: \"Data referring to Barbieux et al. (2017; https://doi.org/10.17882/49388) are freely available on SEANOE.\"\n",
    "*   **Reasoning:** This is a tricky case. The citation format \"(Author et al. Year)\" suggests a literature reference. However, the phrase \"Data referring to\" and the direct data DOI indicate the authors are citing **their own previously published dataset** (from a 2017 paper) that is now available. This is their Primary data.\n",
    "*   **Output:** A\n",
    "\n",
    "## Ready for Input\n",
    "Begin your analysis. Remember: Output only **A** or **B**.\n",
    "\n",
    "'''\n",
    "\n",
    "def get_context_window(text: str, substring: str, window: int = 600) -> str:\n",
    "    idx = text.find(substring)\n",
    "    if idx == -1:\n",
    "        return \"no context\", \"no abstraction\"\n",
    "    start = max(idx - window, 0)\n",
    "    end = min(idx + len(substring) + window, len(text))\n",
    "    return text[start:end] , text[:1000]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def find_context_win(tokenizer,df):\n",
    "    text_df = pl.read_parquet('/tmp/context_data.parquet')\n",
    "    # print(text_df)\n",
    "    df = df.join(text_df, on=[\"article_id\",\"dataset_id\"], how=\"inner\")\n",
    "    df = df.drop(\"type\")\n",
    "    print(df)\n",
    "\n",
    "    prompts = []\n",
    "    \n",
    "    for article_id,dataset_id,text,match in df.select([\"article_id\",\"dataset_id\",\"text\",'match']).rows():\n",
    "\n",
    "        context, abstract = get_context_window(text,match)\n",
    "        user_content = f\"\"\"\n",
    "        Paper Abstract: {abstract}\n",
    "        \n",
    "        Citation: {dataset_id}\n",
    "\n",
    "        \n",
    "        Citation Context: {context}\n",
    "        \"\"\"\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": PROMPT_CLASSIFY_CITATION_TYPE},\n",
    "            {\"role\": \"user\", \"content\": user_content.strip()}\n",
    "        ]\n",
    "        prompts.append(\n",
    "            tokenizer.apply_chat_template(messages, add_generation_prompt=True, tokenize=False)\n",
    "        )\n",
    "        \n",
    "    return df.with_columns(pl.Series(\"prompt\", prompts))\n",
    "\n",
    "    \n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    os.environ[\"VLLM_USE_V1\"] = \"0\"\n",
    "    MODEL_PATH = \"/kaggle/input/qwen2.5/transformers/32b-instruct-awq/1\"\n",
    "    import vllm\n",
    "    from logits_processor_zoo.vllm import MultipleChoiceLogitsProcessor\n",
    "\n",
    "    llm = vllm.LLM(\n",
    "        MODEL_PATH,\n",
    "        quantization='awq',\n",
    "        tensor_parallel_size=2,\n",
    "        gpu_memory_utilization=0.9,\n",
    "        trust_remote_code=True,\n",
    "        dtype=\"half\",\n",
    "        enforce_eager=True,\n",
    "        max_model_len=16384,\n",
    "        disable_log_stats=True, \n",
    "        disable_custom_all_reduce=True,\n",
    "        enable_prefix_caching=True,\n",
    "        task='generate')\n",
    "\n",
    "    tokenizer = llm.get_tokenizer()\n",
    "\n",
    "    df=pl.read_csv(\"/kaggle/working/submission.csv\")\n",
    "    \n",
    "    if \"row_id\" in df.columns:\n",
    "        df = df.drop(\"row_id\")\n",
    "\n",
    "\n",
    "    doi_df = df.filter(is_doi_link(\"dataset_id\"))\n",
    "    acc_df = df.filter(~is_doi_link(\"dataset_id\"))\n",
    "\n",
    "\n",
    "\n",
    "    df = find_context_win(tokenizer,doi_df)\n",
    "\n",
    "    \n",
    "    \n",
    "    prompts = df['prompt'].to_list()\n",
    "    mclp = MultipleChoiceLogitsProcessor(tokenizer, choices=[\"A\", \"B\"])\n",
    "    outputs = llm.generate(prompts, vllm.SamplingParams(seed=777, temperature=0.8, skip_special_tokens=True, max_tokens=1, logits_processors=[mclp], logprobs=len(mclp.choices)), use_tqdm=True)\n",
    "    logprobs = [{lp.decoded_token: lp.logprob for lp in list(lps)} for lps in [output.outputs[0].logprobs[0].values() for output in outputs]]\n",
    "    choices = [max(d, key=d.get) for d in logprobs]\n",
    "    types = {'A':'Primary', 'B':'Secondary'}\n",
    "    choices = [types[c] for c in choices]\n",
    "\n",
    "\n",
    "    \n",
    "    df = df.with_columns(pl.Series('type', choices))\n",
    "    df.select('article_id', 'dataset_id','type').write_csv('/tmp/doi_sub.csv')\n",
    "\n",
    "    acc_df = assume_type(acc_df)\n",
    "    acc_df.select('article_id','dataset_id','type').write_csv(\"/tmp/accid_sub.csv\")\n",
    "    df = pl.concat([pl.read_csv('/tmp/doi_sub.csv'), pl.read_csv('/tmp/accid_sub.csv')])\n",
    "    \n",
    "    df.select(['article_id', 'dataset_id', 'type']).with_row_index(name='row_id').write_csv('/kaggle/working/submission.csv')\n",
    "    # print(df)\n",
    "    if not IS_KAGGLE_SUBMISSION:\n",
    "        results = evaluate(df)\n",
    "        for r in results: l.info(r) \n",
    "        results = evaluate(df, on=['article_id', 'dataset_id', 'type'])\n",
    "        for r in results: l.info(r)\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        del llm, tokenizer\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    import gc, torch\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "c6a12705-737a-4b21-9bf2-125b3d1ab724",
    "_kg_hide-output": true,
    "_uuid": "bc8e0d68-3097-4ce9-99a1-536921913550",
    "execution": {
     "iopub.execute_input": "2025-09-08T08:36:06.327823Z",
     "iopub.status.busy": "2025-09-08T08:36:06.326614Z",
     "iopub.status.idle": "2025-09-08T08:36:14.273487Z",
     "shell.execute_reply": "2025-09-08T08:36:14.272181Z",
     "shell.execute_reply.started": "2025-09-08T08:36:06.327780Z"
    },
    "papermill": {
     "duration": 448.641642,
     "end_time": "2025-07-30T12:51:19.65281",
     "exception": false,
     "start_time": "2025-07-30T12:43:51.011168",
     "status": "completed"
    },
    "scrolled": true,
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp\n",
      "INFO 2025-09-08 08:36:08  [parse.py:133 - main()] Found and processed 524 PDF files.\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1590_1678-4685-gmb-2018-0055.xml -> 10.1590_1678-4685-gmb-2018-0055.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1021_jacs.2c06519.xml -> 10.1021_jacs.2c06519.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1107_s2056989015019891.xml -> 10.1107_s2056989015019891.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12881-019-0773-3.xml -> 10.1186_s12881-019-0773-3.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.3762_bjoc.8.42.xml -> 10.3762_bjoc.8.42.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1038_s41597-023-02280-2.xml -> 10.1038_s41597-023-02280-2.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1093_bib_bbab395.xml -> 10.1093_bib_bbab395.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12918-018-0564-z.xml -> 10.1186_s12918-018-0564-z.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1017_s0007123423000601.xml -> 10.1017_s0007123423000601.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.3133_fs20233046.xml -> 10.3133_fs20233046.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.3133_ofr20231027.xml -> 10.3133_ofr20231027.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1016_j.dib.2022.108797.xml -> 10.1016_j.dib.2022.108797.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s13104-018-4014-1.xml -> 10.1186_s13104-018-4014-1.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1021_acscentsci.1c01109.xml -> 10.1021_acscentsci.1c01109.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12906-019-2769-0.xml -> 10.1186_s12906-019-2769-0.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1107_s1600536808011148.xml -> 10.1107_s1600536808011148.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1371_journal.pone.0117675.xml -> 10.1371_journal.pone.0117675.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12859-016-0938-4.xml -> 10.1186_s12859-016-0938-4.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12864-018-5198-4.xml -> 10.1186_s12864-018-5198-4.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12977-015-0204-2.xml -> 10.1186_s12977-015-0204-2.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1080_14756366.2020.1740692.xml -> 10.1080_14756366.2020.1740692.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1029_2018gl078007.xml -> 10.1029_2018gl078007.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12885-018-4229-5.xml -> 10.1186_s12885-018-4229-5.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1371_journal.pone.0139215.xml -> 10.1371_journal.pone.0139215.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1038_s41598-020-59839-x.xml -> 10.1038_s41598-020-59839-x.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1016_j.ecolind.2021.107934.xml -> 10.1016_j.ecolind.2021.107934.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1038_s41396-020-00885-8.xml -> 10.1038_s41396-020-00885-8.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12870-019-1926-4.xml -> 10.1186_s12870-019-1926-4.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1136_jitc-2021-003114.xml -> 10.1136_jitc-2021-003114.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.5194_essd-2023-187.xml -> 10.5194_essd-2023-187.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12870-020-02692-x.xml -> 10.1186_s12870-020-02692-x.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1111_gcb.14974.xml -> 10.1111_gcb.14974.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s13046-018-0843-y.xml -> 10.1186_s13046-018-0843-y.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_1752-153x-7-123.xml -> 10.1186_1752-153x-7-123.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12885-018-4314-9.xml -> 10.1186_s12885-018-4314-9.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1107_s2052252520013603.xml -> 10.1107_s2052252520013603.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: generic\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1111_1365-2435.13569.xml -> 10.1111_1365-2435.13569.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1039_d0sc02676j.xml -> 10.1039_d0sc02676j.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.3390_rs4102923.xml -> 10.3390_rs4102923.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1109_access.2024.3385658.xml -> 10.1109_access.2024.3385658.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s13058-015-0618-8.xml -> 10.1186_s13058-015-0618-8.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.3389_feart.2023.1205211.xml -> 10.3389_feart.2023.1205211.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.3389_fpls.2023.1160645.xml -> 10.3389_fpls.2023.1160645.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s13321-017-0246-7.xml -> 10.1186_s13321-017-0246-7.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1107_s1600536812024269.xml -> 10.1107_s1600536812024269.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12870-018-1332-3.xml -> 10.1186_s12870-018-1332-3.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.5194_essd-12-1287-2020.xml -> 10.5194_essd-12-1287-2020.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12864-015-2206-9.xml -> 10.1186_s12864-015-2206-9.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1002_ece3.5260.xml -> 10.1002_ece3.5260.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1039_d0sc03604h.xml -> 10.1039_d0sc03604h.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12885-017-3237-1.xml -> 10.1186_s12885-017-3237-1.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12859-018-2146-x.xml -> 10.1186_s12859-018-2146-x.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1016_j.cpc.2024.109087.xml -> 10.1016_j.cpc.2024.109087.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.7554_elife.29944.xml -> 10.7554_elife.29944.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.3390_inorganics7050058.xml -> 10.3390_inorganics7050058.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1128_spectrum.00422-24.xml -> 10.1128_spectrum.00422-24.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1021_acsomega.3c06074.xml -> 10.1021_acsomega.3c06074.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1371_journal.pone.0198382.xml -> 10.1371_journal.pone.0198382.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.20944_preprints202009.0353.v1.xml -> 10.20944_preprints202009.0353.v1.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1371_journal.pone.0191086.xml -> 10.1371_journal.pone.0191086.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.12688_f1000research.13622.1.xml -> 10.12688_f1000research.13622.1.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1038_sdata.2017.167.xml -> 10.1038_sdata.2017.167.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1002_chem.201902131.xml -> 10.1002_chem.201902131.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1038_s41467-019-10357-z.xml -> 10.1038_s41467-019-10357-z.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:08  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1002_ece3.3985.xml -> 10.1002_ece3.3985.txt\n",
      "INFO 2025-09-08 08:36:08  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1002_ejoc.202000916.xml -> 10.1002_ejoc.202000916.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s13068-018-1316-4.xml -> 10.1186_s13068-018-1316-4.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1111_bph.14747.xml -> 10.1111_bph.14747.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1107_s1600536811003163.xml -> 10.1107_s1600536811003163.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1130_ges01387.1.xml -> 10.1130_ges01387.1.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.21203_rs.3.rs-3338732_v1.xml -> 10.21203_rs.3.rs-3338732_v1.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s13024-018-0254-8.xml -> 10.1186_s13024-018-0254-8.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1039_c9ra06638a.xml -> 10.1039_c9ra06638a.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1107_s160053681103220x.xml -> 10.1107_s160053681103220x.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12920-020-00737-6.xml -> 10.1186_s12920-020-00737-6.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: generic\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1111_ddi.13161.xml -> 10.1111_ddi.13161.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12864-020-6657-2.xml -> 10.1186_s12864-020-6657-2.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.7717_peerj.12422.xml -> 10.7717_peerj.12422.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.3389_fcimb.2024.1292467.xml -> 10.3389_fcimb.2024.1292467.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.3897_neobiota.82.87455.xml -> 10.3897_neobiota.82.87455.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1038_s41597-019-0101-y.xml -> 10.1038_s41597-019-0101-y.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1371_journal.pone.0200041.xml -> 10.1371_journal.pone.0200041.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1093_beheco_arw167.xml -> 10.1093_beheco_arw167.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.3133_ofr20231026.xml -> 10.3133_ofr20231026.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1002_ece3.6144.xml -> 10.1002_ece3.6144.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1039_d0sc02283g.xml -> 10.1039_d0sc02283g.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s11658-018-0120-2.xml -> 10.1186_s11658-018-0120-2.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12864-019-6131-1.xml -> 10.1186_s12864-019-6131-1.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.5194_amt-15-3969-2022.xml -> 10.5194_amt-15-3969-2022.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1534_g3.119.400401.xml -> 10.1534_g3.119.400401.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1002_2017jc013030.xml -> 10.1002_2017jc013030.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1590_1516-3180.2018.0270071218.xml -> 10.1590_1516-3180.2018.0270071218.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12918-018-0620-8.xml -> 10.1186_s12918-018-0620-8.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12918-015-0209-4.xml -> 10.1186_s12918-015-0209-4.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12870-018-1542-8.xml -> 10.1186_s12870-018-1542-8.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s13326-019-0195-3.xml -> 10.1186_s13326-019-0195-3.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1039_d1ee03696c.xml -> 10.1039_d1ee03696c.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.3390_d13010019.xml -> 10.3390_d13010019.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12859-018-2414-9.xml -> 10.1186_s12859-018-2414-9.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1055_s-0039-1693681.xml -> 10.1055_s-0039-1693681.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s13059-020-1949-z.xml -> 10.1186_s13059-020-1949-z.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1002_anie.201916483.xml -> 10.1002_anie.201916483.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12859-018-2263-6.xml -> 10.1186_s12859-018-2263-6.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12885-019-5681-6.xml -> 10.1186_s12885-019-5681-6.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1107_s1600536809014883.xml -> 10.1107_s1600536809014883.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s40169-019-0253-6.xml -> 10.1186_s40169-019-0253-6.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1002_chem.202001412.xml -> 10.1002_chem.202001412.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1107_s1600536809022582.xml -> 10.1107_s1600536809022582.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12866-020-01863-y.xml -> 10.1186_s12866-020-01863-y.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1128_JVI.01717-21.xml -> 10.1128_JVI.01717-21.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.3389_fcell.2020.618552.xml -> 10.3389_fcell.2020.618552.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_1471-244x-13-259.xml -> 10.1186_1471-244x-13-259.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1107_s1600536810036299.xml -> 10.1107_s1600536810036299.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1029_2023wr035126.xml -> 10.1029_2023wr035126.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.3390_molecules23123199.xml -> 10.3390_molecules23123199.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s13024-018-0266-4.xml -> 10.1186_s13024-018-0266-4.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1107_s1600536811042164.xml -> 10.1107_s1600536811042164.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1002_chem.202003167.xml -> 10.1002_chem.202003167.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1242_dev.138545.xml -> 10.1242_dev.138545.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12920-019-0628-y.xml -> 10.1186_s12920-019-0628-y.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: generic\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1111_1365-2656.12382.xml -> 10.1111_1365-2656.12382.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.5194_acp-2021-570.xml -> 10.5194_acp-2021-570.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1590_1413-785220192703169516.xml -> 10.1590_1413-785220192703169516.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12859-016-1206-3.xml -> 10.1186_s12859-016-1206-3.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1080_22221751.2020.1738277.xml -> 10.1080_22221751.2020.1738277.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s13068-017-0901-2.xml -> 10.1186_s13068-017-0901-2.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1111_eva.12151.xml -> 10.1111_eva.12151.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: generic\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1111_1365-2435.13431.xml -> 10.1111_1365-2435.13431.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1107_s2053229620003757.xml -> 10.1107_s2053229620003757.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1002_chem.202001668.xml -> 10.1002_chem.202001668.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12879-019-3766-0.xml -> 10.1186_s12879-019-3766-0.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1371_journal.pone.0093021.xml -> 10.1371_journal.pone.0093021.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s40793-015-0095-9.xml -> 10.1186_s40793-015-0095-9.txt\n",
      "INFO 2025-09-08 08:36:09  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:09  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12943-018-0878-x.xml -> 10.1186_s12943-018-0878-x.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12866-019-1542-3.xml -> 10.1186_s12866-019-1542-3.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s13059-020-02048-6.xml -> 10.1186_s13059-020-02048-6.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1007_s00382-022-06361-7.xml -> 10.1007_s00382-022-06361-7.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12943-019-1017-z.xml -> 10.1186_s12943-019-1017-z.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1016_j.dib.2023.109949.xml -> 10.1016_j.dib.2023.109949.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1016_j.scitotenv.2024.171850.xml -> 10.1016_j.scitotenv.2024.171850.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: generic\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1002_anie.202005531.xml -> 10.1002_anie.202005531.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: generic\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1155_2013_536562.xml -> 10.1155_2013_536562.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.3897_zoologia.35.e23481.xml -> 10.3897_zoologia.35.e23481.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s13104-019-4127-1.xml -> 10.1186_s13104-019-4127-1.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s13071-016-1359-y.xml -> 10.1186_s13071-016-1359-y.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1145_3461702.3462538.xml -> 10.1145_3461702.3462538.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12859-020-3496-8.xml -> 10.1186_s12859-020-3496-8.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.12688_f1000research.10556.1.xml -> 10.12688_f1000research.10556.1.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s13321-015-0110-6.xml -> 10.1186_s13321-015-0110-6.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12868-018-0468-2.xml -> 10.1186_s12868-018-0468-2.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s13014-018-1166-z.xml -> 10.1186_s13014-018-1166-z.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1039_d0sc01518k.xml -> 10.1039_d0sc01518k.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s13321-017-0223-1.xml -> 10.1186_s13321-017-0223-1.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12935-020-01373-x.xml -> 10.1186_s12935-020-01373-x.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s13073-019-0674-2.xml -> 10.1186_s13073-019-0674-2.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1107_s2056989015010257.xml -> 10.1107_s2056989015010257.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12920-018-0379-1.xml -> 10.1186_s12920-018-0379-1.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1107_s1600536809043700.xml -> 10.1107_s1600536809043700.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12916-019-1469-4.xml -> 10.1186_s12916-019-1469-4.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s40168-018-0532-2.xml -> 10.1186_s40168-018-0532-2.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1371_journal.pone.0170126.xml -> 10.1371_journal.pone.0170126.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.3390_s19030479.xml -> 10.3390_s19030479.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1617_s11527-023-02260-3.xml -> 10.1617_s11527-023-02260-3.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1093_beheco_arad016.xml -> 10.1093_beheco_arad016.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1038_s41562-021-01247-w.xml -> 10.1038_s41562-021-01247-w.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s13643-018-0859-6.xml -> 10.1186_s13643-018-0859-6.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.5194_acp-22-5701-2022.xml -> 10.5194_acp-22-5701-2022.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12860-020-00261-6.xml -> 10.1186_s12860-020-00261-6.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1093_beheco_arz101.xml -> 10.1093_beheco_arz101.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1080_21645515.2023.2189598.xml -> 10.1080_21645515.2023.2189598.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.7554_elife.74937.xml -> 10.7554_elife.74937.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: generic\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1111_1365-2656.12491.xml -> 10.1111_1365-2656.12491.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12864-018-5054-6.xml -> 10.1186_s12864-018-5054-6.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1002_ece3.5395.xml -> 10.1002_ece3.5395.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12859-016-0904-1.xml -> 10.1186_s12859-016-0904-1.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1101_2022.02.10.480011.xml -> 10.1101_2022.02.10.480011.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1107_s2056989016016819.xml -> 10.1107_s2056989016016819.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12859-017-1952-x.xml -> 10.1186_s12859-017-1952-x.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1101_2022.07.21.501061.xml -> 10.1101_2022.07.21.501061.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12967-020-02311-1.xml -> 10.1186_s12967-020-02311-1.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1098_rspb.2015.1498.xml -> 10.1098_rspb.2015.1498.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1371_journal.pntd.0005385.xml -> 10.1371_journal.pntd.0005385.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1111_eva.12446.xml -> 10.1111_eva.12446.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1107_s2052252514012081.xml -> 10.1107_s2052252514012081.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1098_rsbl.2015.0113.xml -> 10.1098_rsbl.2015.0113.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.3390_molecules200917469.xml -> 10.3390_molecules200917469.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1029_2022gl100473.xml -> 10.1029_2022gl100473.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s13059-019-1840-y.xml -> 10.1186_s13059-019-1840-y.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1371_journal.pone.0262974.xml -> 10.1371_journal.pone.0262974.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12885-018-4768-9.xml -> 10.1186_s12885-018-4768-9.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1002_ece3.961.xml -> 10.1002_ece3.961.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s40168-017-0338-7.xml -> 10.1186_s40168-017-0338-7.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1039_c5sc01309g.xml -> 10.1039_c5sc01309g.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: generic\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1002_ejic.201900904.xml -> 10.1002_ejic.201900904.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12868-019-0514-8.xml -> 10.1186_s12868-019-0514-8.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.3133_ofr20201035.xml -> 10.3133_ofr20201035.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.21105_joss.04237.xml -> 10.21105_joss.04237.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12885-020-06724-5.xml -> 10.1186_s12885-020-06724-5.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12920-019-0611-7.xml -> 10.1186_s12920-019-0611-7.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s40478-018-0655-5.xml -> 10.1186_s40478-018-0655-5.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1177_0018720820970751.xml -> 10.1177_0018720820970751.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1038_s41597-022-01555-4.xml -> 10.1038_s41597-022-01555-4.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s13039-022-00631-z.xml -> 10.1186_s13039-022-00631-z.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1098_rsos.170796.xml -> 10.1098_rsos.170796.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12862-019-1388-1.xml -> 10.1186_s12862-019-1388-1.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.7554_eLife.72626.xml -> 10.7554_eLife.72626.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12920-019-0646-9.xml -> 10.1186_s12920-019-0646-9.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:10  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1371_journal.pone.0146274.xml -> 10.1371_journal.pone.0146274.txt\n",
      "INFO 2025-09-08 08:36:10  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1038_s41598-021-85671-y.xml -> 10.1038_s41598-021-85671-y.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12874-018-0583-x.xml -> 10.1186_s12874-018-0583-x.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1111_acel.13089.xml -> 10.1111_acel.13089.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12882-019-1494-8.xml -> 10.1186_s12882-019-1494-8.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1038_s41467-018-04041-x.xml -> 10.1038_s41467-018-04041-x.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.3390_s23094491.xml -> 10.3390_s23094491.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1002_ece3.9627.xml -> 10.1002_ece3.9627.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s40478-018-0561-x.xml -> 10.1186_s40478-018-0561-x.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12864-018-4947-8.xml -> 10.1186_s12864-018-4947-8.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12874-019-0829-2.xml -> 10.1186_s12874-019-0829-2.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1107_s2056989014026358.xml -> 10.1107_s2056989014026358.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1007_s00259-022-06053-8.xml -> 10.1007_s00259-022-06053-8.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: generic\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1029_2020jf005675.xml -> 10.1029_2020jf005675.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12863-017-0513-7.xml -> 10.1186_s12863-017-0513-7.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s13148-019-0719-9.xml -> 10.1186_s13148-019-0719-9.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s40851-018-0089-8.xml -> 10.1186_s40851-018-0089-8.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s13321-018-0298-3.xml -> 10.1186_s13321-018-0298-3.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.3897_zoologia.36.e32053.xml -> 10.3897_zoologia.36.e32053.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12864-019-6099-x.xml -> 10.1186_s12864-019-6099-x.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s11689-019-9287-8.xml -> 10.1186_s11689-019-9287-8.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1140_epjc_s10052-018-6468-7.xml -> 10.1140_epjc_s10052-018-6468-7.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1029_2021gl096173.xml -> 10.1029_2021gl096173.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s13148-018-0581-1.xml -> 10.1186_s13148-018-0581-1.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12859-020-3415-z.xml -> 10.1186_s12859-020-3415-z.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.12688_f1000research.11698.1.xml -> 10.12688_f1000research.11698.1.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1534_g3.119.400993.xml -> 10.1534_g3.119.400993.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s40170-020-00212-x.xml -> 10.1186_s40170-020-00212-x.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s13073-019-0709-8.xml -> 10.1186_s13073-019-0709-8.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12870-019-2199-7.xml -> 10.1186_s12870-019-2199-7.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1002_ece3.4466.xml -> 10.1002_ece3.4466.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1107_s2052252515023945.xml -> 10.1107_s2052252515023945.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.7554_elife.73695.xml -> 10.7554_elife.73695.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12920-018-0426-y.xml -> 10.1186_s12920-018-0426-y.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12859-018-2036-2.xml -> 10.1186_s12859-018-2036-2.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.3390_s23177333.xml -> 10.3390_s23177333.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1371_journal.pcbi.1011828.xml -> 10.1371_journal.pcbi.1011828.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s13568-018-0680-6.xml -> 10.1186_s13568-018-0680-6.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: generic\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1002_esp.5090.xml -> 10.1002_esp.5090.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12974-020-01860-y.xml -> 10.1186_s12974-020-01860-y.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1038_s41558-022-01301-z.xml -> 10.1038_s41558-022-01301-z.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12920-018-0403-5.xml -> 10.1186_s12920-018-0403-5.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12931-019-1001-6.xml -> 10.1186_s12931-019-1001-6.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1038_s41437-020-0318-8.xml -> 10.1038_s41437-020-0318-8.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12870-019-1904-x.xml -> 10.1186_s12870-019-1904-x.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1080_15476286.2016.1232238.xml -> 10.1080_15476286.2016.1232238.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1029_2023ea002840.xml -> 10.1029_2023ea002840.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.5194_essd-2023-198.xml -> 10.5194_essd-2023-198.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1140_epjc_s10052-016-4366-4.xml -> 10.1140_epjc_s10052-016-4366-4.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s13071-018-2842-4.xml -> 10.1186_s13071-018-2842-4.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.12688_f1000research.13852.1.xml -> 10.12688_f1000research.13852.1.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s13054-019-2488-4.xml -> 10.1186_s13054-019-2488-4.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1007_s12559-020-09751-3.xml -> 10.1007_s12559-020-09751-3.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s13104-019-4058-x.xml -> 10.1186_s13104-019-4058-x.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1107_s1600536812014614.xml -> 10.1107_s1600536812014614.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1098_rsos.190841.xml -> 10.1098_rsos.190841.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1016_j.molcel.2018.11.006.xml -> 10.1016_j.molcel.2018.11.006.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s13072-019-0322-5.xml -> 10.1186_s13072-019-0322-5.txt\n",
      "INFO 2025-09-08 08:36:11  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:11  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1007_s12263-014-0408-4.xml -> 10.1007_s12263-014-0408-4.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1093_nar_gkp1049.xml -> 10.1093_nar_gkp1049.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1002_chem.202000235.xml -> 10.1002_chem.202000235.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1002_chem.201903120.xml -> 10.1002_chem.201903120.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12934-018-1005-9.xml -> 10.1186_s12934-018-1005-9.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s13054-015-1052-0.xml -> 10.1186_s13054-015-1052-0.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12884-018-1751-z.xml -> 10.1186_s12884-018-1751-z.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.3390_ijms12117360.xml -> 10.3390_ijms12117360.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.7554_elife.42722.xml -> 10.7554_elife.42722.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: generic\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1111_1365-2664.13136.xml -> 10.1111_1365-2664.13136.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: generic\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1111_gcb.13914.xml -> 10.1111_gcb.13914.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s13071-018-2964-8.xml -> 10.1186_s13071-018-2964-8.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1212_wnl.0000000000006035.xml -> 10.1212_wnl.0000000000006035.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1093_sysbio_syy011.xml -> 10.1093_sysbio_syy011.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1016_j.ast.2022.107401.xml -> 10.1016_j.ast.2022.107401.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12864-019-6324-7.xml -> 10.1186_s12864-019-6324-7.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1107_s1600536807066780.xml -> 10.1107_s1600536807066780.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1093_evolut_qpad206.xml -> 10.1093_evolut_qpad206.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.3390_microorganisms8121872.xml -> 10.3390_microorganisms8121872.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1242_bio.035071.xml -> 10.1242_bio.035071.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12870-020-2295-8.xml -> 10.1186_s12870-020-2295-8.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s40168-018-0550-0.xml -> 10.1186_s40168-018-0550-0.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s40425-019-0730-x.xml -> 10.1186_s40425-019-0730-x.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: generic\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1111_2041-210x.12453.xml -> 10.1111_2041-210x.12453.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1039_d0sc01197e.xml -> 10.1039_d0sc01197e.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1107_s1600536812027390.xml -> 10.1107_s1600536812027390.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1098_rsos.210982.xml -> 10.1098_rsos.210982.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s13007-019-0403-2.xml -> 10.1186_s13007-019-0403-2.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1107_s160053681102201x.xml -> 10.1107_s160053681102201x.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1111_eva.12768.xml -> 10.1111_eva.12768.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1107_s2056989020010658.xml -> 10.1107_s2056989020010658.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12870-019-1889-5.xml -> 10.1186_s12870-019-1889-5.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12903-018-0656-6.xml -> 10.1186_s12903-018-0656-6.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.12688_f1000research.13483.1.xml -> 10.12688_f1000research.13483.1.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.7554_eLife.63194.xml -> 10.7554_eLife.63194.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.3390_v11060565.xml -> 10.3390_v11060565.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.3897_zookeys.500.9360.xml -> 10.3897_zookeys.500.9360.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1002_anie.202007717.xml -> 10.1002_anie.202007717.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1107_s1600536812046892.xml -> 10.1107_s1600536812046892.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12866-015-0509-2.xml -> 10.1186_s12866-015-0509-2.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1002_ece3.6303.xml -> 10.1002_ece3.6303.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s13059-018-1557-3.xml -> 10.1186_s13059-018-1557-3.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.12688_f1000research.4660.1.xml -> 10.12688_f1000research.4660.1.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12864-019-5872-1.xml -> 10.1186_s12864-019-5872-1.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.3390_molecules191017026.xml -> 10.3390_molecules191017026.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s13100-019-0153-8.xml -> 10.1186_s13100-019-0153-8.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1002_mp.14424.xml -> 10.1002_mp.14424.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.5194_essd-2019-206.xml -> 10.5194_essd-2019-206.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12862-019-1509-x.xml -> 10.1186_s12862-019-1509-x.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12913-018-3333-1.xml -> 10.1186_s12913-018-3333-1.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1111_ejn.13855.xml -> 10.1111_ejn.13855.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1107_s2052252515010271.xml -> 10.1107_s2052252515010271.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12862-015-0558-z.xml -> 10.1186_s12862-015-0558-z.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1371_journal.pone.0096457.xml -> 10.1371_journal.pone.0096457.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: generic\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1111_mec.16977.xml -> 10.1111_mec.16977.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: generic\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1111_2041-210x.13817.xml -> 10.1111_2041-210x.13817.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12870-019-1632-2.xml -> 10.1186_s12870-019-1632-2.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1002_cssc.202201821.xml -> 10.1002_cssc.202201821.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.3389_fchem.2019.00828.xml -> 10.3389_fchem.2019.00828.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_gb-2010-11-10-r101.xml -> 10.1186_gb-2010-11-10-r101.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1371_journal.pone.0284951.xml -> 10.1371_journal.pone.0284951.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1107_s2059798322005691.xml -> 10.1107_s2059798322005691.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1038_s41598-024-56373-y.xml -> 10.1038_s41598-024-56373-y.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12859-017-1563-6.xml -> 10.1186_s12859-017-1563-6.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1103_physrevresearch.4.023008.xml -> 10.1103_physrevresearch.4.023008.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1371_journal.pone.0159387.xml -> 10.1371_journal.pone.0159387.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s13059-017-1200-8.xml -> 10.1186_s13059-017-1200-8.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s13059-019-1908-8.xml -> 10.1186_s13059-019-1908-8.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:12  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s13020-020-00307-z.xml -> 10.1186_s13020-020-00307-z.txt\n",
      "INFO 2025-09-08 08:36:12  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1038_ncomms11871.xml -> 10.1038_ncomms11871.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.5194_gmd-13-335-2020.xml -> 10.5194_gmd-13-335-2020.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1107_s2052252515011665.xml -> 10.1107_s2052252515011665.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1073_pnas.2306723120.xml -> 10.1073_pnas.2306723120.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1590_1414-431x20198292.xml -> 10.1590_1414-431x20198292.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1107_s1600536810047185.xml -> 10.1107_s1600536810047185.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1038_hdy.2015.99.xml -> 10.1038_hdy.2015.99.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.3133_cir1497.xml -> 10.3133_cir1497.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: generic\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1111_ddi.13153.xml -> 10.1111_ddi.13153.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1371_journal.pone.0188323.xml -> 10.1371_journal.pone.0188323.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s13059-019-1918-6.xml -> 10.1186_s13059-019-1918-6.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s13073-020-00727-4.xml -> 10.1186_s13073-020-00727-4.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.3897_bdj.7.e47369.xml -> 10.3897_bdj.7.e47369.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1107_s1600536812019885.xml -> 10.1107_s1600536812019885.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.17581_bp.2020.09104.xml -> 10.17581_bp.2020.09104.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1371_journal.pone.0212669.xml -> 10.1371_journal.pone.0212669.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s13059-019-1924-8.xml -> 10.1186_s13059-019-1924-8.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1371_journal.pone.0070749.xml -> 10.1371_journal.pone.0070749.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s13054-015-0738-7.xml -> 10.1186_s13054-015-0738-7.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12859-016-0922-z.xml -> 10.1186_s12859-016-0922-z.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.3390_molecules25010053.xml -> 10.3390_molecules25010053.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12863-019-0790-4.xml -> 10.1186_s12863-019-0790-4.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1098_rspb.2015.2726.xml -> 10.1098_rspb.2015.2726.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1038_s41467-018-07681-1.xml -> 10.1038_s41467-018-07681-1.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1007_s00442-022-05201-z.xml -> 10.1007_s00442-022-05201-z.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12933-019-0813-5.xml -> 10.1186_s12933-019-0813-5.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12879-018-3065-1.xml -> 10.1186_s12879-018-3065-1.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s13072-019-0285-6.xml -> 10.1186_s13072-019-0285-6.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s40170-018-0185-4.xml -> 10.1186_s40170-018-0185-4.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12915-018-0498-3.xml -> 10.1186_s12915-018-0498-3.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.7554_elife.62329.xml -> 10.7554_elife.62329.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: generic\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1111_njb.02077.xml -> 10.1111_njb.02077.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1590_s1677-5538.ibju.2019.0167.xml -> 10.1590_s1677-5538.ibju.2019.0167.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1039_d2cc00847e.xml -> 10.1039_d2cc00847e.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.3389_fmicb.2024.1456637.xml -> 10.3389_fmicb.2024.1456637.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s13071-018-3084-1.xml -> 10.1186_s13071-018-3084-1.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.12688_f1000research.13064.1.xml -> 10.12688_f1000research.13064.1.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1371_journal.pone.0253228.xml -> 10.1371_journal.pone.0253228.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.7717_peerj.10452.xml -> 10.7717_peerj.10452.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.5194_acp-22-2769-2022.xml -> 10.5194_acp-22-2769-2022.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1111_ggr.12517.xml -> 10.1111_ggr.12517.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s13059-019-1749-5.xml -> 10.1186_s13059-019-1749-5.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1039_c9sc02930c.xml -> 10.1039_c9sc02930c.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1002_ece3.6784.xml -> 10.1002_ece3.6784.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1002_ecs2.4619.xml -> 10.1002_ecs2.4619.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1038_s41598-017-15852-1.xml -> 10.1038_s41598-017-15852-1.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1371_journal.pone.0220399.xml -> 10.1371_journal.pone.0220399.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.7717_peerj.11352.xml -> 10.7717_peerj.11352.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.7717_peerj.13193.xml -> 10.7717_peerj.13193.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12915-018-0584-6.xml -> 10.1186_s12915-018-0584-6.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12870-020-02651-6.xml -> 10.1186_s12870-020-02651-6.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.7554_elife.63455.xml -> 10.7554_elife.63455.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s13071-018-3237-2.xml -> 10.1186_s13071-018-3237-2.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1098_rsos.160417.xml -> 10.1098_rsos.160417.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12967-019-2100-3.xml -> 10.1186_s12967-019-2100-3.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: generic\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1111_cas.12935.xml -> 10.1111_cas.12935.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.5194_gmd-12-4221-2019.xml -> 10.5194_gmd-12-4221-2019.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s13068-018-1167-z.xml -> 10.1186_s13068-018-1167-z.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s13068-018-1078-z.xml -> 10.1186_s13068-018-1078-z.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1186_s12862-018-1213-2.xml -> 10.1186_s12862-018-1213-2.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1371_journal.pone.0137181.xml -> 10.1371_journal.pone.0137181.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.3762_bjoc.9.92.xml -> 10.3762_bjoc.9.92.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1098_rspb.2015.0371.xml -> 10.1098_rspb.2015.0371.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.1016_j.jobe.2023.107105.xml -> 10.1016_j.jobe.2023.107105.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.5937_bnhmb1811227u.xml -> 10.5937_bnhmb1811227u.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:88 - convert_xml_to_txt()] Detected XML style: html\n",
      "INFO 2025-09-08 08:36:13  [parse.py:114 - batch_convert_xml_folder()] Converted: 10.3390_molecules17077645.xml -> 10.3390_molecules17077645.txt\n",
      "INFO 2025-09-08 08:36:13  [parse.py:137 - main()] Found and processed 400 XML files.\n",
      "INFO 2025-09-08 08:36:13  [parse.py:138 - main()] Overwrote 400 text files from XML conversions.\n",
      "Processed 524 PDF files.\n",
      "Processed 400 XML files.\n",
      "Overwrote 400 text files from XML conversions.\n"
     ]
    }
   ],
   "source": [
    "%cd /tmp\n",
    "! python src/parse.py /tmp/train_parse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-08T08:36:14.275742Z",
     "iopub.status.busy": "2025-09-08T08:36:14.275348Z",
     "iopub.status.idle": "2025-09-08T08:36:18.107304Z",
     "shell.execute_reply": "2025-09-08T08:36:18.105977Z",
     "shell.execute_reply.started": "2025-09-08T08:36:14.275675Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 2025-09-08 08:36:17  [check_parse.py:31 - main()] pymupdf misses: 36 dataset_ids\n"
     ]
    }
   ],
   "source": [
    "! python src/check_parse.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-08T08:36:18.109153Z",
     "iopub.status.busy": "2025-09-08T08:36:18.108791Z",
     "iopub.status.idle": "2025-09-08T08:36:25.731334Z",
     "shell.execute_reply": "2025-09-08T08:36:25.730081Z",
     "shell.execute_reply.started": "2025-09-08T08:36:18.109120Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "INFO 2025-09-08 08:36:25  [getid.py:314 - main()] all - f1: 0.5814 [648/862/71]\n",
      "INFO 2025-09-08 08:36:25  [getid.py:314 - main()] doi - f1: 0.4871 [246/477/41]\n",
      "INFO 2025-09-08 08:36:25  [getid.py:314 - main()] acc - f1: 0.6596 [402/385/30]\n",
      "**********\n",
      "INFO 2025-09-08 08:36:25  [getid.py:317 - main()] all - f1: 0.4612 [514/996/205]\n",
      "INFO 2025-09-08 08:36:25  [getid.py:317 - main()] doi - f1: 0.3366 [170/553/117]\n",
      "INFO 2025-09-08 08:36:25  [getid.py:317 - main()] acc - f1: 0.5644 [344/443/88]\n"
     ]
    }
   ],
   "source": [
    "! python src/getid.py\n",
    "# old\n",
    "# INFO 2025-09-08 07:12:48  [getid.py:299 - main()] all - f1: 0.1256 [626/8620/93]\n",
    "# INFO 2025-09-08 07:12:48  [getid.py:299 - main()] doi - f1: 0.0530 [233/8270/54]\n",
    "# INFO 2025-09-08 07:12:48  [getid.py:299 - main()] acc - f1: 0.6689 [393/350/39]\n",
    "\n",
    "# INFO 2025-09-08 07:12:48  [getid.py:301 - main()] all - f1: 0.0997 [497/8749/222]\n",
    "# INFO 2025-09-08 07:12:48  [getid.py:301 - main()] doi - f1: 0.0362 [159/8344/128]\n",
    "# INFO 2025-09-08 07:12:48  [getid.py:301 - main()] acc - f1: 0.5753 [338/405/94]\n",
    "# add Codeadd Markdown\n",
    "\n",
    "# new\n",
    "# **********\n",
    "# INFO 2025-09-08 07:22:31  [getid.py:313 - main()] all - f1: 0.6038 [615/703/104]\n",
    "# INFO 2025-09-08 07:22:31  [getid.py:313 - main()] doi - f1: 0.5432 [236/346/51]\n",
    "# INFO 2025-09-08 07:22:31  [getid.py:313 - main()] acc - f1: 0.6490 [379/357/53]\n",
    "# **********\n",
    "# INFO 2025-09-08 07:22:31  [getid.py:316 - main()] all - f1: 0.4742 [483/835/236]\n",
    "# INFO 2025-09-08 07:22:31  [getid.py:316 - main()] doi - f1: 0.3659 [159/423/128]\n",
    "# INFO 2025-09-08 07:22:31  [getid.py:316 - main()] acc - f1: 0.5548 [324/412/108]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-08T08:36:25.733416Z",
     "iopub.status.busy": "2025-09-08T08:36:25.732981Z",
     "iopub.status.idle": "2025-09-08T08:36:39.173330Z",
     "shell.execute_reply": "2025-09-08T08:36:39.172017Z",
     "shell.execute_reply.started": "2025-09-08T08:36:25.733357Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-08 08:36:34 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform\n",
      "WARNING 09-08 08:36:35 [_custom_ops.py:21] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/src/llm_validate.py\", line 90, in <module>\n",
      "    llm = vllm.LLM(model_path, quantization='awq', tensor_parallel_size=2, gpu_memory_utilization=0.9, trust_remote_code=True, dtype=\"half\", enforce_eager=True, max_model_len=2048, disable_log_stats=True, disable_custom_all_reduce=True, enable_prefix_caching=True, task='generate')\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/vllm/utils.py\", line 1161, in inner\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/vllm/entrypoints/llm.py\", line 247, in __init__\n",
      "    self.llm_engine = LLMEngine.from_engine_args(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/vllm/engine/llm_engine.py\", line 503, in from_engine_args\n",
      "    vllm_config = engine_args.create_engine_config(usage_context)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/vllm/engine/arg_utils.py\", line 1098, in create_engine_config\n",
      "    device_config = DeviceConfig(device=self.device)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<string>\", line 4, in __init__\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/vllm/config.py\", line 2119, in __post_init__\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Failed to infer device type, please set the environment variable `VLLM_LOGGING_LEVEL=DEBUG` to turn on verbose logging to help debug the issue.\n"
     ]
    }
   ],
   "source": [
    "! python src/llm_validate.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-08T08:36:39.175299Z",
     "iopub.status.busy": "2025-09-08T08:36:39.174954Z",
     "iopub.status.idle": "2025-09-08T08:36:52.020974Z",
     "shell.execute_reply": "2025-09-08T08:36:52.019728Z",
     "shell.execute_reply.started": "2025-09-08T08:36:39.175268Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-08 08:36:47 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform\n",
      "WARNING 09-08 08:36:48 [_custom_ops.py:21] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/src/post_validate.py\", line 121, in <module>\n",
      "    llm = vllm.LLM(\n",
      "          ^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/vllm/utils.py\", line 1161, in inner\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/vllm/entrypoints/llm.py\", line 247, in __init__\n",
      "    self.llm_engine = LLMEngine.from_engine_args(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/vllm/engine/llm_engine.py\", line 503, in from_engine_args\n",
      "    vllm_config = engine_args.create_engine_config(usage_context)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/vllm/engine/arg_utils.py\", line 1098, in create_engine_config\n",
      "    device_config = DeviceConfig(device=self.device)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<string>\", line 4, in __init__\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/vllm/config.py\", line 2119, in __post_init__\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Failed to infer device type, please set the environment variable `VLLM_LOGGING_LEVEL=DEBUG` to turn on verbose logging to help debug the issue.\n"
     ]
    }
   ],
   "source": [
    "! python src/post_validate.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-08T08:36:52.022425Z",
     "iopub.status.busy": "2025-09-08T08:36:52.022078Z",
     "iopub.status.idle": "2025-09-08T08:36:52.148638Z",
     "shell.execute_reply": "2025-09-08T08:36:52.147270Z",
     "shell.execute_reply.started": "2025-09-08T08:36:52.022389Z"
    },
    "papermill": {
     "duration": 0.009673,
     "end_time": "2025-07-30T12:51:19.672901",
     "exception": false,
     "start_time": "2025-07-30T12:51:19.663228",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 2025-09-08 08:29:34  [getid.py:314 - main()] all - f1: 0.5814 [648/862/71]\n",
      "INFO 2025-09-08 08:29:34  [getid.py:314 - main()] doi - f1: 0.4871 [246/477/41]\n",
      "INFO 2025-09-08 08:29:34  [getid.py:314 - main()] acc - f1: 0.6596 [402/385/30]\n",
      "INFO 2025-09-08 08:29:34  [getid.py:317 - main()] all - f1: 0.4612 [514/996/205]\n",
      "INFO 2025-09-08 08:29:34  [getid.py:317 - main()] doi - f1: 0.3366 [170/553/117]\n",
      "INFO 2025-09-08 08:29:34  [getid.py:317 - main()] acc - f1: 0.5644 [344/443/88]\n",
      "INFO 2025-09-08 08:36:25  [getid.py:314 - main()] all - f1: 0.5814 [648/862/71]\n",
      "INFO 2025-09-08 08:36:25  [getid.py:314 - main()] doi - f1: 0.4871 [246/477/41]\n",
      "INFO 2025-09-08 08:36:25  [getid.py:314 - main()] acc - f1: 0.6596 [402/385/30]\n",
      "INFO 2025-09-08 08:36:25  [getid.py:317 - main()] all - f1: 0.4612 [514/996/205]\n",
      "INFO 2025-09-08 08:36:25  [getid.py:317 - main()] doi - f1: 0.3366 [170/553/117]\n",
      "INFO 2025-09-08 08:36:25  [getid.py:317 - main()] acc - f1: 0.5644 [344/443/88]\n"
     ]
    }
   ],
   "source": [
    "! grep \"f1:\" /tmp/logs/project.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-08T08:36:52.150547Z",
     "iopub.status.busy": "2025-09-08T08:36:52.150200Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "! python src/predict.py"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 13015230,
     "sourceId": 82370,
     "sourceType": "competition"
    },
    {
     "sourceId": 248118764,
     "sourceType": "kernelVersion"
    },
    {
     "modelId": 164048,
     "modelInstanceId": 141565,
     "sourceId": 166368,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 474.866415,
   "end_time": "2025-07-30T12:51:20.001095",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-30T12:43:25.13468",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
