Articles
https://doi.org/10.1038/s41562-021-01247-w
1Donders Institute for Brain, Cognition and Behavior, Radboud University, Nijmegen, the Netherlands. 2Zuckerman Mind Brain Behavior Institute, Columbia 
University, New York, NY, USA. ✉e-mail: janneke.jehee@donders.ru.nl
V
irtually any decision comes with a sense of confidence—a 
subjective feeling that clearly affects our everyday choices. 
For example, we reduce speed when driving at night because 
we feel less confident about our estimates of distance to surround-
ing traffic, we hesitate to try a piece of food when unsure about 
its taste and we resist investing in stocks unless convinced of their 
likely future profit. But what is this sense of confidence that accom-
panies almost all of our decisions?
Recent Bayesian decision theories1–5 propose that confidence 
corresponds to the degree of belief, or probability, that a choice is 
correct based on the evidence. More specifically, these theories pro-
pose that confidence is a function of the posterior probability of 
being correct, which links confidence directly to the quality of the 
evidence on which the decision is based. Thus, greater imprecision 
in the evidence reduces the probability that the choice is correct, 
which should result in lower levels of confidence. The agent’s evi-
dence is similarly described as a degree of belief in an event, or more 
formally as a probability distribution over a latent variable. For 
example, the evidence could be a probability distribution over the 
perceived distance to surrounding traffic. The width of the distribu-
tion (the range of probable distances) is broader in the dark than on 
a clear day, thereby signalling greater imprecision or uncertainty. 
Although central to the Bayesian confidence hypothesis, whether 
such probabilistic representations play a role in confidence is 
currently unclear.
Results from behavioural studies6–9 are consistent with the notion 
that confidence is computed from the degree of imprecision in sen-
sory information. However, a major limitation of this work has been 
the use of physical sources of noise, such as a variation in image 
brightness or contrast, to manipulate uncertainty. This is problem-
atic because it could be that observers simply monitor such stimu-
lus properties as external cues to uncertainty and confidence7,10–13. 
While physiological studies have found neural correlates of statisti-
cal confidence in the orbitofrontal14,15 and lateral intraparietal cor-
tex16, these studies used a two-alternative forced choice task, so that 
the animal could simply rely on the distance between stimulus esti-
mates (that is, point estimates) and category boundary to compute 
confidence17 and need not use a representation of probability. Thus, 
one of the most fundamental assumptions of normative theories of 
decision-making—that confidence is derived from a probabilistic 
representation of information—has yet to be tested in cortex.
Here we use a combination of functional magnetic resonance 
imaging (fMRI), psychophysics and computational modelling 
to address two fundamental questions. Is confidence based on a 
probabilistic representation of sensory information? And if so, what 
neural mechanisms extract confidence from this cortical represen-
tation of uncertainty? Human participants viewed random orienta-
tion stimuli and reported both the orientation of the stimulus and 
their level of confidence in this judgement. Critically, no physical 
noise was added to the stimuli. We quantified the degree of uncer-
tainty associated with stimulus representations in visual cortex 
using a probabilistic decoding approach10,18, relying on trial-by-trial 
fluctuations in internal noise to render the evidence more or less 
reliable to the observer. We used the decoded probability distribu-
tions to compare between human data and simulated data from a 
Bayesian observer, as well as two alternative models implement-
ing heuristic strategies for confidence. Corroborating the Bayesian 
model, we discovered that human confidence judgements track the 
degree of uncertainty contained in visual cortical activity. That is, 
when the cortical representation of the stimulus was more precise 
(as indicated by a narrower decoded probability distribution), par-
ticipants reported higher levels of confidence. In addition, activity 
in the dorsal anterior insula (dAI), dorsal anterior cingulate cortex 
(dACC) and rostrolateral prefrontal cortex (rlPFC) reflected both 
this sensory uncertainty and reported confidence, in ways predicted 
by the Bayesian observer model. Taken together, these results sup-
port normative theories of decision-making and suggest that proba-
bilistic sensory information guides the computation of one’s sense 
of confidence.
Results
Ideal observer models. The observer’s task is to infer the orienta-
tion of a stimulus from a noisy sensory measurement and to report 
both this estimate and their level of confidence in this judgement. 
Subjective confidence reflects representation of 
Bayesian probability in cortex
Laura S. Geurts   1, James R. H. Cooke1, Ruben S. van Bergen   1,2 and Janneke F. M. Jehee   1 ✉
What gives rise to the human sense of confidence? Here we tested the Bayesian hypothesis that confidence is based on a prob-
ability distribution represented in neural population activity. We implemented several computational models of confidence 
and tested their predictions using psychophysics and functional magnetic resonance imaging. Using a generative model-based 
decoding technique, we extracted probability distributions from neural population activity in human visual cortex. We found 
that subjective confidence tracks the shape of the decoded distribution. That is, when sensory evidence was more precise, as 
indicated by the decoded distribution, observers reported higher levels of confidence. We furthermore found that neural activ-
ity in the insula, anterior cingulate and prefrontal cortex was linked to both the shape of the decoded distribution and reported 
confidence, in ways consistent with the Bayesian model. Altogether, our findings support recent statistical theories of confi-
dence and suggest that probabilistic information guides the computation of one’s sense of confidence.
Nature Human Behaviour | VOL 6 | February 2022 | 294–305 | www.nature.com/nathumbehav
294
Articles
NATUrE HUmAn BEhAvioUr
We consider three model observers for this task. The decision pro-
cess is identical for all three observers, but they use different strate-
gies for confidence.
The observer’s measurement m of the sensory stimulus s is cor-
rupted by noise: even when the physical stimulus is held constant, 
the measurement varies from trial to trial. Thus, the relationship 
between stimulus and measurement on each trial is given by a prob-
ability distribution, p(m|s), which we model as a circular Gaussian 
centred on the stimulus and with variance σ2
m (s). This variability 
in the measurements stems from various sources of noise that are 
of both sensory and non-sensory origin. Specifically, we consider 
three sources of noise: two sensory and one non-sensory. The first 
source depends on stimulus orientation, with larger noise levels 
for oblique than for cardinal stimulus orientations. This pattern 
captures the well-established ‘oblique effect’ in orientation percep-
tion19,20. The second source varies in magnitude from trial to trial 
and captures, for example, random fluctuations in neural response 
gain in sensory areas21. Finally, non-sensory noise refers to those 
sources of variance that affect, for example, the stimulus represen-
tation while held in working memory, or task-related processes in 
areas downstream of sensory cortex.
To infer the orientation of the stimulus from the measurement, all 
three observers invert the generative model to compute the posterior 
probability distribution p(s|m) (equation (12)). This distribution 
quantifies the degree to which different stimulus values are consis-
tent with the measurement. The mean of the posterior distribution 
is the model observer’s estimate of the stimulus ˆs. We take the (circu-
lar) variance of the distribution as a measure of the degree of uncer-
tainty in this estimate. The observer’s internal estimate of orientation 
is subsequently translated into an overt (behavioural) response, r. 
This transformation from internal estimate into motor response is 
noisy. Thus, across trials, the response fluctuates around ˆs, where 
(motor) noise is drawn from a circular Gaussian (equation (13)).
How does each of the observer models compute confidence? 
The ideal strategy is to consider the degree of imprecision in the 
observer’s decision, which depends on all sources of variance that 
affect their reports. Specifically, for the estimation task used here, 
it is statistically reasonable to compute confidence as a function of 
the expected magnitude of the error in the observer’s response. We 
quantified this as follows:
cB =
1
∫p(s|m)angle(r,s)2ds
(1)
where cB refers to the reported level of confidence, and angle (r,s)2 
represents the magnitude of the response error (that is, the squared 
acute-angle distance between response and (latent) stimulus). In 
other words, when uncertainty in evidence is higher, the expected 
decision error tends to be larger, and reported confidence will be 
lower. However, our predictions do not strongly depend on the 
particular function assumed here, as long as confidence monotoni-
cally decreases when overall uncertainty increases. We refer to this 
model as the Bayesian observer, as confidence is based (in part) 
on the posterior probability distribution—a probabilistic notion 
of uncertainty.
The second model observer uses certain properties of the stim-
ulus, such as its orientation, as a cue to confidence. This observer 
has learned through experience that behavioural precision is usu-
ally better for cardinal than for oblique orientations. The observer 
utilizes this learned relationship as a heuristic and simply reports 
lower levels of confidence for those orientations that generally 
result in reduced levels of performance. We refer to this model 
as the Stimulus heuristics observer and formally define their 
confidence as:
cS =
1
f(ˆs)
(2)
where f (ˆs) is a function that rises for oblique orientations (see equa-
tion (14) in the Methods). As the strategy ignores many sources of 
noise that create uncertainty, it is clearly suboptimal, but it could 
potentially explain human behaviour, which is why we include the 
strategy here.
The third and final model observer ignores the imprecision in 
internal estimates altogether and computes confidence exclusively 
from the noise in their motor response. We refer to this model as the 
Response heuristics observer. That is, on a given trial, the observer 
simply notices a large offset between their internal orientation esti-
mate and overt (motor) response. Observing that their response 
is off, they report lower levels of confidence. This is not an ideal 
strategy, but it could nonetheless result in a reliable link between 
confidence and behavioural performance, as we will show in our 
simulations below. We define confidence for this observer model as:
cR =
1
angle(r,ˆs)2
(3)
where angle (r,ˆs)2 is the squared acute-angle distance between ori-
entation estimate ˆs and response r. Figure 1 summarizes the three 
observer models.
Model predictions. What behavioural patterns should one observe 
for the different strategies for confidence? To address this question, 
we simulated the behavioural orientation estimates and associated 
confidence reports of the three model observers. As we will show 
below, this leads to a set of concrete predictions that we can then test 
in psychophysical and neuroimaging experiments.
Does confidence predict behavioural performance? To address 
this question, we binned the simulated data according to reported 
level of confidence and calculated the across-trial variance in behav-
ioural orientation estimates for each of the bins. We first did this 
irrespective of the orientation of the stimulus. We found that the 
orientation judgements of the model observers were generally more 
precise when confidence was higher, regardless of the strategy for 
confidence employed by the observer (Fig. 2a). Thus, a predictive 
link between confidence and behavioural precision is consistent 
with several strategies and does not necessarily imply that confi-
dence is based on a probabilistic representation of the degree of 
uncertainty in one’s evidence.
We next turned to the relationship between confidence and 
behavioural performance for a constant stimulus. Closely repli-
cating the experimental analysis procedures (see below), we first 
removed the effect of stimulus orientation from confidence, binned 
the data according to residual level of confidence and calculated the 
variance in behavioural orientation estimates for each of the bins. 
We found that higher levels of confidence again predicted greater 
behavioural precision for both the Bayesian and Response heuristics 
models (Fig. 2b). For the Stimulus heuristics observer, in contrast, 
we observed no clear link between confidence and behavioural 
performance. This makes sense, as this observer uses orientation 
as a cue to confidence, so an identical orientation stimulus should, 
when averaged across repeated presentations, always result in the 
same level of confidence, irrespective of any stimulus-independent 
sources of variance. This analysis could thus enable us to differenti-
ate between some, though not all, strategies for confidence.
We next considered the relationship between confidence and 
the quality of the observer’s evidence. Specifically, we determined 
the extent to which the degree of uncertainty in their sensory evi-
dence predicted reported levels of confidence. Sensory uncertainty 
was quantified as the width of a probability distribution (Methods), 
similar to the empirical conditions. For practical reasons, we here 
disregard the contribution of non-sensory sources of variance 
and focus on sensory uncertainty alone, so as to closely match the 
empirical analyses. The data were binned for visualization only, 
and the mean levels of confidence and uncertainty were computed 
Nature Human Behaviour | VOL 6 | February 2022 | 294–305 | www.nature.com/nathumbehav
295
Articles
NATUrE HUmAn BEhAvioUr
for each of the bins. When analysed across stimulus orientations, 
and for both the Stimulus heuristics and Bayesian observers, the 
reported levels of confidence consistently decreased as sensory 
uncertainty increased. However, we observed no such relationship 
between confidence and uncertainty for the Response heuristics 
observer (Fig. 2c). When holding the stimulus constant, the results 
were even more distinct between confidence strategies. That is, after 
we removed the contribution of stimulus orientation (Methods), 
the relationship between sensory uncertainty and confidence still 
held for the Bayesian observer, but no such link between the fidel-
ity of the observer’s sensory representation and confidence was 
observed for the two remaining models (Fig. 2d). This illustrates 
the importance of considering internal levels of uncertainty when 
studying confidence and moreover indicates that these analyses, 
when combined, should enable us to adjudicate between strategies 
for confidence.
In sum, if human confidence estimates are based on probabilis-
tic computations, then (1) behavioural variance in an orientation 
judgement task should be higher with reduced levels of confidence 
for a constant stimulus, (2) there should be an inverse relationship 
between sensory uncertainty in cortex and reported confidence, 
and (3) this inverse relationship should hold both across orienta-
tions and when holding the stimulus constant. With these predic-
tions in hand, we now turn to the experimental data to see which 
strategy best describes human confidence judgements.
Human observers. Do human observers use a probabilistic rep-
resentation of evidence quality when reporting confidence? To 
address this question, we presented 32 human participants with ori-
ented gratings while we measured their brain activity using fMRI. 
The observers reported the orientation of the grating, as well as 
their confidence in this judgement (see Extended Data Fig. 1 for 
the trial structure). They generally performed well on this task, 
with a mean absolute behavioural estimation error of 4.34 ± 0.212° 
(mean ± s.e.m. across participants).
We first focused on the link between behavioural performance 
and confidence. For each observer, we divided all trials, regard-
less of presented orientation, into ten bins of increasing confi-
dence, and we computed and compared behavioural variability 
and mean level of confidence in each bin. We found a significant 
inverse relationship between confidence and behavioural variability 
(t(287) = −16.79; P < 0.001; r = −0.70; 95% confidence interval (CI), 
(−0.76, −0.64); Fig. 3a, left). The observers’ orientation judgements 
were thus more precise when confidence was high. This indicates 
that the participants were able to meaningfully estimate their own 
level of confidence in the task.
We next turned to the relationship between confidence and 
behavioural precision for repeated presentations of the same stimu-
lus. For each observer, we again sorted the trials into ten bins of 
increasing confidence, calculated the mean level of confidence and 
behavioural variability across all trials in each bin, and computed 
the partial correlation coefficient between the two (while control-
ling for stimulus orientation; Methods). We considered two pos-
sible outcomes. If observers account for trial-by-trial fluctuations 
in internal noise when estimating confidence, as suggested by both 
the Bayesian and Response heuristics models, then higher levels of 
confidence should predict improved behavioural performance. If, 
in contrast, observers rely on orientation heuristics for confidence, 
then we should observe no systematic relationship between confi-
dence and behavioural variability. The results revealed that behav-
iour was more precise when confidence was high (Fig. 3a, right; 
t(286) = −11.02; P < 0.001; r = −0.55; 95% CI, (−0.62, −0.46)). 
This is consistent with both the Bayesian and Response heuristics 
models and argues against an explanation of confidence in terms of 
orientation heuristics.
To adjudicate between the two remaining hypotheses, we then 
turned to the brain data. Specifically, we used a probabilistic decod-
ing algorithm10,18 to characterize the degree of uncertainty in per-
ceptual evidence from cortical activity patterns in areas V1–V3. 
Uncertainty in the cortical stimulus representation (‘decoded 
s
m
r
Non-sensory noise (
)
Stimulus-independent
sensory noise (
)
Stimulus-dependent
sensory noise (σso
2
σsi
2
σn2
σso
2
)
p(s|m)
s r
Orientation
Orientation
Confidence
Distance
     r
Response 
heuristics
Stimulus
heuristics
r
Orientation
Expected
distance 
s      r
Bayesian
Confidence
ˆ
ˆ
ˆ
s
s
ˆs
˄s
Response noise (
)
σr2
Measurement noise (
)
σm2
Fig. 1 | Overview of sources of noise and three observer models. The observers’ task is to estimate the presented stimulus orientation s from a noisy 
measurement m. Multiple sources of noise affect the perceptual decision-making process. The measurements (m) vary from trial to trial due to sensory 
sources of noise, which can be decomposed into stimulus-related (σ2
so) and stimulus-independent (σ2
si) noise, as well as (unexplained) downstream 
(non-sensory) noise (σ2
n). The observers compute their stimulus estimates ˆs as the mean of the posterior distribution p(s|m). The internal orientation 
estimate is transformed into a behavioural (overt) response r, which is subject to further noise (σ2
r ). The observers also give their level of confidence in this 
behavioural estimate. The Bayesian observer computes confidence as a function of the expected distance between latent stimulus and response, which 
depends on both the response itself and the width of the posterior p(s|m); this incorporates all sources of measurement noise. The Stimulus heuristics 
observer computes confidence as a function of their perceptual orientation estimate (ˆs). The Response heuristics observer computes confidence as a 
function of the distance between their internal orientation estimate (ˆs) and overt motor response (r). Both Heuristics observers ignore the degree of 
uncertainty in their orientation estimates when computing confidence.
Nature Human Behaviour | VOL 6 | February 2022 | 294–305 | www.nature.com/nathumbehav
296
Articles
NATUrE HUmAn BEhAvioUr
uncertainty’) was quantified on a trial-by-trial basis as the width (vari-
ance) of a decoded probability distribution (Methods). Benchmark 
analyses verified that (1) orientation decoding performance was 
well above chance levels (Extended Data Fig. 2a; see also ref. 10), 
(2) decoded uncertainty was lower for cardinal than for oblique 
stimuli (Extended Data Fig. 2b; see also ref. 10) and (3) decoded 
uncertainty predicted behavioural variability, both within and 
across stimulus orientations (Extended Data Fig. 2c,d; see also 
ref. 10). Altogether, this confirms that the precision of the observer’s 
internal sensory evidence was reliably extracted from the patterns of 
fMRI activity on a trial-by-trial basis.
Do human observers rely on the quality of their internal visual 
evidence when estimating confidence? To address this question, we 
computed, for each individual observer, the trial-by-trial rank cor-
relation coefficient (ρ) between reported confidence and decoded 
uncertainty (see Fig. 3b for an example observer). The obtained 
correlation coefficients were subsequently averaged across observ-
ers. Per our simulations, we predicted that if confidence is based on 
sensory uncertainty, then the imprecision in the observer’s sensory 
evidence, as assessed by the decoder, should predict the confidence 
judgements of the observer. If, however, confidence is consistent 
with heuristic computations based on non-sensory sources of noise, 
then we should observe no relationship between decoded uncer-
tainty and reported confidence. Corroborating the Bayesian model, 
there was a reliable inverse relationship between decoded uncer-
tainty and behavioural confidence (z = −2.17; P = 0.015; ρ = −0.018; 
95% CI, (−0.035, −0.0018); Fig. 3c, left). To further substantiate this 
result, we repeated the analysis while controlling for stimulus orien-
tation (Methods, see Extended Data Fig. 3 for fitted functions). This 
did not significantly reduce the strength of the observed relation-
ship between the fidelity of the cortical stimulus representation and 
reported confidence (z = 0.45; P = 0.33; Cohen’s q = 0.0054; 95% CI, 
(−0.018, 0.029); Fig. 3c, right) and again reached significance when 
using smaller numbers of voxels, which respond more strongly to 
the visual stimulus (Extended Data Fig. 4). Thus, when the cortical 
representation of a stimulus is more precise, observers consistently 
report higher levels of confidence, as predicted by the Bayesian 
model (and neither of the other models). Control analyses verified 
that these results were robust to variations in the number of voxels 
selected for analysis (Extended Data Fig. 4) and, moreover, that they 
could not be explained by eye movement, position or blinks, or by 
the mean amplitude of the blood-oxygen-level-dependent (BOLD) 
signal (Extended Data Fig. 5). Taken together, these results suggest 
that human observers rely on a probabilistic representation of the 
quality of their sensory evidence when judging confidence.
Sensory uncertainty and confidence in downstream areas. To 
further test the probabilistic confidence hypothesis, we next asked 
which downstream regions might read out the uncertainty con-
tained in visual cortical activity to compute confidence. On the 
basis of our modelling work, we reasoned that if confidence is based 
on a probabilistic representation of the evidence, then we should be 
able to find downstream areas whose activity reflects sensory uncer-
tainty and predicts reported confidence on a trial-by-trial basis. 
Specifically, we predicted an inverse relationship in activity between 
sensory uncertainty and confidence for these regions (Fig. 2d). 
Thus, under the probabilistic confidence hypothesis, cortical activ-
ity should not only increase (decrease) with reduced reliability of 
the observer’s perceptual evidence but also decrease (increase) 
when the observer reports greater levels of decision confidence.
We first focused on those areas that are driven by internal fluc-
tuations in perceptual uncertainty. To identify candidate areas, we 
performed a whole-brain search. Specifically, we ran a general linear 
model (GLM) analysis in which we modelled the BOLD signal as 
a function of the degree of uncertainty decoded from visual corti-
cal representations (in areas V1–V3), while controlling for differ-
ences in stimulus orientation (see Methods for further details). We 
found several clusters downstream of visual cortex where neural 
activity reliably co-fluctuated with trial-by-trial changes in decoded 
sensory uncertainty (see Fig. 4a for an overview, Supplementary 
Data for whole-brain maps and Supplementary Table 1 for a list of 
clusters). These included the dAI, dACC and left rlPFC—regions 
that are commonly associated with uncertainty22 (dAI), volatility23,24 
(dACC) and metacognition25 (rlPFC).
We next asked whether these uncertainty-tracking regions 
would also show a reliable opposite relationship to confidence 
in their activity, as predicted by the Bayesian observer model. To 
address this question, we performed region-of-interest (ROI) 
analyses within the candidate regions identified by the above 
whole-brain analysis. First, individual ROIs were created by select-
ing all uncertainty-driven voxels within predefined anatomical 
masks corresponding to dAI26, dACC27 and left rlPFC28, using a 
leave-one-participant-out cross-validation procedure to avoid 
double-dipping29,30 (see Methods for the details and Extended Data 
Fig. 6 for the remaining clusters). For each participant, we then 
averaged the BOLD signal across all voxels within the ROI. To 
test whether BOLD activity was reliably modulated by the level of 
confidence reported by the observer, we performed a GLM analy-
sis (see Methods for the model details). This revealed a significant 
effect of confidence on BOLD activity in all three regions (dAI: 
Across
stimulus orientations
Controlled for
stimulus orientation
a
c
b
d
Bayesian
Resp. heuri.
Stim. heuri.
✓
✓
✓
Bayesian
Resp. heuri.
Stim. heuri.
✓
Ø
✓
Bayesian
Resp. heuri.
Stim. heuri.
✓
✓
Ø
Bayesian
Resp. heuri.
Stim. heuri.
✓
Ø
Ø
20
30
40
1
Behavioural variability (a.u.)
Confidence (a.u.)
–1
0
1
Confidence (a.u.)
–1
0
1
–1
0
10
20
30
20
25
Sensory uncertainty (a.u.)
Confidence (a.u.)
Sensory uncertainty (a.u.)
30
Fig. 2 | Ideal observer predictions. a, Relationship between confidence 
and behavioural variability for a uniform stimulus distribution (orientation 
range, 0–179°). The trials (N = 50,000) were binned into ten equal-sized 
bins of increasing confidence. For each bin, the variance of orientation 
estimation errors was computed and plotted against the mean level of 
confidence in that bin. The lines represent best linear fits. b, Same as  
a, but holding the stimulus constant. Confidence values were z-scored per 
observer such that they fall in the same range for all models. c, Relationship 
between sensory uncertainty and confidence for a uniform stimulus 
distribution (orientation range, 0–179°). For visualization purposes,  
the trials were binned into ten equal-sized bins of increasing uncertainty. 
The means of both confidence and sensory uncertainty were computed 
across all trials in each bin and are shown in the plot. The lines represent 
linear best fits computed on single-trial (unbinned) data. d, Same as  
c, but controlled for stimulus orientation. In a–d, the insets indicate, for 
each model, whether there is a relationship between the plotted variables 
(✓) or not (ø). For ease of exposition, the group mean was added to the 
residuals plotted in b,d.
Nature Human Behaviour | VOL 6 | February 2022 | 294–305 | www.nature.com/nathumbehav
297
Articles
NATUrE HUmAn BEhAvioUr
F(3,93) = 25.94; P < 0.001; R2 = 0.26; 95% CI, (0.12, 0.41); dACC: 
F(3,93) = 27.33; P < 0.001; R2 = 0.25; 95% CI, (0.10, 0.39); rlPFC: 
F(3,90) = 2.88; P = 0.040; R2 = 0.01; 95% CI, (−0.03, 0.05)). It thus 
seems that neural activity in dAI, dACC and rlPFC is affected by 
both the trial-by-trial imprecision in sensory evidence and the level 
of confidence reported by the observers.
Having established that activity in dAI, dACC and rlPFC is mod-
ulated by confidence, we next investigated the hypothesized inverse 
relationship between sensory uncertainty and reported confidence 
on the cortical response in these regions. To illustrate our approach, 
we first focus on a single ROI (dAI; Fig. 4b). We computed, for each 
observer, the trial-by-trial correlation coefficient between decoded 
uncertainty and mean BOLD amplitude within the ROI (after 
removing the effect of stimulus orientation (Methods); see Fig. 4c 
for an example observer), averaged the coefficients across observers 
(Fig. 4d) and repeated the analysis over time (Fig. 4e, left). We also 
performed the same analysis for reported confidence (Fig. 4b–e) 
and for dACC and rlPFC (Fig. 4e). We discovered, in all three ROIs, 
a significant positive relationship between decoded uncertainty and 
cortical activity that was sustained over an extended period (Fig. 4e; 
all P < 0.05, family-wise error rate (FWER) controlled). Critically, 
the effect on the cortical response was reversed for confidence 
(Fig. 4e) and similarly held up over time (all P < 0.05, 
FWER-controlled). Thus, while the cortical response in dAI, dACC 
and rlPFC reliably increased with decoded uncertainty, activity 
in these regions consistently decreased with reported confidence, 
further corroborating the Bayesian confidence hypothesis. These 
effects could not be explained by trial-by-trial fluctuations in the 
participant’s response time (see Extended Data Fig. 7 for control 
analyses). Especially interesting is that (in dACC and dAI) the posi-
tive correlation with uncertainty temporally preceded the negative 
correlation with reported confidence (dAI: t(31) = −3.05; P = 0.005; 
d = −0.54; 95% CI, (−0.90, −0.17); dACC: t(31) = −2.72; P = 0.011; 
d = −0.39; 95% CI, (−0.75, −0.032); rlPFC: t(30) = −1.09; P = 0.29; 
d = −0.20; 95% CI, (−0.57, 0.17)). Factoring in the (approximately 
four-second) haemodynamic delay inherent in the BOLD response, 
the effect of sensory uncertainty seems to be roughly time-locked to 
the presentation (and neural processing) of the stimulus, while the 
correlation with reported confidence coincides with the time when 
participants had to estimate their confidence. These distinct latencies 
further suggest that decoded uncertainty and reported confidence 
exert (partially) independent effects on activity in these regions, 
which was confirmed by a partial correlation analysis (Extended 
Data Fig. 8). Moreover, cortical activity in all three regions was 
additionally found to mediate the trial-by-trial relationship between 
decoded uncertainty and reported confidence (Extended Data 
Fig. 9). This indicates that some of the variance in cortical activity is 
shared between sensory uncertainty and subjective confidence, and 
alludes to a direct functional role of these regions in the computa-
tion of confidence from sensory uncertainty. Taken together, these 
results are consistent with the Bayesian confidence hypothesis and 
suggest that dAI, dACC and rlPFC are involved in the computation 
of confidence from a probabilistic representation of the quality of 
the observer’s sensory evidence.
Discussion
What computations give rise to the subjective sense of confidence? 
Here we tested the Bayesian hypothesis that confidence is com-
puted from a probabilistic representation of information in cortex. 
We first implemented a Bayesian observer model as well as two 
models using alternative strategies for confidence. This resulted in 
a set of predictions that we tested using psychophysics and fMRI. 
Corroborating the Bayesian model, we found that reported confi-
dence reflects behavioural precision, even when stimulus properties 
such as orientation are held constant. Moreover, probability distri-
butions decoded from population activity in visual cortex predict 
60
20
40
Reported confidence (z-score)
Behavioral variability (σ2, °)
Reported confidence (z-score)
Across stimulus orientations
Controlled for stimulus orientation
Reported confidence and behavioural variability
250
300
200
0
200
–2
0
2
–2
0
2
400
0
200
400
Reported confidence (rank)
Decoded uncertainty (rank)
Decoded uncertainty (rank)
Across stimulus orientations
Controlled for stimulus orientation
Reported confidence and decoded uncertainty
Observer S24
Group average
Single observer
Observer S24
Correlation coefficient (ρ)
0
5
10
Probability density
–0.1
0
0.1
0.2
–0.1
0
0.1
0.2
Correlation coefficient (ρ)
Across stimulus orientations
Controlled for stimulus orientation
Reported confidence and decoded uncertainty
All observers
c
b
a
Observer S24
P = 0.063
P = 0.015
P ≈ 0
P ≈ 0
Fig. 3 | Reported confidence, behavioural variability and  
decoded sensory uncertainty. a, Behavioural variability decreases  
as confidence increases (left: t(287) = −16.79; P < 0.001;  
r = −0.70; 95% CI, (−0.73, −0.67); right: t(286) = −11.02;  
P < 0.001; r = −0.55; 95% CI, (−0.62, −0.46)). The shades of blue  
indicate ten within-observer bins of increasing confidence. The dots 
represent single observers (N = 32). For ease of exposition, the group 
mean was added to the plotted residuals. b,c, Decoded sensory 
uncertainty reliably predicts reported confidence. In b, the results  
for an example observer (S24) are shown (left: z = −1.67; P = 0.047; 
ρ = −0.078; 95% CI, (−0.17, 0.014); right: z = −1.52; P = 0.064;  
ρ = −0.071; 95% CI, (−0.16, 0.021)). The analyses were performed  
on trial-by-trial data (N = 493); the data were binned (ten bins)  
for visualization only. The error bars represent ±1 s.e.m. In c, the  
group average (red line; the shaded area represents ±1 s.e.m.),  
probability density and individual correlation coefficients  
(left: z = −2.17; P = 0.015; ρ = −0.018; 95% CI, (0.035, −0.0018);  
right: z = −1.53; P = 0.063; ρ = −0.013; 95% CI, (−0.030, 0.0036))  
are shown. The grey dots indicate observers (N = 32); the circle  
denotes S24.
Nature Human Behaviour | VOL 6 | February 2022 | 294–305 | www.nature.com/nathumbehav
298
Articles
NATUrE HUmAn BEhAvioUr
the level of confidence reported by the participant on a trial-by-trial 
basis. We furthermore identified three downstream regions, dACC, 
dAI and rlPFC, where BOLD activity is linked to both the width of 
the decoded distributions and reported confidence in ways consis-
tent with the Bayesian observer model. Taken together, these find-
ings support recent normative theories and suggest that probabilistic 
information guides the computation of one’s sense of confidence.
Earlier work on statistical confidence has manipulated evidence 
reliability by varying physical properties of the stimulus, such 
as its contrast. This left open the possibility that observers sim-
ply monitor these image features as a proxy for uncertainty7,10–12, 
without considering an internal belief distribution over the latent 
variable. For this reason, we held the stimulus properties constant, 
relied on fluctuations in internal noise and extracted probability 
distributions directly from cortical activity. Our work shows that 
the uncertainty decoded from visual activity predicts the level of 
confidence reported by the observer. No less important, we find 
that downstream regions commonly associated with volatility in the 
environment23,24, decision-making22,31 and confidence25,32,33 repre-
sent trial-by-trial fluctuations in both this decoded uncertainty and 
reported confidence. Altogether, this strongly suggests that a proba-
bilistic representation of information, and not stimulus heuristics or 
point estimates, drives human confidence reports.
While decision confidence is usually studied in the context 
of binary decisions, we here focused on a continuous estimation 
task, which requires observers to reproduce a feature of the stimu-
lus. For binary decisions, confidence is normatively defined as a 
function of the observer’s measurement and decision boundary, 
in addition to sensory uncertainty, and each of these parameters 
can vary on a trial-by-trial basis due to internal noise. For the 
continuous estimation task used here, confidence is more straight-
forwardly defined as a function of sensory uncertainty, without 
dAI
z = 1
L
R
dACC
x = –2
dAI
x = –38
rlPFC
y = 47
rlPFC
z = 34
dACC
3.79
16.64
F value
dAI, observer S24 
t = ~15.75 s
c
b
a
dAI
e
Decoded uncertainty
–0.10
–0.05
0
0.05
Correlation coefficient (ρ)
Reported confidence
dACC
L rlPFC
Time (s)
Time (s)
0
5
10
15
20
0
5
10
15
20
0
5
10
15
20
Time (s)
dAI
–20
–10
0
10
20
BOLD signal (a.u.)
Low confidence
High confidence
Time (s)
Low uncertainty
High uncertainty
–20
–10
0
10
20
BOLD signal (a.u.)
0
–0.2
–0.1
0.1
Correlation coefficient (ρ)
0
5
10
Probability density
0
5
10
15
20
0
200
400
Reported confidence (rank)
200
250
300
BOLD signal (rank)
0
200
400
Decoded uncertainty (rank)
200
250
300
BOLD  signal (rank)
t = ~6.75 s
0
5
10
Probability density
dAI, all observers 
dACC
y = 18
dAI
Group average
Single observer
Observer S24
d
t = ~6.75 s
t = ~15.75 s
P ≈ 0
P ≈ 0
Fig. 4 | Activity in dAI, dACC and left rlPFC over time. a, Downstream clusters significantly modulated by uncertainty decoded from visual cortex (P < 0.05, 
FWER-controlled) (the data were masked to exclude occipital cortex; Supplementary Table 1 gives an overview of all activations, and see Supplementary 
Data for whole-brain maps). b, Cortical response in dAI for high versus low decoded uncertainty (top) and high versus low reported confidence (bottom), 
averaged across all observers. The trials were binned by a median split per observer. The black arrows indicate the data presented in c and d. c, Example 
observer S24. The observer’s cortical response tentatively increases with decoded uncertainty and decreases with reported confidence. The trials (N = 493) 
were binned (ten bins) for visualization only; correlation coefficients were computed from trial-by-trial data. d, Group average (red or blue line) and 
correlation coefficients for individual observers (grey dots; N = 32). Shown is the relationship between cortical response amplitude and decoded uncertainty 
(top) or reported confidence (bottom). Both effects are statistically significant (permutation test; uncertainty: ρ = 0.044, P < 0.001; confidence: ρ = −0.047, 
P < 0.001). e, Group-averaged correlation coefficient between cortical response amplitude and decoded uncertainty (red) or reported confidence (blue). 
The horizontal lines indicate statistical significance (P < 0.05, FWER-controlled). The arrows indicate the data in d. In b,e, the dark grey area marks the 
stimulus presentation window, and the light grey area represents the response window. In b–e, the shaded areas and error bars denote ±1 s.e.m.
Nature Human Behaviour | VOL 6 | February 2022 | 294–305 | www.nature.com/nathumbehav
299
Articles
NATUrE HUmAn BEhAvioUr
many additional parameters. This definition makes this task ide-
ally suited for addressing the probabilistic confidence hypothesis. 
While we specifically focused on uncertainty in continuous esti-
mation, it seems nonetheless likely that the probabilistic nature of 
the representation will extend to binary choices and other deci-
sions of increasing complexity.
Our findings are also important for understanding how uncer-
tainty is represented in cortex. Previous work has shown that the 
width of the decoded probability distribution predicts the magni-
tude of behavioural orientation biases10, serial dependence effects in 
perception34 and classification decisions35. The current work extends 
these earlier findings by linking the decoded distributions directly 
to activity in downstream decision areas and the subjective level of 
confidence reported by the observer. Taken together, these findings 
suggest that probability distributions are not only represented in 
neural population activity but also used in the brain’s computations.
Earlier work has implicated the involvement of the dACC, dAI 
and rlPFC in experimental (objective) manipulations of evidence 
reliability23,33,36–38. Our results suggest that these regions similarly 
track spontaneous (internal) fluctuations in uncertainty and more-
over mediate the link between sensory uncertainty and reported 
confidence, further elucidating their functional role in human 
decision-making. It thus seems that a more general notion of uncer-
tainty is represented in these regions, albeit for different functional 
purposes. While the representation in dACC may serve to inform 
internal models and response selection39–42, it seems likely that dAI 
integrates uncertainty with interoceptive and affective information 
to form a general subjective feeling state22, and rlPFC probably plays 
a key role in the integration of internal uncertainty with contextual 
information to compute confidence32,36,43–45.
While we focused here on the link between subjective confi-
dence and the precision of early sensory evidence in visual areas, 
confidence should additionally reflect uncertainty added by later 
stages of processing—for instance, when the item is held in visual 
working memory before observers make their judgement (although 
the impact of memory imprecision might be relatively small46). 
Indeed, our ideal observer model incorporates these sources of 
variance in its estimates of confidence (equations (1), (8) and (9), 
σ2
n). Given the involvement of early visual areas in visual working 
memory47,48, this predicts that the imprecision in the visual cortical 
representation during the delay period between stimulus presenta-
tion and response should predict the level of confidence reported 
by the observer. Interestingly, additional analysis of the empirical 
data revealed that uncertainty decoded from signals during the 
retention interval indeed reliably predicted subjective levels of 
confidence (Extended Data Fig. 10). Although our design does not 
warrant strong conclusions regarding the nature of these signals 
(see Extended Data Fig. 10 for a discussion), these findings are con-
sistent with a model that considers additional sources of variance 
when judging confidence. Corroborating this interpretation, a very 
recent study used our probabilistic decoding techniques and found 
that decoded uncertainty predicted the observer’s judgements of 
uncertainty in a visual working memory task49. It will be interest-
ing for future work to further disentangle these and other sources 
of noise that affect the observer’s decisions and associated levels 
of confidence.
In conclusion, we showed that behavioural confidence tracks 
the degree of uncertainty contained in neural population activity in 
visual cortex, suggesting that human observers have access to and 
can report about the degree of imprecision in their visual cortical 
representations of the stimulus. Furthermore, activity in the dACC, 
dAI and rlPFC is modulated by both this uncertainty and reported 
confidence in ways predicted by the Bayesian model, suggesting 
that these regions are involved in the computation of confidence 
from sensory uncertainty. Taken together, our results support recent 
normative theories of confidence and suggest that the subjective 
feeling of confidence is based on a statistical measure of the quality 
of one’s evidence.
Methods
Participants. Thirty-two healthy adult volunteers (age range 19–31, 20 female,  
12 male) with normal or corrected-to-normal vision participated in this study.  
The sample size (N = 32) was based on a power calculation (power = 0.8; α = 0.05). 
All participants gave informed written consent prior to their participation and 
received monetary compensation (eight and ten euros per hour for the behavioural 
and fMRI sessions, respectively). The study was approved by the local ethics 
committee (CMO Arnhem-Nijmegen, the Netherlands). Participants were included 
on the basis of their ability to perform the task, which was assessed in a separate 
behavioural training session before the experimental sessions.
Imaging data acquisition. The MRI data were acquired on a Siemens 3T 
MAGNETOM PrismaFit scanner at the Donders Center for Cognitive Neuroimaging, 
using a 32-channel head coil. For anatomical reference, a high-resolution T1-weighted 
image was collected at the start of each session (3D MPRAGE; repetition time (TR), 
2,300 ms; inversion time (TI), 1,100 ms; echo time (TE), 3 ms; flip angle, 8 degrees; 
field of view (FOV), 256 mm × 256 mm; 192 sagittal slices; 1-mm isotropic voxels). 
B0 field inhomogeneity maps (TR, 653 ms; TE, 4.92 ms; flip angle, 60 degrees; 
FOV, 256 mm × 256 mm; 68 transversal slices; 2-mm isotropic voxels; interleaved 
slice acquisition) were acquired. Functional data were acquired using a multi-band 
accelerated gradient-echo EPI protocol, in 68 transversal slices covering the whole 
brain (TR, 1,500 ms; TE, 38.60 ms; flip angle, 75 degrees; FOV, 210 mm × 210 mm; 
2-mm isotropic voxels; multiband acceleration factor, 4; interleaved slice acquisition).
Experimental design and stimuli. The participants performed an orientation 
estimation task while their cortical activity was measured with fMRI. They 
completed a total of 22–26 task runs, divided over two scan sessions on separate 
days. Prior to the experimental sessions, the participants extensively practised the 
task (two to four hours) in a separate behavioural session.
Throughout each task run, the participants fixated a bull’s-eye target (radius, 
0.375 degrees) presented at the centre of the screen. Each run consisted of 20 
trials (16.5 s each), separated by an intertrial interval of 1.5 s, and started and 
ended with a fixation period (duration at the start, 4.5 s; at the end, 15 s). Each 
trial started with the presentation of the orientation stimulus, which remained 
on the screen for 1.5 s. This was followed by a 6-s fixation interval and then 
two successive 4.5-s response windows (Extended Data Fig. 1). The orientation 
stimuli were counterphasing sinusoidal gratings (contrast, 10%; spatial 
frequency, one cycle per degree; randomized spatial phase; 2-Hz sinusoidal 
contrast modulation) presented in an annulus around fixation (inner radius, 
1.5 degrees; outer radius, 7.5 degrees; grating contrast decreased linearly to 0 
over the inner and outer 0.5 degrees of the radius of the annulus). The stimulus 
orientations were drawn (pseudo)randomly from a uniform distribution 
covering the full orientation space (0–179 degrees) to ensure an approximately 
even sampling of orientations within each run. At the start of the first response 
window, a black bar (length, 2.8 degrees; width, 0.1 degrees; contrast, 40%) 
appeared at the centre of the screen at an initially random orientation. The 
participants reported the orientation of the previously seen grating by rotating 
this bar, using separate buttons for clockwise and counterclockwise rotation on 
an MRI-compatible button box. At the start of the second response window, 
a black bar of increasing width (contrast, 40%; bar width, 0.1–0.5 degrees, 
linearly increasing) and wrapped around fixation (radius, 1.4 degrees) became 
visible at the centre of the screen. The participants indicated their confidence 
in their orientation judgement by moving a white dot (contrast, 40%; radius, 
0.05 degrees) on this continuous confidence scale, using the same buttons for 
clockwise and counterclockwise as for their orientation response. The mapping 
of confidence level to scale width (that is, whether the narrow end of the scale 
indicated high or low confidence) was counterbalanced across participants. 
The scale’s orientation and direction (that is, width increasing in a clockwise 
or counterclockwise direction), as well as the starting position of the dot, were 
randomized across trials. For both response windows, the bar (scale) disappeared 
gradually over the last 1 s of the response window to indicate the approaching 
end of this window. Shortly before trial onset (0.5 s), the fixation bull’s-eye 
briefly turned black (duration, 0.1 s) to indicate the start of the trial. Because 
we were interested in the effects of sensory uncertainty on cortical activity and 
confidence, rather than the cortical representation of confidence per se, and 
because reward-related signals might contaminate the representation of sensory 
information in visual areas50, the participants received no trial-by-trial feedback 
about the accuracy of their judgements.
Each scan session also included one or two functional localizer runs,  
during which flickering checkerboard stimuli were presented in seven 12-s  
blocks interleaved with fixation blocks of equal duration. The checkerboard  
stimuli were presented within the same aperture as the grating stimuli (contrast, 
100%; flicker frequency, 10 Hz; check size, 0.5 degrees). Retinotopic maps of the 
visual cortex were acquired in a separate scan session using standard retinotopic 
mapping procedures51–53.
Nature Human Behaviour | VOL 6 | February 2022 | 294–305 | www.nature.com/nathumbehav
300
Articles
NATUrE HUmAn BEhAvioUr
All visual stimuli were generated on a Macbook Pro computer using MATLAB 
and the Psychophysics Toolbox54 and were presented on a rear-projection screen 
using a luminance-calibrated EIKI LC-XL100 projector (screen resolution, 
1,024 × 768 pixels; refresh rate, 60 Hz). The participants viewed the screen through 
a mirror mounted on the head coil.
Behavioural data analysis. In general, the participants finished adjusting their 
orientation and confidence responses well before the end of the response windows 
(4.5 s each), taking on average 2,761 ± 378 ms (mean ± s.d. across observers) for 
the orientation response and 2,587 ± 313 ms for the confidence response. Trials 
on which participants did not finish their response by the end of the response 
window were excluded from further analyses (0–43 of 440–520 trials). The error in 
the observer’s behavioural orientation response was computed as the acute-angle 
difference between the reported and the presented orientation on a given trial. 
Orientation-dependent shifts (biases) in mean behavioural error were removed 
by fitting two fourth-degree polynomials to each observer’s behavioural errors 
as a function of stimulus orientation (see ref. 10 for a similar procedure). One 
polynomial was fit to trials for which the presented stimulus orientation was 
between 90 and 179 degrees, and the second polynomial was fit to trials on which 
the presented stimulus orientation was between 0 and 89 degrees. We used the 
bias-corrected behavioural errors (that is, the residuals of this fit) in subsequent 
analyses. Behavioural errors that were more than three standard deviations away 
from the mean of each participant (after bias correction) were marked as guesses 
and excluded from further analysis (1–7 of 440–520 trials). To remove potential 
session-specific and participant-specific differences in usage of the confidence 
scale, confidence ratings were z-scored within sessions.
Preprocessing of MRI data. The raw functional imaging data were 
motion-corrected with respect to the middle volume of the middle run of the 
session, using FSL’s MCFLIRT55. The functional data were corrected for distortion 
using the within-session B0 field map and aligned to the T1-weighted image 
obtained during the same scan session. This anatomical (T1-weighted) image was 
aligned with a participant-specific unbiased template image, created by combining 
the T1-weighted images from the two sessions, using Freesurfer’s mri_robust_
template56. Slow drifts in the BOLD signal were removed using FSL’s nonlinear 
high-pass temporal filter with a sigma of 24 TRs (two trials), corresponding to a 
cut-off period of approximately 83 s.
For all univariate analyses, additional preprocessing steps were performed 
before high-pass filtering. Specifically, non-brain structures were removed using 
FSL’s BET57, and the data were spatially smoothed with a 6-mm Gaussian kernel 
using FSL’s SUSAN58. As the univariate analyses required combining data across 
participants, each participant’s anatomical template image was nonlinearly 
registered to MNI152 space using FSL’s FNIRT with a warp resolution of 10 mm 
isotropic59.
A set of nuisance regressors was used to remove residual motion effects and 
global fluctuations in the BOLD signal. Per session, we defined an intercept 
regressor per run, 24 motion regressors based on the motion parameters estimated 
by MCFLIRT (all analyses) and two regressors reflecting the average signal in 
cerebrospinal fluid (CSF) and white matter (WM) (univariate analyses only). The 
CSF and WM regressors served to capture global fluctuations in signal intensity 
and were obtained by first creating WM and CSF masks based on the participant’s 
anatomical scan data using FSL’s FAST60, and then removing the outer edges from 
these masks to exclude voxels at the tissue boundaries. For the multivariate and 
ROI-based univariate analyses, nuisance signals were removed from the BOLD 
signal prior to further analyses. For the whole-brain univariate analysis, motion, 
CSF/WM and intercept regressors were included as covariates in the GLM 
(‘Whole-brain analysis’).
For the multivariate analyses, the ROI (consisting of V1, V2 and V3) was 
identified on the reconstructed cortical surface. Within this ROI, and in the native 
space of each participant, we selected for further analysis the 2,000 voxels that 
were activated most strongly by the functional localizer stimulus while surviving a 
lenient statistical threshold (P < 0.01, uncorrected). Control analyses verified that 
our results were not strongly affected by the number of voxels selected for analysis 
(Extended Data Fig. 4). The time series of each selected voxel was subsequently 
z-normalized with respect to corresponding trial time points in the same run. 
Activation patterns for each trial were obtained by averaging over the first 3 s of 
each trial, after adding a 4.5-s temporal shift to account for haemodynamic delay. 
This relatively short time window was chosen to ensure that activity from the 
behavioural response window was excluded from analysis. For the control analyses 
in Extended Data Fig. 5, mean BOLD intensity values were calculated by averaging 
the z-normalized activation values across the selected voxels and time window. The 
results in Extended Data Fig. 10 were obtained using a sliding window of size 3 s 
(two TRs), chosen to match the window size of the main analysis. For each window 
of analysis, the z-normalized activation values were averaged and subsequently fed 
to the decoding algorithm.
Multivariate analysis (visual cortex). Decoding algorithm. Trial-by-trial 
uncertainty in cortical stimulus representations was computed using a generative 
model-based, probabilistic decoding algorithm10,18, applied to selected voxels 
in visual cortex (see the previous section for the voxel selection criteria). The 
model describes the generative distribution of the voxel activity patterns given a 
certain stimulus, p(b|s)—in other words, the probability that stimulus s will evoke 
activation pattern b. The model assumes that, across trials, voxel activity follows a 
multivariate normal distribution around the voxel’s tuning curve for orientation. 
Voxel tuning curves are defined as a linear combination Wf(s) of eight bell-shaped 
basis functions, each centred on a different orientation61:
fk (s) = max [0, cos (2π s−φk
180
)]5
(4)
where s is the orientation of the presented stimulus and φk is the preferred 
orientation of the kth population. The basis functions were spaced equally across 
the full orientation space (0–179 degrees) with the first centred at zero degrees.  
Wik is the contribution of the kth basis function to the response of the ith voxel.
The covariance around the voxel tuning curves is described by the noise 
covariance matrix Ω:
Ω= ρττT + (1 −ρ) I ◦ττT + σ2WWT
(5)
The first term of this covariance matrix describes noise shared globally between 
all voxels in the ROI, and the second term refers to noise specific to individual 
voxels (with variance τ2
i for voxel i). The relative contribution of each of these types 
of noise is reflected in ρ. The third term models tuning-dependent noise—that is, 
noise (with variance σ2) shared between voxels with similar orientation preference.
The generative distribution of voxel responses is thus given by a multivariate 
normal distribution with mean Wf(s) and covariance Ω:
p (b|s;θ) = N (Wf (s) , Ω)
(6)
where θ = {W,τ,ρ,σ} are the model’s parameters. The model’s parameters were 
estimated in a two-step procedure (see ref. 10 for further details). First, the tuning 
weights W were estimated by ordinary least squares regression. Second, the  
noise covariance parameters (ρ,σ,τ) were estimated by numerical maximization  
of their likelihood.
Model training and testing (‘decoding’) was performed following a 
leave-one-run-out cross-validation procedure to prevent double-dipping29. That 
is, the model parameters were first fit to a training dataset consisting of all but one 
fMRI run, and the model was then tested on the data from the remaining run. This 
procedure was repeated until all runs had served as a test set once.
Using the fitted parameters, a posterior distribution over stimulus orientation 
was computed for each trial in the test set. The posterior distribution is given by 
Bayes’s rule:
p
(
s|b;ˆθ
)
=
p(b|s;ˆθ)p(s)
∫p(b|s;ˆθ)p(s)ds
(7)
where ˆθ are the estimated model parameters. The stimulus prior p(s) was flat, given 
that the stimuli presented in the experiment were uniformly distributed, and the 
normalizing constant in the denominator was calculated numerically. The circular 
mean of the posterior distribution was taken as the estimate of the presented 
orientation on that test trial, and the squared circular standard deviation was used 
as a measure of the amount of uncertainty in this estimate.
Statistical procedures. Most of our analyses relied on the computation of a 
correlation coefficient between two variables. These coefficients were calculated for 
each individual participant and then averaged across observers (see below). On the 
basis of the assumed relationship between the two variables (linear or monotonic), 
either Pearson’s or Spearman’s (rank) correlation coefficient was computed. For 
the analyses using Pearson’s correlation coefficient (Fig. 3a and Extended Data Fig. 
2c,d), the data were visually inspected and appeared to be normally distributed, 
although this was not formally tested. Decoding accuracy was quantified by 
computing the circular analogue of the Pearson correlation coefficient between 
the presented and decoded stimulus orientations. To test for an oblique effect in 
decoded uncertainty, we first calculated for each presented stimulus orientation 
its distance to the nearest cardinal (that is, horizontal or vertical) orientation and 
then computed the Spearman correlation coefficient between this measure and 
decoded uncertainty. To test the relationship between reported confidence and 
decoded uncertainty (independent of stimulus orientation), we first removed 
orientation-dependent shifts in decoded uncertainty and confidence by modelling 
confidence (decoded uncertainty) as a quadratic (linear) function of distance to 
cardinal (see Extended Data Fig. 3 for the fitted functions); the rank correlation 
coefficient between confidence and decoded uncertainty was subsequently 
computed on the residuals of these fitted functions. After we obtained correlation 
coefficients for each individual observer i, the coefficients were Fisher transformed, 
and a weighted average was computed across observers. Specifically, the weight of 
the ith correlation coefficient was calculated as wi = 1/vi, where vi is the variance 
of the Fisher-transformed correlation coefficient62. For the Pearson correlation, 
vi is given by 1/(ni − 3) (where ni is the number of trials), and for the Spearman 
correlation, vi = 1.06/(ni  −3) (ref. 63). Weights were adjusted for the additional 
degrees of freedom lost due to stepwise correction for the oblique effect in decoded 
Nature Human Behaviour | VOL 6 | February 2022 | 294–305 | www.nature.com/nathumbehav
301
Articles
NATUrE HUmAn BEhAvioUr
uncertainty or reported confidence by subtracting 1 (for linear correction) or 2  
(for quadratic correction) from the denominator in the variance term. The 
significance of the coefficients was assessed using a Z-test, testing specifically for 
effects in the direction predicted by the ideal observer models. The average of the 
Z-transformed values was translated back to the correlation scale for reporting 
purposes. To compare correlation coefficients between confidence and decoded 
uncertainty with and without correction for stimulus orientation, we computed 
Cohen’s q and used a Z-test to assess statistical significance. Similar procedures 
were used for the control analyses in Extended Data Fig. 5. For these control 
analyses, we additionally performed equivalence tests (using the two one-sided 
tests procedure64), comparing against a smallest effect size of interest of ρ = 0.1  
(see ref. 65 for further rationale).
Some of our analyses required the computation of a dispersion measure (that is, 
behavioural variability). For these analyses, each participant’s data were first divided 
into ten equal-sized bins, on the basis of either the reported level of confidence or 
decoded uncertainty, and summary statistics were computed across all trials in a 
given bin. Behavioural variability was computed as the squared circular standard 
deviation of (bias-corrected) estimation errors across all trials in each bin, and the 
average level of confidence or decoded uncertainty was quantified by computing 
the statistical mean. To test the relationship between behavioural variability and 
confidence (or decoded uncertainty), we used a multiple linear regression analysis. 
The independent variables were the level of confidence (or decoded uncertainty) 
and the absolute distance between the stimulus and the nearest cardinal axis (mean 
across trials in each bin). We also included participant-specific intercepts. The 
dependent variable was behavioural variability. Partial correlation coefficients were 
computed from the binned data, and significance was assessed using t-tests, testing 
for effects in the direction predicted by the ideal observer models. Control analyses 
verified that our results did not strongly depend on the number of used bins or on 
the specific shape of the function used to model the effect of stimulus orientation 
on confidence (or decoded uncertainty).
Univariate analyses (whole-brain and ROI-based). Whole-brain analysis. 
To identify brain regions that are modulated by sensory uncertainty, we used 
a whole-brain GLM approach. A GLM can be written as y = Xβ + ε, where y 
represents the time series of a single voxel, X is referred to as the design matrix (or 
model), β is a vector of model parameters and ε represents the residuals.
We constructed a model of task-related activity based on three components: 
(1) a 1.5-s boxcar function time-locked to the stimulus onsets of all excluded trials, 
with height one; (2) a 1.5-s boxcar function time-locked to the stimulus onsets of all 
included trials, with height one; and (3) a 1.5-s boxcar function time-locked to the 
stimulus onsets of all included trials, with its height equal to the decoded uncertainty 
on that trial (linearly corrected for trial-by-trial differences in stimulus orientation; 
‘Multivariate analysis (visual cortex)’). Each boxcar function was convolved with a 
canonical haemodynamic response function and temporal and dispersion derivatives 
of the haemodynamic response function (SPM’s informed basis set), yielding a total 
of nine regressors to include in the design matrix. The derivatives were added for 
additional model flexibility regarding the shape and latency of the BOLD response. 
In addition to the task-related regressors, we included nuisance regressors (24 
motion regressors and 2 CSF/WM regressors per session) and run-specific intercepts 
(‘Preprocessing of MRI data’) to improve the overall model fit.
The model X was fit to each participant’s time series, separately for each voxel, 
to obtain a set of parameter estimates ˆβ. Participant-level analyses were performed 
using SPM12, because of its increased efficiency (relative to FSL) when performing 
the GLM analysis on concatenated data rather than individual runs. The resulting 
participant-level ˆβ maps were then transformed from participant-specific to 
standard space (MNI152) to allow for comparison and combination of estimates 
across participants. We were specifically interested in the effect of decoded 
uncertainty on the BOLD response, which was modelled by the three regressors 
corresponding to the third boxcar function. The combined explanatory power 
of the three regressors was quantified by computing an F statistic over the 
corresponding β estimates (across participants). To calculate P values, a sign-flip 
test (5,000 permutations) was performed in combination with threshold-free 
cluster enhancement (TFCE)66, using FSL’s randomise67. The FWER was controlled 
by comparing the true voxel-wise TFCE scores against the null distribution of the 
maximum TFCE score across voxels66,68.
ROI analysis. Brain regions modulated by perceptual uncertainty were selected and 
further investigated as follows. ROIs were defined using existing anatomical atlases, 
combined with a functional parcellation based on the whole-brain GLM analysis 
(as described in more detail above). Specifically, within a given (anatomical) ROI, 
we selected voxels modulated by decoded uncertainty using the GLM analysis, 
while applying a leave-one-participant-out procedure30 to avoid double-dipping29. 
This led to the definition of eight ROIs for each participant individually: (1) dAI 
(using the functional parcellation by Chang et al.26, mirrored to obtain bilateral 
labels, retrieved from Neurovault: https://identifiers.org/neurovault.collection:13), 
(2) left rlPFC (frontal pole label, Harvard–Oxford cortical atlas28, trimmed to 
include the left hemisphere only), (3) dACC (bilateral RCZa and RCZp labels, 
Neubert cingulate orbitofrontal connectivity-based parcellation27), (4) precuneus 
(precuneus label, Harvard–Oxford cortical atlas28), (5) supplementary motor area 
(SMA label, Sallet dorsal frontal connectivity-based parcellation69, mirrored to 
obtain bilateral labels), (6) dorsal perigenual anterior cingulate cortex (bilateral 
area 32d, Neubert cingulate orbitofrontal connectivity-based parcellation27),  
(7) ventral posterior cingulate cortex (bilateral area 23ab labels, Neubert cingulate 
orbitofrontal connectivity-based parcellation27) and (8) dorsal posterior cingulate 
cortex (bilateral CCZ labels, Neubert cingulate orbitofrontal connectivity-based 
parcellation27). For ROIs 2 and 8, some of the leave-one-out, GLM-based masks 
did not contain any voxels. The corresponding data were excluded from further 
analyses for the respective ROIs (for ROI 2, one participant; for ROI 8, two 
participants). The BOLD signal was averaged over all voxels within a given ROI.
Having defined our ROIs, we then proceeded to investigate the effects of 
confidence in these regions. We did this in two different analyses. To assess the 
degree to which confidence modulated the BOLD response in each ROI, we 
performed a GLM analysis. The model structure was similar to the whole-brain 
univariate analysis, including three 1.5-s boxcar functions time-locked to 
stimulus onset: one for excluded trials (height one), one for included trials (height 
one) and one to model the effect of confidence (included trials only; height 
equal to confidence value on that trial, quadratically corrected for trial-by-trial 
differences in stimulus orientation; ‘Multivariate analysis (visual cortex)’). These 
boxcar functions were each convolved with SPM’s informed basis set (canonical 
haemodynamic response function and its temporal and dispersion derivatives)  
and nuisance regressors (24 motion and 2 CSF/WM regressors per session).  
Run intercepts were also added.
To further investigate the magnitude and directionality of the effects of 
reported confidence and decoded uncertainty over the course of a trial (without 
a priori assumptions regarding the shape or timing of the BOLD response), we 
also performed a trial-by-trial correlation analysis. Specifically, we computed 
the Spearman correlation coefficient between BOLD intensity and decoded 
uncertainty or reported confidence for each TR in the trial. Orientation-dependent 
changes in decoded uncertainty and confidence were first removed by modelling 
confidence (decoded uncertainty) as a quadratic (linear) function of distance to 
cardinal (‘Multivariate analysis (visual cortex)’), and the correlation coefficient 
was computed using the residuals of this fit. For the control analyses presented 
in Extended Data Fig. 7, response time effects in the BOLD signal were removed 
by modelling BOLD intensity at each time point (relative to stimulus onset) as a 
linear function of the time it took for the observer to (1) respond to the presented 
orientation and (2) report confidence on that trial, and the correlation coefficient 
between BOLD intensity and decoded uncertainty or confidence was computed on 
the residuals of this fit. For the partial correlation analyses reported in Extended 
Data Fig. 8, both reported confidence (or decoded uncertainty) and BOLD intensity 
at each time point were modelled as linear functions of uncertainty (or confidence). 
The residuals of these fits were used to compute the (Spearman) correlation 
coefficient between confidence (or uncertainty) and the BOLD signal for each time 
point. The single-participant correlation coefficients were Fisher transformed, and 
a weighted average was computed across observers (‘Multivariate analysis (visual 
cortex)’). Statistical significance was assessed using two-tailed permutation tests, 
in which uncertainty (or confidence) values were permuted across trials (1,000 
permutations). To control for multiple comparisons (FWER), we compared against 
the null distribution of the maximum correlation coefficient across time points 
(‘Whole-brain analysis’). Finally, we tested whether there was a significant difference 
in latency between the effects of confidence and uncertainty on the BOLD signal 
in each ROI. To this end, we determined, for each participant individually, the 
(within-trial) time point at which the correlation coefficient between BOLD and 
uncertainty (confidence) was most strongly positive (negative). We then performed 
a paired t-test on these values, comparing between uncertainty and confidence.
To investigate whether activity in downstream areas mediates the relationship 
between decoded uncertainty and reported confidence, we performed the 
following analysis. We first modelled both confidence and uncertainty as linear 
functions of the BOLD signal in a given ROI and at a given (within-trial) time 
point. We then took the residuals of these model fits and computed the Spearman 
correlation coefficient between the (residual) uncertainty and confidence values. If 
the selected ROIs mediate the relationship between uncertainty and confidence, the 
residual correlation coefficient should be smaller in magnitude than the baseline 
correlation coefficient between uncertainty and confidence (that is, not controlled 
for activity in downstream areas; as reported in Fig. 3c). To quantify the mediating 
effect of the BOLD signal in each ROI at each time point, the single-participant 
correlation coefficients were Fisher transformed, and we subtracted from 
these values the (Fisher-transformed) baseline correlation coefficient between 
uncertainty and confidence. Finally, a weighted average was computed across 
observers (‘Multivariate analysis (visual cortex)’). Statistical significance of the 
predicted reduction in correlation strength was assessed using a permutation test, 
in which BOLD values were permuted across all trials (following otherwise similar 
procedures as for the whole-brain and main ROI-based analyses).
Eye tracking data. Eye tracking data were acquired using an SR Research Eyelink 
1000 system for 62 of 64 sessions. For 11 of these sessions, data were collected for 
4–12 runs (of a total of 10–13) due to technical difficulties with the eye-tracking 
system. Gaze position was sampled at 1 kHz. Blinks and saccades were identified 
using the Eyelink software and removed. Eye fixations shorter than 100 ms in 
Nature Human Behaviour | VOL 6 | February 2022 | 294–305 | www.nature.com/nathumbehav
302
Articles
NATUrE HUmAn BEhAvioUr
duration were similarly identified and removed. Any blinks of duration >1,000 ms 
were considered to be artifacts and removed. For some trials, the quality of the 
eye tracking data was insufficient (as indicated by a high proportion of missing 
data points). This was identified by computing the percentage of missing (gaze) 
data points in a time window starting 4.5 s before stimulus onset and ending 
4.5 s after stimulus offset, but excluding the stimulus window itself. Trials were 
excluded from further analysis if the percentage of missing data points within 
this pre- and post-stimulus window exceeded 50%. On the basis of this criterion, 
3.84 ± 1.69% (mean ± s.d.) of trials were excluded from further analysis. The data 
were band-pass filtered using upper and lower period cut-offs of 36 s and 100 ms, 
respectively. The median gaze position per run was computed and subtracted from 
all data points within that run. All measures of interest were computed during 
stimulus presentation only—that is, over the first 1.5 s of each trial. Mean eye 
position was obtained by first computing the mean x and y coordinates of the gaze 
data and then taking the absolute distance from this position to the central fixation 
target. The proportion of blinks was computed as the fraction of time labelled as 
blinks; this included saccades immediately preceding or following a blink. A break 
from fixation occurred when the absolute distance between gaze position and the 
central fixation target was more than 1.5 degrees of visual angle. The proportion of 
fixation breaks was computed as the fraction of time labelled as such.
Ideal observer models. Model description. We implemented three different 
observer models, which make identical decisions but differ in how they compute 
confidence from internal signals. Model 1 takes a statistical approach and computes 
confidence from the degree of imprecision in the orientation judgement. Models 
2 and 3 use heuristic strategies: model 2 uses features of the stimulus as a cue to 
confidence, and model 3 bases confidence on the magnitude of the observed error 
in the response. We call these the Bayesian, Stimulus heuristics and Response 
heuristics observers, respectively (see also Fig. 1).
The observer’s task is to infer the stimulus from incoming sensory signals. 
These signals are noisy, so that there is no one-to-one mapping between a given 
stimulus s and its measurement m. Rather, the relationship between stimulus and 
measurements is described by a probability distribution p(m|s). We assume that 
across trials, the sensory measurements follow a (circular) Gaussian distribution 
centred on the true stimulus s, with variance σ2
m (s):
p (m|s) = 1
Z exp
(
−
1
2σ2
m(s) angle (m, s)2)
(8)
where Z is a normalization constant.
We make a distinction between three sources of measurement noise: 
stimulus-dependent sensory noise (σ2
so), stimulus-independent sensory noise (σ2
si) 
and non-sensory (downstream) noise (σ2
n). The total amount of measurement 
noise equals the sum of the three noise components:
σ2
m (s) = σ2
so (s) + σ2
si + σ2
n
(9)
The stimulus-dependent component, σ2
so, represents Gaussian noise that 
varies in magnitude as a function of stimulus orientation. Specifically, human 
behavioural orientation judgements tend to be more precise for cardinal than 
oblique orientations19,70, and we model this oblique effect in orientation perception 
as a rectified sine function20:
σ2
so (s) = a ×
sin s 2π
180

(10)
where a is the amplitude of the oblique effect. The stimulus-independent 
component, σ2
si, models any remaining sources of (Gaussian) sensory noise. Its 
magnitude varies randomly over trials, and we model the across-trial distribution 
of σ2
si as a gamma distribution:
σ2
si ∼Γ (α, β)
(11)
where α represents the shape parameter and β represents the rate parameter. 
Finally, the non-sensory (downstream) noise component, σ2
n, is of constant 
magnitude and captures (Gaussian) noise that arises beyond the initial stages of 
sensory processing but prior to the decision—for example, when the item is held in 
working memory or in processing steps downstream of sensory areas V1–V3.
To infer which stimulus probably caused their sensory measurement, the 
observers use full knowledge of the generative model. Specifically, each observer 
inverts the generative model using Bayes’s rule. Assuming a flat stimulus prior, the 
posterior distribution is proportional to the likelihood function:
p (s|m) ∝p (m|s)
(12)
All three observer models take the mean of the posterior distribution as 
their internal sensory estimate ˆs of the presented stimulus. This is the optimal 
solution for a squared-error loss function71. The observer’s internal estimate of 
orientation is subsequently translated into an overt behavioural (motor) response 
r. The transformation from internal estimate into a motor response is noisy. The 
behavioural response r for the observer models is thus given by:
r = ˆs + εr
(13)
where εr is a zero-mean (circular) Gaussian noise variable with variance σ2
r.
The three model observers differ in how they compute confidence. The 
Bayesian observer computes confidence as a function of the expected response 
error. Specifically, this observer assumes a (circular) squared-error loss function 
and computes confidence as the inverse of the expected loss (equation (1)).
Replacing this direct mapping with any other monotonically decreasing function 
does not qualitatively change any of the predictions for this model. Thus, for 
the Bayesian observer, confidence is based (in part) on the posterior probability 
distribution over the stimulus.
The Stimulus heuristics observer uses the estimated orientation of the stimulus 
as a cue to uncertainty and confidence. That is, this observer knows that behaviour 
tends to be more precise for cardinal than oblique orientations, and simply exploits 
this knowledge in their confidence judgements (equation (2)).The function f (ˆs) 
takes the shape of the oblique effect (equation (10)):
f (ˆs) = a ×
sinˆs 2π
180
 + E σ2
si

(14)
The Response heuristics observer bases confidence on the observed error in the 
motor response. Specifically, the observer simply notices the difference between 
the overt response r and internal estimate ˆs and adjusts confidence accordingly. 
We quantified confidence for this model observer as the inverse of the squared 
acute-angle distance between the internal orientation estimate and the external 
response (equation (3)).
Simulations. We simulated 50,000 trials for each of the three model observers.  
The stimulus orientations were drawn from a uniform distribution on the interval 
[0–179°]. Sensory measurements were randomly sampled from the generative 
model as described above (equations (8)–(11)), with a = 20, σ2
n = 5, α = 10 and 
β = 1. The normalization constant Z was computed numerically.
Probabilistic inference proceeded with full knowledge of the parameter values 
and according to equation (12). Behavioural responses were obtained using 
equation (13) and with σ2
r = 5. Confidence judgements were obtained using 
equations (1)–(3) and (14). To obtain a reasonable range of confidence values,  
a constant (of value 1) was added to the denominator of equation (3). Confidence 
ratings were z-scored per observer to ensure that they would all fall on the same 
scale. Sensory uncertainty was quantified as:
σ2
s = σ2
si + σ2
so
(15)
The data were preprocessed following the procedures described in ‘Behavioural 
data analysis’. Similar to the empirical analyses, orientation-dependent shifts 
in confidence judgements, behavioural variability or sensory uncertainty were 
removed. For data visualization, the simulated data were divided over ten 
equal-sized bins of increasing confidence (Fig. 2a,b) or sensory uncertainty  
(Fig. 2c,d), and the mean confidence level, variance of behavioural errors  
(Fig. 2a,b) and mean level of sensory uncertainty (Fig. 2c,d) were computed  
across all trials in each bin.
Citation diversity. We quantified the gender balance of works cited in the main 
text of this paper (N = 45, excluding self-citations) by manual gender classification 
of the first and last authors. Among the cited works, there are 4.4% single-author 
male, 73.3% male–male, 2.2% male–female, 15.6% female–male and 4.4% female–
female publications. The expected proportions computed from publications in 
five top neuroscience journals (as reported in ref. 72) are 55.3% male–male, 10.2% 
male–female, 26.2% female–male and 8.3% female–female.
Reporting Summary. Further information on research design is available in the 
Nature Research Reporting Summary linked to this article.
Data availability
The preprocessed behavioural and fMRI data for individual participants, as well 
as unthresholded statistical maps from the whole-brain univariate analysis, can 
be downloaded from https://doi.org/10.34973/983b-a047. To protect participant 
privacy, the raw data are available from the corresponding author upon request. 
Source data are provided with this paper.
Code availability
All custom code is available from the corresponding author upon request. Custom 
code for the probabilistic decoding technique can also be found at https://github.
com/jeheelab/.
Received: 1 May 2021; Accepted: 2 November 2021;  
Published online: 20 January 2022
References
	1.	 Pouget, A., Drugowitsch, J. & Kepecs, A. Confidence and certainty:  
distinct probabilistic quantities for different goals. Nat. Neurosci. 19,  
366–374 (2016).
Nature Human Behaviour | VOL 6 | February 2022 | 294–305 | www.nature.com/nathumbehav
303
Articles
NATUrE HUmAn BEhAvioUr
	2.	 Meyniel, F., Sigman, M. & Mainen, Z. F. Confidence as Bayesian probability: 
from neural origins to behavior. Neuron 88, 78–92 (2015).
	3.	 Hangya, B., Sanders, J. I. & Kepecs, A. A mathematical framework for 
statistical decision confidence. Neural Comput. 28, 1840–1858 (2016).
	4.	 Mamassian, P. Visual confidence. Annu. Rev. Vis. Sci. 2, 459–481 (2016).
	5.	 Kepecs, A. & Mainen, Z. F. A computational framework for the study  
of confidence in humans and animals. Phil. Trans. R. Soc. B 367,  
1322–1337 (2012).
	6.	 Sanders, J. I., Hangya, B. & Kepecs, A. Signatures of a statistical computation 
in the human sense of confidence. Neuron 90, 499–506 (2016).
	7.	 Barthelmé, S. & Mamassian, P. Flexible mechanisms underlie the evaluation 
of visual confidence. Proc. Natl Acad. Sci. USA 107, 20834–20839 (2010).
	8.	 Adler, W. T. & Ma, W. J. Comparing Bayesian and non-Bayesian accounts of 
human confidence reports. PLoS Comput. Biol. 14, e1006572 (2018).
	9.	 Denison, R. N., Adler, W. T., Carrasco, M. & Ma, W. J. Humans incorporate 
attention-dependent uncertainty into perceptual decisions and confidence. 
Proc. Natl Acad. Sci. USA 115, 11090–11095 (2018).
	10.	van Bergen, R. S., Ji Ma, W., Pratte, M. S. & Jehee, J. F. M. Sensory 
uncertainty decoded from visual cortex predicts behavior. Nat. Neurosci. 18, 
1728–1730 (2015).
	11.	Navajas, J. et al. The idiosyncratic nature of confidence. Nat. Hum. Behav. 1, 
810–818 (2017).
	12.	Bertana, A., Chetverikov, A., van Bergen, R. S., Ling, S. & Jehee, J. F. M. Dual 
strategies in human confidence judgments. J. Vis. 21, 21 (2021).
	13.	Honig, M., Ma, W. J. & Fougnie, D. Humans incorporate trial-to-trial 
working memory uncertainty into rewarded decisions. Proc. Natl Acad.  
Sci. USA 117, 8391–8397 (2020).
	14.	Kepecs, A., Uchida, N., Zariwala, H. A. & Mainen, Z. F. Neural correlates, 
computation and behavioural impact of decision confidence. Nature 455, 
227–231 (2008).
	15.	Masset, P., Ott, T., Lak, A., Hirokawa, J. & Kepecs, A. Behavior- and 
modality-general representation of confidence in orbitofrontal cortex.  
Cell 182, 112–126.e18 (2020).
	16.	Kiani, R. & Shadlen, M. N. Representation of confidence associated with a 
decision by neurons in the parietal cortex. Science 324, 759–764 (2009).
	17.	Green, D. M. & Swets, J. A. Signal Detection Theory and Psychophysics (Wiley, 
1966).
	18.	van Bergen, R. S. & Jehee, J. F. M. Modeling correlated noise is necessary to 
decode uncertainty. NeuroImage 180, 78–87 (2018).
	19.	Appelle, S. Perception and discrimination as a function of stimulus 
orientation: the “oblique effect” in man and animals. Psychol. Bull. 78, 
266–278 (1972).
	20.	Girshick, A. R., Landy, M. S. & Simoncelli, E. P. Cardinal rules: visual 
orientation perception reflects knowledge of environmental statistics.  
Nat. Neurosci. 14, 926–932 (2011).
	21.	Goris, R. L. T., Movshon, J. A. & Simoncelli, E. P. Partitioning neuronal 
variability. Nat. Neurosci. 17, 858–865 (2014).
	22.	Singer, T., Critchley, H. D. & Preuschoff, K. A common role of insula in 
feelings, empathy and uncertainty. Trends Cogn. Sci. 13, 334–340 (2009).
	23.	Behrens, T. E. J., Woolrich, M. W., Walton, M. E. & Rushworth, M. F. S. 
Learning the value of information in an uncertain world. Nat. Neurosci. 10, 
1214–1221 (2007).
	24.	Rushworth, M. F. S. & Behrens, T. E. J. Choice, uncertainty and value in 
prefrontal and cingulate cortex. Nat. Neurosci. 11, 389–397 (2008).
	25.	Fleming, S. M. & Dolan, R. J. The neural basis of metacognitive ability. Phil. 
Trans. R. Soc. B 367, 1338–1349 (2012).
	26.	Chang, L. J., Yarkoni, T., Khaw, M. W. & Sanfey, A. G. Decoding the role of 
the insula in human cognition: functional parcellation and large-scale reverse 
inference. Cereb. Cortex 23, 739–749 (2013).
	27.	Neubert, F.-X., Mars, R. B., Sallet, J. & Rushworth, M. F. S. Connectivity 
reveals relationship of brain areas for reward-guided learning and decision 
making in human and monkey frontal cortex. Proc. Natl Acad. Sci. USA 112, 
E2695–E2704 (2015).
	28.	Desikan, R. S. et al. An automated labeling system for subdividing the human 
cerebral cortex on MRI scans into gyral based regions of interest. NeuroImage 
31, 968–980 (2006).
	29.	Kriegeskorte, N., Simmons, W. K., Bellgowan, P. S. & Baker, C. I. Circular 
analysis in systems neuroscience: the dangers of double dipping. Nat. 
Neurosci. 12, 535–540 (2009).
	30.	Esterman, M., Tamber-Rosenau, B. J., Chiu, Y. C. & Yantis, S. Avoiding 
non-independence in fMRI data analysis: leave one subject out. NeuroImage 
50, 572–576 (2010).
	31.	Gold, J. I. & Shadlen, M. N. The neural basis of decision making. Annu. Rev. 
Neurosci. 30, 535–574 (2007).
	32.	De Martino, B., Fleming, S. M., Garrett, N. & Dolan, R. J. Confidence in 
value-based choice. Nat. Neurosci. 16, 105–110 (2013).
	33.	Stolyarova, A. et al. Contributions of anterior cingulate cortex and basolateral 
amygdala to decision confidence and learning under uncertainty. Nat. 
Commun. 10, 4704 (2019).
	34.	van Bergen, R. S. & Jehee, J. F. M. Probabilistic representation in human 
visual cortex reflects uncertainty in serial decisions. J. Neurosci. 39, 
8164–8176 (2019).
	35.	Walker, E. Y., Cotton, R. J., Ma, W. J. & Tolias, A. S. A neural basis  
of probabilistic computation in visual cortex. Nat. Neurosci. 23,  
122–129 (2020).
	36.	Fleming, S. M., Huijgen, J. & Dolan, R. J. Prefrontal contributions  
to metacognition in perceptual decision making. J. Neurosci. 32,  
6117–6125 (2012).
	37.	Grinband, J., Hirsch, J. & Ferrera, V. P. A neural representation of 
categorization uncertainty in the human brain. Neuron 49, 757–763 (2006).
	38.	Yoshida, W. & Ishii, S. Resolution of uncertainty in prefrontal cortex. Neuron 
50, 781–789 (2006).
	39.	Karlsson, M. P., Tervo, D. G. R. & Karpova, A. Y. Network resets in medial 
prefrontal cortex mark the onset of behavioral uncertainty. Science 338, 
135–139 (2012).
	40.	Kolling, N., Behrens, T. E. J., Mars, R. B. & Rushworth, M. F. S. Neural 
mechanisms of foraging. Science 335, 95–98 (2012).
	41.	Kolling, N. et al. Value, search, persistence and model updating in anterior 
cingulate cortex. Nat. Neurosci. 19, 1280–1285 (2016).
	42.	Shenhav, A., Cohen, J. D. & Botvinick, M. M. Dorsal anterior cingulate cortex 
and the value of control. Nat. Neurosci. 19, 1286–1291 (2016).
	43.	Bang, D., Ershadmanesh, S., Nili, H. & Fleming, S. M. Private–public 
mappings in human prefrontal cortex. eLife 9, e56477 (2020).
	44.	Morales, J., Lau, H. C. & Fleming, S. M. Domain-general and domain-specific 
patterns of activity supporting metacognition in human prefrontal cortex.  
J. Neurosci. 38, 3534–3546 (2018).
	45.	Shekhar, M. & Rahnev, D. Distinguishing the roles of dorsolateral and 
anterior PFC in visual metacognition. J. Neurosci. 38, 5078–5087 (2018).
	46.	Shin, H., Zou, Q. & Ma, W. J. The effects of delay duration on visual working 
memory for orientation. J. Vis. 17, 10 (2017).
	47.	Harrison, S. A. & Tong, F. Decoding reveals the contents of visual working 
memory in early visual areas. Nature 458, 632–635 (2009).
	48.	Rademaker, R. L., Chunharas, C. & Serences, J. T. Coexisting representations 
of sensory and mnemonic information in human visual cortex. Nat. Neurosci. 
22, 1336–1344 (2019).
	49.	Li, H.-H., Sprague, T. C., Yoo, A. H., Ma, W. J. & Curtis, C. E. Joint 
representation of working memory and uncertainty in human cortex. Neuron 
109, 3699–3712.e6 (2021).
	50.	Serences, J. T. Value-based modulations in human visual cortex. Neuron 60, 
1169–1181 (2008).
	51.	Sereno, M. I. et al. Borders of multiple visual areas in humans revealed by 
functional magnetic resonance imaging. Science 268, 889–893 (1995).
	52.	Deyoe, E. A. et al. Mapping striate and extrastriate visual areas in human 
cerebral cortex. Proc. Natl Acad. Sci. USA 93, 2382–2386 (1996).
	53.	Engel, S. A., Glover, G. H. & Wandell, B. A. Retinotopic organization in 
human visual cortex and the spatial precision of functional MRI. Cereb. 
Cortex 7, 181–192 (1997).
	54.	Kleiner, M., Brainard, D. H. & Pelli, D. G. What’s new in Psychtoolbox-3? 
Perception 36 (Suppl.), 14 (2007).
	55.	Jenkinson, M., Bannister, P., Brady, M. & Smith, S. M. Improved optimization 
for the robust and accurate linear registration and motion correction of brain 
images. NeuroImage 17, 825–841 (2002).
	56.	Reuter, M., Schmansky, N. J., Rosas, H. D. & Fischl, B. Within-subject 
template estimation for unbiased longitudinal image analysis. NeuroImage 61, 
1402–1418 (2012).
	57.	Smith, S. M. Fast robust automated brain extraction. Hum. Brain Mapp. 17, 
143–155 (2002).
	58.	Smith, S. M. & Brady, J. M. SUSAN—a new approach to low level image 
processing. Int. J. Comput. Vis. 23, 45–78 (1997).
	59.	Jenkinson, M., Beckmann, C. F., Behrens, T. E. J., Woolrich, M. W. & Smith, 
S. M. FSL. NeuroImage 62, 782–790 (2012).
	60.	Zhang, Y., Brady, M. & Smith, S. M. Segmentation of brain MR images 
through a hidden Markov random field model and the 
expectation-maximization algorithm. IEEE Trans. Med. Imaging 20,  
45–57 (2001).
	61.	Brouwer, G. J. & Heeger, D. J. Cross-orientation suppression in human visual 
cortex. J. Neurophysiol. 106, 2108–2119 (2011).
	62.	Hedges, L. V. & Olkin, I. Statistical Methods for Meta-analysis (Academic 
Press, 1985).
	63.	Fieller, E. C. & Pearson, E. S. Tests for rank correlation coefficients: II. 
Biometrika 48, 29–40 (1961).
	64.	Schuirmann, D. J. A comparison of the two one-sided tests procedure and  
the power approach for assessing the equivalence of average bioavailability.  
J. Pharmacokinet. Biopharm. 15, 657–680 (1987).
	65.	Cohen, J. A power primer. Psychol. Bull. 112, 155–159 (1992).
	66.	Smith, S. M. & Nichols, T. E. Threshold-free cluster enhancement: addressing 
problems of smoothing, threshold dependence and localisation in cluster 
inference. NeuroImage 44, 83–98 (2009).
Nature Human Behaviour | VOL 6 | February 2022 | 294–305 | www.nature.com/nathumbehav
304
Articles
NATUrE HUmAn BEhAvioUr
	67.	Winkler, A. M., Ridgway, G. R., Webster, M. A., Smith, S. M. & Nichols, T. E. 
Permutation inference for the general linear model. NeuroImage 92,  
381–397 (2014).
	68.	Nichols, T. E. & Hayasaka, S. Controlling the familywise error rate in 
functional neuroimaging: a comparative review. Stat. Methods Med. Res. 12, 
419–446 (2003).
	69.	Sallet, J. et al. The organization of dorsal frontal cortex in humans and 
macaques. J. Neurosci. 33, 12255–12274 (2013).
	70.	Furmanski, C. S. & Engel, S. A. An oblique effect in human primary visual 
cortex. Nat. Neurosci. 3, 535–536 (2000).
	71.	Wei, X. X. & Stocker, A. A. A Bayesian observer model constrained by 
efficient coding can explain “anti-Bayesian” percepts. Nat. Neurosci. 18, 
1509–1517 (2015).
	72.	Dworkin, J. D. et al. The extent and drivers of gender imbalance in 
neuroscience reference lists. Nat. Neurosci. 23, 918–926 (2020).
	73.	Ress, D., Backus, B. T. & Heeger, D. J. Activity in primary visual cortex 
predicts performance in a visual detection task. Nat. Neurosci. 3,  
940–945 (2000).
	74.	Baird, B., Smallwood, J., Gorgolewski, K. J. & Margulies, D. S. Medial and 
lateral networks in anterior prefrontal cortex support metacognitive ability for 
memory and perception. J. Neurosci. 33, 16657–16665 (2013).
	75.	McCurdy, L. Y. et al. Anatomical coupling between distinct metacognitive 
systems for memory and visual perception. J. Neurosci. 33, 1897–1906 (2013).
	76.	Ye, Q., Zou, F., Lau, H., Hu, Y. & Kwok, S. C. Causal evidence for mnemonic 
metacognition in human precuneus. J. Neurosci. 38, 6379–6387 (2018).
	77.	Drugowitsch, J., Mendonça, A. G., Mainen, Z. F. & Pouget, A. Learning 
optimal decisions with confidence. Proc. Natl Acad. Sci. USA 116, 
24872–24880 (2019).
	78.	Kastner, S. et al. Increased activity in human visual cortex during directed 
attention in the absence of visual stimulation. Neuron 22, 751–761 (1999).
	79.	Sreenivasan, K. K. & D’Esposito, M. The what, where and how of delay 
activity. Nat. Rev. Neurosci. 20, 466–481 (2019).
Acknowledgements
We thank A. Sanfey and R. Cools for helpful discussions, C. Beckmann for advice 
on statistical analyses and P. Gaalman for MRI support. This work was supported by 
European Research Council Starting Grant No. 677601 (to J.F.M.J.). The funder had  
no role in study design, data collection and analysis, decision to publish or preparation  
of the manuscript.
Author contributions
L.S.G., R.S.v.B. and J.F.M.J. conceived and designed the experiments. L.S.G. collected the 
data. L.S.G. analysed the data, with help from J.F.M.J. L.S.G. and J.R.H.C. constructed the 
ideal observer models, with help from J.F.M.J. L.S.G., J.R.H.C., R.S.v.B. and J.F.M.J. wrote 
the manuscript.
Competing interests
The authors declare no competing interests.
Additional information
Extended data is available for this paper at https://doi.org/10.1038/s41562-021-01247-w.
Supplementary information The online version contains supplementary material 
available at https://doi.org/10.1038/s41562-021-01247-w.
Correspondence and requests for materials should be addressed to Janneke F. M. Jehee.
Peer review information Nature Human Behaviour thanks Dan Bang, Pascal Mamassian 
and Peter Murphy for their contribution to the peer review of this work.
Reprints and permissions information is available at www.nature.com/reprints.
Publisher’s note Springer Nature remains neutral with regard to jurisdictional claims in 
published maps and institutional affiliations.
© The Author(s), under exclusive licence to Springer Nature Limited 2022,  
corrected publication 2022
Nature Human Behaviour | VOL 6 | February 2022 | 294–305 | www.nature.com/nathumbehav
305
Articles
NATUrE HUmAn BEhAvioUr
Articles
NATUrE HUmAn BEhAvioUr
Extended Data Fig. 1 | Trial structure. Each trial started with the presentation of an oriented grating (1500 ms) followed by a 6000-ms fixation interval 
and two 4500-ms response intervals, during which the participant first reported the orientation of the previously seen stimulus by rotating a bar, and then 
indicated their level of confidence in this judgment on a continuous scale. Trials were separated by a 1500-ms intertrial interval. Stimulus, response bar 
and confidence scale are not drawn to their true scale and contrast.
Nature Human Behaviour | www.nature.com/nathumbehav
Articles
NATUrE HUmAn BEhAvioUr
Articles
NATUrE HUmAn BEhAvioUr
Extended Data Fig. 2 | Orientation and uncertainty decoding performance. The orientation of the presented stimulus, and associated uncertainty, 
decoded from activity patterns in areas V1-V3. (a) Orientation decoding performance was quantified by means of the circular equivalent of the Pearson 
correlation coefficient between presented and decoded orientations. Correlation coefficients were computed for each subject individually and then 
averaged across subjects (N = 32). Presented and decoded orientations were significantly correlated (z = 83.58, p < 0.001, r = 0.60, 95% CI = [0.58, 
0.61]). (b-d) To assess the degree to which the decoder captured uncertainty contained in neural population activity, we compared decoded uncertainty 
to behavioral variability, the rationale being that a more precise representation in cortex should also result in more precise behavioral estimates (see 
also10). (b) Corroborating our approach, we found that decoded uncertainty was greater for oblique compared to cardinal orientation stimuli (correlation 
distance-to-cardinal and decoded uncertainty: z = 2.95, p = 0.002, ρ = 0.025, 95% CI = [0.0083 0.041]). This finding was paralleled by the imprecision 
in observer behaviour (correlation distance-to-cardinal and behavioral variability: t(287) = 13.60, p < 0.001, r = 0.63, 95% CI = [0.55, 0.69]). (c-d) In 
addition, behavioral orientation responses were more precise when the decoded probability distributions indicated greater certainty in cortex, (c) both 
across orientation stimuli (correlation decoded uncertainty and behavioral variability: t(287) = 2.30, p = 0.011, r = 0.13, 95% CI = [0.019, 0.25]), and (d) 
when controlling for orientation (t(286) = 1.68, p = 0.047, r = 0.099, 95% CI=[−0.017, 0.21]). Altogether, this further underscores the validity of the 
decoding approach and shows that decoded uncertainty reliably characterizes the degree of imprecision in cortical representations of the stimulus  
(see10,18 for further proof of this approach). Note that these are partial residual plots, which is why the data is centered around 0. Error bars (a-b) represent 
± 1 s.e.m. (c-d) Shades of red indicate ten equal-size bins of increasing decoded uncertainty, dots represent individual observers (N = 32).
Nature Human Behaviour | www.nature.com/nathumbehav
Articles
NATUrE HUmAn BEhAvioUr
Articles
NATUrE HUmAn BEhAvioUr
Extended Data Fig. 3 | Oblique effect in reported confidence and decoded uncertainty. Effect of stimulus orientation on reported confidence (a) and 
decoded uncertainty (b). Each participant’s data were first binned based on the absolute distance between presented stimulus orientation and the 
nearest cardinal axis (equal-width bins), and then averaged across trials and finally across subjects (error bars represent ± 1 s.e.m). Dashed lines indicate 
best-fitting function (least-squares; quadratic for confidence, linear for decoded uncertainty). Functions were fitted on the trial-by-trial data for each 
participant, and averaged across participants.
Nature Human Behaviour | www.nature.com/nathumbehav
Articles
NATUrE HUmAn BEhAvioUr
Articles
NATUrE HUmAn BEhAvioUr
Extended Data Fig. 4 | Relationship between decoded uncertainty and reported confidence across different numbers of voxels. Correlation coefficients 
between decoded uncertainty and reported confidence as a function of the number of voxels included in the ROI, both across all orientations (a) and after 
removing the effect of stimulus orientation (b). Voxels within V1-V3 were ranked and selected for multivariate analysis based on their response to the 
visual localizer stimulus (see Methods), using a lenient statistical threshold of p < 0.01, uncorrected. The results proved reasonably robust to variations in 
the number of voxels selected for analysis. Dark red line indicates group average correlation coefficients, error bars denote ± 1 s.e.m.
Nature Human Behaviour | www.nature.com/nathumbehav
Articles
NATUrE HUmAn BEhAvioUr
Articles
NATUrE HUmAn BEhAvioUr
Extended Data Fig. 5 | No effects of overall BOLD or eyetracking measures on confidence. Reported confidence is not significantly correlated with the 
mean BOLD response to the stimulus in areas V1-V3 (z = 0.73, p = 0.47, ρ = 0.0062, 95% CI=[−0.010, 0.023]; equivalence test: z=−0.094, p<0.001), nor 
with mean eye position (mean absolute distance to screen center; z=−1.38, p=0.17, ρ = −0.012, 95% CI=[−0.030, 0.0051]; equivalence test: z=−0.088, 
p<0.001), eye blinks (z=0.99, p=0.32, ρ = 0.0087, 95% CI=[−0.0086, 0.026]; equivalence test: z=−0.11, p<0.001), or the number of breaks from fixation 
during stimulus presentation (z=0.57, p=0.57, ρ = 0.0050, 95% CI=[−0.012, 0.022]; equivalence test: z=−0.11, p < 0.001), suggesting that participants did 
not rely on heuristics in terms of eye position (‘did I look at the stimulus?’) or eye blinks (‘were my eyes closed?’) for reporting confidence. It furthermore 
rules out simple heuristic explanations in terms of attentional effort (‘my mind was elsewhere’, ‘I didn’t really try that hard’), as the mean BOLD response to 
the stimulus tends to increase with attention in these areas73. Shaded blue represents ± 1 s.e.m. Gray dots denote individual observers (N = 32).
Nature Human Behaviour | www.nature.com/nathumbehav
Articles
NATUrE HUmAn BEhAvioUr
Articles
NATUrE HUmAn BEhAvioUr
Extended Data Fig. 6 | Effects of decoded uncertainty and reported confidence on the BOLD response in precuneus, supplementary motor area, 
dorsal perigenual anterior cingulate cortex, ventral posterior cingulate cortex, dorsal posterior cingulate cortex, and stimulus-driven voxels in V1-V3. 
Group-average correlation coefficients for the relationship between decoded uncertainty and BOLD contrast, and reported confidence and BOLD contrast, 
in six ROIs. (a) In precuneus, the effects of both decoded sensory uncertainty and reported confidence on BOLD peaked around the same time, i.e. during 
the second half of the response window. This finding is consistent with previous work suggesting that precuneus may represent uncertainty in memory but 
not in perception74–76. (b) In supplementary motor area, both decoded uncertainty and reported confidence modulated cortical activity relatively early in 
the response window, while the effects of confidence lingered until after observers gave their response. (c-d) In dorsal perigenual anterior cingulate cortex 
and ventral posterior cingulate cortex, decoded uncertainty had a moderate effect on the BOLD response. Reported confidence modulated cortical activity 
during as well as shortly after the response window. (e) In dorsal posterior cingulate cortex, the modulatory effect of both decoded uncertainty and 
reported confidence on the cortical response was largest around the onset of the response window. (f) Stimulus-driven voxels in early visual cortex were 
modulated by both decoded uncertainty and reported confidence, most notably during the first portion of the response interval. Given the timing of the 
effect (and taking into account the hemodynamic delay), this likely does not reflect uncertainty in the sensory representation per se, but is consistent with 
anticipatory processes or working memory-related signals potentially influenced by the imprecision in the cortical stimulus representation77–79. Please note 
there is no net effect of uncertainty on the overall (univariate) BOLD response during the decoding window (stimulus presentation; dashed lines). (a-f) 
Horizontal lines indicate statistical significance (p < 0.05, FWER-controlled). Error bars represent ± 1 s.e.m. Dark gray area marks stimulus presentation 
window, light gray area marks response window.
Nature Human Behaviour | www.nature.com/nathumbehav
Articles
NATUrE HUmAn BEhAvioUr
Articles
NATUrE HUmAn BEhAvioUr
Extended Data Fig. 7 | Effects of decoded uncertainty and reported confidence on the BOLD response in dAI, dACC and rlPFC, after accounting for 
trial-by-trial fluctuations in behavioral response times. Behavioral response time effects were linearly regressed out from decoded uncertainty and 
reported confidence, prior to computing the Spearman correlation coefficient between decoded uncertainty (reported confidence) and the BOLD response 
at different moments in time after stimulus presentation. The remaining analysis steps are identical to those in the main text. Removing the effect of 
behavioral response time did not qualitatively change the pattern of results in any of these ROIs. Horizontal lines indicate statistical significance (p < 0.05, 
FWER-controlled). Dark gray area marks stimulus presentation window, light gray area denotes response window. Error bars represent ± 1 s.e.m.
Nature Human Behaviour | www.nature.com/nathumbehav
Articles
NATUrE HUmAn BEhAvioUr
Articles
NATUrE HUmAn BEhAvioUr
Extended Data Fig. 8 | Effects of decoded uncertainty (or reported confidence) on the BOLD response in dAI, dACC and rlPFC, after controlling for 
confidence (or decoded uncertainty). Reported confidence (or decoded uncertainty) was linearly regressed on both decoded uncertainty (or reported 
confidence) and the BOLD response at different moments in time after stimulus presentation. The residuals of these fits were then used to compute 
the group-averaged correlation coefficient between cortical response amplitude and decoded uncertainty (red) or reported confidence (blue). For all 
ROIs, the results are qualitatively similar to the main results reported in Fig. 4 in the main text. Horizontal lines indicate statistical significance (p < 0.05, 
FWER-controlled). Dark gray area marks stimulus presentation window, light gray area denotes response window. Error bars represent ± 1 s.e.m.
Nature Human Behaviour | www.nature.com/nathumbehav
Articles
NATUrE HUmAn BEhAvioUr
Articles
NATUrE HUmAn BEhAvioUr
Extended Data Fig. 9 | Activity in dAI, dACC, and left rlPFC mediates the relationship between decoded uncertainty and reported confidence. To assess 
the degree to which the cortical activity in these regions mediates the observed relationship between decoded uncertainty and reported confidence, 
we performed the following analysis. We first modeled both uncertainty and confidence as a function of the overall BOLD signal in a given ROI at 
each timepoint, and then used the residuals of these fits to compute the Spearman correlation coefficient between decoded uncertainty and reported 
confidence when controlled for the BOLD signal. From the resulting correlation coefficient, we subtracted the (baseline) correlation coefficient that was 
obtained while we did not control for the BOLD signal (see Fig. 3c). We observed a significant net effect at various moments in time, which indicates that 
there was a reliable reduction in the strength of the inverse (negative) correlation coefficient between uncertainty and confidence when we controlled for 
BOLD intensity. This suggests that the level of cortical activity in these windows (partially) mediates the relationship between decoded uncertainty and 
reported confidence. Horizontal lines indicate statistical significance (p < 0.05, FWER-controlled). Dark gray area marks stimulus presentation window, 
light gray area denotes response window. Dashed lines indicate the decoding window used in the main analyses (Fig. 3b-c and Extended Data Fig. 2).  
Error bars represent ± 1 s.e.m.
Nature Human Behaviour | www.nature.com/nathumbehav
Articles
NATUrE HUmAn BEhAvioUr
Articles
NATUrE HUmAn BEhAvioUr
Extended Data Fig. 10 | Decoding results over time. Does reported confidence similarly reflect imprecision in the cortical representation when the 
orientation is held in visual working memory? To address this question, the analyses of Fig. 3b-c and Extended Data Fig. 2 were repeated over time, using 
a sliding window of size 3 s (2 TRs). We focused on successive intervals from 1.5 s before to 13.5 s after stimulus onset (which roughly corresponds to 
the onset of the response window after accounting for hemodynamic delay). Benchmark tests verified that the decoded probability distributions reliably 
predict the orientation of the presented stimulus (a), and variability in the observer’s behavioral estimates (b-c) over extended periods of time. Having 
established that the decoded distributions meaningfully reflect the degree of imprecision in the cortical representation, we next investigated the extent 
to which decoded uncertainty predicts reported confidence during the retention interval. We found a reliable negative relationship between decoded 
uncertainty and reported confidence that held up well into the delay period (d). This is consistent with an imprecise working memory trace in V1-V3 that 
influences subjective confidence. Please note, however, that our design does not warrant strong conclusions regarding the nature of this representation: 
due to fMRI’s low temporal resolution, it is difficult to say whether these signals are purely perceptual or working memory-related (see e.g.47, for similar 
rationale), and later TRs could simply reflect the visual presentation of the response bar, rather than memory-based signals. (a-d) Data are centered to the 
middle of the analysis window (of size 2 TRs). Horizontal lines indicate statistical significance (p < 0.05, FWER-controlled). Dark gray area marks stimulus 
presentation window, light gray area denotes response window. Dashed lines indicate the decoding window used for the main analyses (i.e., Fig. 3b,c and 
Extended Data Fig. 2). Shaded regions represent ± 1 s.e.m. (standard errors in (a) are too small to be visible).
Nature Human Behaviour | www.nature.com/nathumbehav
1
nature research  |  reporting summary
April 2020
Corresponding author(s):
Janneke F.M. Jehee, PhD
Last updated by author(s): 10/28/21
Reporting Summary
Nature Research wishes to improve the reproducibility of the work that we publish. This form provides structure for consistency and transparency 
in reporting. For further information on Nature Research policies, see our Editorial Policies and the Editorial Policy Checklist.
Statistics
For all statistical analyses, confirm that the following items are present in the figure legend, table legend, main text, or Methods section.
n/a Confirmed
The exact sample size (n) for each experimental group/condition, given as a discrete number and unit of measurement
A statement on whether measurements were taken from distinct samples or whether the same sample was measured repeatedly
The statistical test(s) used AND whether they are one- or two-sided 
Only common tests should be described solely by name; describe more complex techniques in the Methods section.
A description of all covariates tested
A description of any assumptions or corrections, such as tests of normality and adjustment for multiple comparisons
A full description of the statistical parameters including central tendency (e.g. means) or other basic estimates (e.g. regression coefficient) 
AND variation (e.g. standard deviation) or associated estimates of uncertainty (e.g. confidence intervals)
For null hypothesis testing, the test statistic (e.g. F, t, r) with confidence intervals, effect sizes, degrees of freedom and P value noted 
Give P values as exact values whenever suitable.
For Bayesian analysis, information on the choice of priors and Markov chain Monte Carlo settings
For hierarchical and complex designs, identification of the appropriate level for tests and full reporting of outcomes
Estimates of effect sizes (e.g. Cohen's d, Pearson's r), indicating how they were calculated
Our web collection on statistics for biologists contains articles on many of the points above.
Software and code
Policy information about availability of computer code
Data collection
Matlab 2012a
Data analysis
Matlab 2018b, SPM12, FSL 6.0.1, freesurfer 5.3, custom code (PRINCE decoding algorithm: https://github.com/jeheelab/TAFKAP; see van 
Bergen et al., 2015, Nature Neuroscience; van Bergen & Jehee, 2018, NeuroImage)
For manuscripts utilizing custom algorithms or software that are central to the research but not yet described in published literature, software must be made available to editors and 
reviewers. We strongly encourage code deposition in a community repository (e.g. GitHub). See the Nature Research guidelines for submitting code & software for further information.
Data
Policy information about availability of data
All manuscripts must include a data availability statement. This statement should provide the following information, where applicable: 
- Accession codes, unique identifiers, or web links for publicly available datasets 
- A list of figures that have associated raw data 
- A description of any restrictions on data availability
The data used to generate the main figures in this article are provided under Source Data. Preprocessed behavioral and fMRI data for individual participants, as well 
as unthresholded statistical maps from the whole-brain univariate analysis, can be downloaded from: https://doi.org/10.34973/983b-a047. To protect participant 
privacy, the raw data are available from the corresponding author upon request.
2
nature research  |  reporting summary
April 2020
Field-specific reporting
Please select the one below that is the best fit for your research. If you are not sure, read the appropriate sections before making your selection.
Life sciences
Behavioural & social sciences
 Ecological, evolutionary & environmental sciences
For a reference copy of the document with all sections, see nature.com/documents/nr-reporting-summary-flat.pdf
Life sciences study design
All studies must disclose on these points even when the disclosure is negative.
Sample size
Sample size (N=32) was based on a power calculation (power = 0.8; alpha = 0.05). 
Data exclusions
Trials on which the participant's behavioral error was more than three standard deviations away from the mean of that participant (after bias 
correction) were marked as guesses and excluded from further analysis (1-7 out of 440-520 trials). Trials on which the participant did not 
finish their response by the end of the response window were also excluded from further analyses (0-43 out of 440-520 trials). 
Replication
We implemented an ideal observer model (i.e., normative computational model). This resulted in a number of quantitative predictions, each 
of which we experimentally tested in several independent ways. All of our predictions were supported by the empirical data.
Randomization
We used a within-subjects design, so no allocation into experimental groups was necessary.
Blinding
We used a within-subjects design so blinding was not necessary.
Reporting for specific materials, systems and methods
We require information from authors about some types of materials, experimental systems and methods used in many studies. Here, indicate whether each material, 
system or method listed is relevant to your study. If you are not sure if a list item applies to your research, read the appropriate section before selecting a response. 
Materials & experimental systems
n/a Involved in the study
Antibodies
Eukaryotic cell lines
Palaeontology and archaeology
Animals and other organisms
Human research participants
Clinical data
Dual use research of concern
Methods
n/a Involved in the study
ChIP-seq
Flow cytometry
MRI-based neuroimaging
Human research participants
Policy information about studies involving human research participants
Population characteristics
Participants were healthy adults (age range 19-31, 20 female, 12 male) with normal or corrected-to-normal vision. All 
participants gave informed written consent prior to their participation and received monetary compensation for their 
participation (8 or 10 euros per hour for behavioral and fMRI sessions, respectively).
Recruitment
Participants were recruited via the participant database (SONA systems) of Radboud University and among colleagues and 
acquaintances. We compared how well quantitative predictions from different computational models could predict the 
participant’s brain and behavioral data, and it is implausible that the recruitment procedures would benefit any particular 
one of these models.
Ethics oversight
CMO Arnhem-Nijmegen, the Netherlands
Note that full information on the approval of the study protocol must also be provided in the manuscript.
Magnetic resonance imaging
Experimental design
Design type
Task; slow event-related design
3
nature research  |  reporting summary
April 2020
Design specifications
Two fMRI sessions per participant. 10-13 runs per session. 20 trials per run (16.5 s/trial + 1.5 s inter-trial interval + 4.5 s 
fixation at the start of the run and 15 s at the end). Additionally, each scan session included one or two functional 
localizer runs, in which flickering checkerboard stimuli were presented in seven 12-s blocks interleaved with fixation 
blocks of equal duration.
Behavioral performance measures
We recorded the position of the orientation bar and the position of the confidence dot, as well as the timing of the first 
and last button presses, in each response window. Participants generally performed well on the task, with a mean 
absolute behavioral estimation error of 4.34° ± 0.212° (mean ± SEM across subjects). In general, participants finished 
adjusting their orientation and confidence responses well before the end of the response windows (4.5 s each), taking 
on average 2761 ± 378 ms (mean ± S.D. across observers) for the orientation response and 2587 ± 313 ms for the 
confidence response.
Acquisition
Imaging type(s)
Functional, structural
Field strength
3T
Sequence & imaging parameters
For anatomical reference, a high-resolution T1-weighted image was collected at the start of each session (3D MPRAGE, 
TR: 2300 ms, TI: 1100 ms, TE: 3 ms, flip angle: 8 degrees, FOV: 256 x 256 mm, 192 saggital slices, 1-mm isotropic voxels). 
B0 field inhomogeneity maps (TR: 653 ms, TE: 4.92 ms, flip angle: 60 degrees, FOV: 256 x 256 mm, 68 transversal slices, 
2-mm isotropic voxels, interleaved slice acquisition) were acquired. Functional data were acquired using a multi-band 
accelerated gradient-echo EPI protocol, in 68 transversal slices covering the whole brain (TR: 1500 ms, TE: 38.60 ms, flip 
angle: 75 degrees, FOV: 210 x 210 mm, 2-mm isotropic voxels, multiband acceleration factor: 4, interleaved slice 
acquisition).
Area of acquisition
Whole brain
Diffusion MRI
Used
Not used
Preprocessing
Preprocessing software
FSL 6.0.1 and freesurfer 5.3 were used for preprocessing of MRI data. Slow drifts in the BOLD signal were removed using FSL’s 
nonlinear high-pass temporal filter (fslmaths) with a sigma of 24 TRs (corresponding to two trials). For univariate analyses 
only, we additionally removed non-brain structures using FSL's BET (fractional intensity threshold: 0.2), and spatially 
smoothed the data with a 6-mm Gaussian kernel using FSL's SUSAN. FSL's MCFLIRT was used for motion correction. FSL's 
FLIRT was applied to unwarp EPI data (using a field map obtained in the same session), and to register the unwarped data to 
the within-session anatomical reference image.
Normalization
For univariate analyses, each subject's anatomical template (created with freesurfer's mri_robust_template) was non-linearly 
registered to MNI152 space using FSL's FNIRT with a warp resolution of 10 mm isotropic. 
For multivariate analyses, the data were analyzed within subjects, so no normalization was necessary.
Normalization template
Univariate analyses: MNI152 
Multivariate analyses: n/a
Noise and artifact removal
The following nuisance regressors were used: an intercept regressor per run, 24 motion regressors based on the 
transformation parameters obtained from the motion correction algorithm (all analyses), and two regressors reflecting the 
average signal in cerebrospinal fluid (CSF) and white matter (WM) (univariate analyses only). Motion regressors included raw 
displacement parameters (3 rotations + 3 translations), the displacement parameters squared, their temporal derivatives, 
and gradients. The CSF and WM regressors served to capture global fluctuations in signal intensity and were obtained by first 
creating WM and CSF masks based on the subject’s anatomical scan data using FSL’s FAST, and then removing the outer 
edges from these masks to exclude voxels at the tissue boundaries. For the multivariate and ROI-based univariate analyses, 
nuisance signals were removed from the BOLD signal prior to further analyses, and no further artifact removal was applied. 
For the whole-brain univariate analysis, motion, CSF/WM, and intercept regressors were included as covariates in the general 
linear model.
Volume censoring
No volume censoring was performed.
Statistical modeling & inference
Model type and settings
We performed both multivariate and univariate (whole-brain and ROI-based) analyses.  
 
Multivariate analyses were based on a previously published, generative-model based decoding technique (van Bergen et al., 
2015, Nature Neuroscience; van Bergen & Jehee, 2018, NeuroImage). Using this technique, and for each individual subject, 
we extracted from BOLD activity a probability distribution over stimulus orientation on a trial-by-trial basis. 'Decoded 
uncertainty' was quantified as the squared circular standard deviation of the decoded distribution. 
 
For the whole-brain univariate analyses, the following model was fit to single-subject multi-session, concatenated data (using 
SPM12). 1) a 1.5-s boxcar function time-locked to the stimulus onsets of all excluded trials, with height one, 2) a 1.5-s boxcar 
function time-locked to the stimulus onsets of all included trials, with height one, 3) a 1.5-s boxcar function time-locked to 
the stimulus onsets of all included trials, with its height equal to the level of sensory uncertainty on that trial (decoded from 
activity in visual cortex, and linearly corrected for trial-by-trial differences in stimulus orientation). Each boxcar function was 
4
nature research  |  reporting summary
April 2020
convolved with a canonical hemodynamic response function (HRF) and temporal and dispersion derivatives of the HRF (SPM’s 
informed basis set), yielding a total of nine regressors to include in the design matrix. We furthermore included nuisance 
regressors (24 motion regressors and 2 CSF/WM regressors per session), and run-specific intercepts (see also above). 
Permutation tests were used to assess statistical significance at the group level (see below). 
 
For the ROI-based univariate analyses, two types of analyses were performed. First, a GLM was fitted using identical 
procedures as described above, except that for component 3) decoded uncertainty values were replaced by the level of 
confidence reported by the participant on that trial. Second, we performed a trial-by-trial correlation analysis. Specifically, for 
each individual participant and for each TR in the trial, we computed the Spearman correlation coefficient between BOLD 
intensity and decoded uncertainty or reported confidence (after removing orientation-dependent changes in decoded 
uncertainty and confidence, see Methods for further details). The single-subject correlation coefficients were Fisher 
transformed, and a weighted average was computed across observers. Statistical significance was assessed using 
permutation tests.
Effect(s) tested
Multivariate analyses: we tested the relationship between decoded uncertainty and behavioral variability (variance of 
response errors), both corrected and uncorrected for differences in presented stimulus orientation, using multiple linear 
regression. We tested the relationship between reported confidence and decoded uncertainty (trial-by-trial), using rank 
regression. We ran benchmark tests for our decoding approach, testing the relationship between decoded and presented 
stimulus orientation (circular correlation), between decoded uncertainty and stimulus distance to cardinal (rank regression), 
and between decoded uncertainty and behavioral variability (linear regression). 
 
Whole-brain univariate analyses: we tested the trial-by-trial relationship between decoded uncertainty and BOLD activity by 
computing (across subjects) an F-statistic over the beta estimates corresponding to the three regressors derived from the 
third model component as described above (i.e., 1.5-s boxcar function time-locked to the stimulus onset of included trials, 
with its height equal to decoded uncertainty on that trial). 
 
ROI-based univariate analyses: we tested the overall trial-by-trial relationship between reported confidence and BOLD 
activity by computing (across subjects) an F-statistic over the beta estimates corresponding to the three regressors derived 
from the third model component (i.e., 1.5-s boxcar function time-locked to the stimulus onset of included trials, with its 
height equal to reported confidence on that trial). We additionally tested the trial-by-trial relationship between BOLD activity 
and decoded uncertainty or reported confidence for each TR in the trial separately, using rank regression.
Specify type of analysis:
Whole brain
ROI-based
Both
Anatomical location(s)
Multivariate analyses: areas V1, V2, and V3 were manually identified on the reconstructed cortical 
surface, based on retinotopic maps acquired using standard retinotopic mapping procedures in a 
separate scan session. 
 
ROI-based univariate analyses: ROIs were defined using existing anatomical atlases, combined with a 
functional parcellation based on the whole-brain GLM analysis. Specifically, within a given (anatomical) 
ROI, we selected voxels modulated by decoded uncertainty in the whole-brain GLM analysis, while 
applying a leave-one-subject-out procedure to avoid double-dipping. The specific atlases used for 
individual ROIs are further detailed in the Methods section.
Statistic type for inference
(See Eklund et al. 2016)
Multivariate analyses: based on the assumed relationship between the two variables (linear or monotonic), linear or rank 
correlation coefficients were computed. Correlation coefficients were Fisher-transformed and then averaged across 
participants, after which statistical significance was assessed using a Z-test. For analyses that required binning of data, 
multiple linear regression (across-subjects) was used, and statistical significance of partial correlation coefficients was 
assessed using a t-test. 
 
Univariate whole-brain analyses: To calculate p-values, a sign-flip test (5000 permutations; voxelwise) was performed in 
combination with threshold-free cluster enhancement (TFCE), using FSL’s randomise.  
 
ROI-based univariate analyses: To assess the overall effect of confidence, we used identical procedures as for the univariate 
whole-brain analyses. For the TR-wise analyses, statistical significance was assessed using permutation tests, in which 
uncertainty (or confidence) values were permuted across trials (1000 permutations).
Correction
Multivariate analyses: n/a 
 
Univariate whole-brain analyses & ROI-based univariate analyses (overall effect of confidence): The family-wise error rate 
(FWER) was controlled by comparing the true voxel-wise TFCE scores against the null distribution of the maximum TFCE score 
across voxels. 
 
ROI-based univariate analyses (TR-wise): To control for multiple comparisons (FWER) we compared against the null 
distribution of the maximum correlation coefficient across timepoints (obtained through permutation testing).
Models & analysis
n/a Involved in the study
Functional and/or effective connectivity
Graph analysis
Multivariate modeling or predictive analysis
Multivariate modeling and predictive analysis
We made use of a previously published, generative-model based, probabilistic decoding technique (van 
5
nature research  |  reporting summary
April 2020
Multivariate modeling and predictive analysis
Bergen et al., 2015, Nature Neuroscience; van Bergen & Jehee, 2018, NeuroImage; code available here: 
https://github.com/jeheelab/TAFKAP). From samples of BOLD activity, we extracted a probability distribution 
over orientation. Within the ROI (areas V1, V2, and V3, combined), we selected the 2000 voxels that were 
activated most strongly by the functional localizer stimulus while surviving a lenient statistical threshold (p < 
0.01, uncorrected). The time series of each selected voxel was subsequently z-normalized with respect to 
corresponding trial time points in the same run. Activation patterns for each trial were obtained by averaging 
over the first 3 s of each trial, after adding a 4.5 s temporal shift to account for hemodynamic delay. A leave-
one-run-out cross-validation procedure was used for model training and testing. The independent variable 
(for training) was the presented stimulus orientation. 
 
We used a previously published and well-validated approach (van Bergen et al., 2015, Nature Neuroscience; 
van Bergen & Jehee, 2018, NeuroImage). Additional benchmark analyses verified that 1) orientation 
decoding performance was well above chance levels, 2) decoded uncertainty was lower for cardinal 
compared to oblique orientation stimuli, and 3) decoded uncertainty predicted  behavioral variability, both 
within and across stimulus orientations. This replicates van Bergen et al. (2015) and confirms that the 
precision of the observer’s internal sensory evidence was reliably extracted from the patterns of fMRI activity 
on a trial-by-trial basis.
