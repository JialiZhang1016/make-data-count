‘HOW TO. . .’ PAPER
On the variety of methods for calculating conﬁdence
intervals by bootstrapping
Marie-Therese Puth1, Markus Neuh€auser1 and Graeme D. Ruxton2*
1Fachbereich Mathematik und Technik, RheinAhrCampus, Koblenz University of Applied Sciences, Joseph-Rovan-
Allee 2, 53424 Remagen, Germany; and 2School of Biology, University of St Andrews, St Andrews, Fife KY16 9TH,
UK
Summary
1. Researchers often want to place a conﬁdence interval around estimated parameter values
calculated from a sample. This is commonly implemented by bootstrapping. There are several
different frequently used bootstrapping methods for this purpose.
2. Here we demonstrate that authors of recent papers frequently do not specify the method
they have used and that different methods can produce markedly different conﬁdence inter-
vals for the same sample and parameter estimate.
3. We encourage authors to be more explicit about the method they use (and number of
bootstrap resamples used).
4. We recommend the bias corrected and accelerated method as giving generally good perfor-
mance; although researchers should be warned that coverage of bootstrap conﬁdence intervals
is characteristically less than the speciﬁed nominal level, and conﬁdence interval evaluation by
any method can be unreliable for small samples in some situations.
Key-words: parameter estimation, randomization, resampling, statistics
Introduction
It is increasingly common for researchers to offer esti-
mates of (population) parameter values (e.g. mean, effect
size, correlation coefﬁcient, etc.) instead of (or as well as)
the P-values associated with testing of null hypotheses.
Evaluation of a sample from the population of interest
does not allow us to estimate a population parameter with
certainty; rather, it is common to produce a conﬁdence
interval in which we aim to enclose the true (population)
value on a speciﬁed fraction of occasions. For the fre-
quently used 95% conﬁdence interval, the calculated inter-
val is intended to enclose the true value for 95% of
samples. Researchers often use bootstrapping as a very
general means of generating a conﬁdence interval for
many commonly used statistics. The essence of bootstrap-
ping is the drawing of pseudo-samples (hereafter called
bootstraps) either from the original sample itself (non-
parametric bootstrapping) or from a model ﬁtted to the
original sample (parametric bootstrapping). The ﬁrst of
these is more commonly used and will be the focus of
this
paper.
Nonparametric
bootstrapping
makes
no
assumptions about the nature of the underlying popula-
tion, and the only information used is the original sample
itself. Bootstrapping is a popular method of producing
conﬁdence intervals because of its generality: the same
method can be used for a very broad range of statistics.
Although computationally demanding, various methods
have been made available through commonly used statisti-
cal software. This means that for almost any situation in
animal ecology where you can calculate some statistic,
bootstrapping can be used to generate a conﬁdence inter-
val around the point value. Further, the calculation of
this can be done with minimal extra effort in commonly
used statistical computing software packages.
There are other methods available for calculation of
conﬁdence intervals for various parameters. However,
almost all alternatives to bootstrapping require assump-
tions to be made about properties of the underlying distri-
bution
from
which
the
sample
is
drawn.
These
assumptions are not always made explicit to the reader
and may not always be easy to evaluate on the basis of
the sample or of other biological knowledge of the sys-
tem. These methods are also often speciﬁc to a particular
type of parameter, whereas a bootstrapping technique will
work
in
essentially
the
same
way
when
applied
to
different parameters. Finally, especially for uncommon
*Correspondence author. E-mail: gr41@st-andrews.ac.uk
© 2015 The Authors. Journal of Animal Ecology © 2015 British Ecological Society
Journal of Animal Ecology 2015, 84, 892–897
doi: 10.1111/1365-2656.12382
parameters, there may be no available alternatives to gen-
eral methods such as bootstrapping.
Here we brieﬂy describe a diversity of the different
alternative
bootstrapping
methods
easily
available
to
researchers, offer some tentative suggestions on which to
use, and encourage researchers to provide more detail on
the method they use when reporting results. A survey of
the recent literature suggests that such speciﬁcation is not
a widely adopted practice, although it is necessary in
order for methodology to be reproducible. We illustrate
our results with comparison of the performance of differ-
ent techniques in a simulation study involving estimation
of strength of association.
Different methods of bootstrapping to obtain
conﬁdence intervals
Philosophically, given its deﬁnition above, the conﬁdence
interval should best be constructed by taking many sam-
ples of the underlying population. However, often only a
single sample is available to us. The essence of nonpara-
metric bootstrapping is that in the absence of any other
information about a population, the distribution of values
found in a random sample from the population is the best
guide to the distribution of values in the population.
Therefore to approximate repeated sampling from the
population, it is justiﬁable to resample the sample (with
replacement). There are a number of different ways that
bootstrapping can be used to obtain the conﬁdence inter-
val for a population parameter, and some of the most
popular of these will be described below in the context of
two commonly used R packages devoted to bootstrapping:
bootstrap and boot.
The
R package bootstrap offers four different meth-
ods taken from Efron & Tibshirani (1993): the BCa
method, parametric and nonparametric versions of the
ABC method, and the studentized method. The boot.ci
function of the R package boot offers ﬁve methods: as
well as the studentized and BCa methods described
above, it offers the ﬁrst-order normal approximation,
basic and percentile methods. The implementation of
all of these methods is explained fully in Chapter 5 of
Davison & Hinkley (1997). From our survey of the lit-
erature, another method that seems to commonly be
used, but which is not available in either of our focal
R packages, is bias-corrected (BC) percentile conﬁdence
limits. Our literature survey suggested that users used
the statistical package
STATA to access this method.
For each of these methods, we describe the underlying
rationale behind them, in order of increasing complex-
ity. In each case, we will assume that we want to esti-
mate some population parameter h, and the estimator
of this parameter based on the original sample is ^h.
Under
standard
bootstrapping,
B
bootstrap
samples
are
generated
and
an
estimate
of
the
population
parameter is calculated for each; these estimates are
denoted ^h*
1; . . .;^h*
B.
percentile method
If the bootstrap estimates ^h*
1; . . .;^h*
B are ordered, then the
two values that contain the central 100 (1  a)% of these
estimates are used as the limits of the 100 (1  a)% conﬁ-
dence interval for the population parameter of interest
(commonly a = 005 is used). This method depends upon
the fact that the empirical distribution function based on
the bootstraps converges to the true distribution function
asymptotically in sample size, and the empirical quantiles
have a law of large numbers.
basic method
For each^h*
i , an error ei is calculated as^h*
i ^h. It is these ei
that are then ordered, and we identify the lower and
upper limits el and eu that enclose the central 100
(1  a)% of these errors. The 100 (1  a)% conﬁdence
interval
for
the
population
parameter
is
then
[^h  el;^h  eu]. This method is based on the assumption
that the bootstrap distribution of errors is a good approx-
imation for the real distribution of sampling errors.
first-order normal approximation
For this method, if ^rB is the standard deviation of the B
bootstrap samples and h is the mean, then the 100
(1  a)% conﬁdence interval is given by
h  za=2 ^rB;
where za/2 is the z-score for a given level of signiﬁcance a,
if a = 005 then za/2 = 196.
This method takes advantage of the observation that
bootstraps often approximate a normal distribution.
studentized method
Here we work with the t-distribution as a so-called pivot
function, rather than the raw bootstraps directly. Speciﬁ-
cally we ﬁrst estimate the standard deviation (^r*
i ) for each
bootstrap i. This can be calculated in the conventional way
if the parameter of interest is a mean; otherwise, alternative
equations or procedures are required (see Efron & Tibsh-
irani 1993 for details). For example, where the parameter
of interest is a correlation coefﬁcient, we can use:
^r*
i ¼ 1 ^h
*
i
2
ﬃﬃn
p ;
and we then calculate a t value for that bootstrap:
t*
i ¼^h
*
i ^h
^r*
i :
We then order these t*
i and ﬁnd the lower and upper
values (t*
l and t*
u) that enclose the central 100 (1  a)%
© 2015 The Authors. Journal of Animal Ecology © 2015 British Ecological Society, Journal of Animal Ecology, 84, 892–897
Conﬁdence intervals by bootstrapping
893
 13652656, 2015, 4, Downloaded from https://besjournals.onlinelibrary.wiley.com/doi/10.1111/1365-2656.12382, Wiley Online Library on [31/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License
of these t values. The limits of the 100 (1  a)% conﬁ-
dence interval for the population parameter of interest
are then [^h  t*
u^r;^h  t*
l ^r], where ^r is the standard devia-
tion of the original sample, calculated in the same way
as
for
the
bootstraps.
The
key
attraction
of
this
approach is that the statistic that is bootstrapped is piv-
otal (i.e. it does not depend on any nuisance parameters).
This means that it is possible to make exact probability
statements about this statistic, which by a ‘pivoting’ pro-
cedure can be converted to an exact conﬁdence interval
for the statistic of interest. Thus, this method should the-
oretically produce more precise conﬁdence intervals than
any of the forgoing.
bias-corrected (bc) percentile confidence
limits
The percentile method could be improved if any bias that
arises because the true parameter value is not the median
of the distribution of bootstrap estimates could be esti-
mated and corrected for. Essentially, this revised method
is based on the assumption that there is a monotonic
increasing transformation f() of the estimator ^h such that
the transformed values f(^h) are normally distributed with
mean f(h)  zo and standard deviation one. The central
challenge of implementing this method is to provide an
estimator for zo.
accelerated bias-corrected percentile limits
(bca)
This method is based on the assumption that a transfor-
mation f() of the estimator ^h exists such that f(^h) has a
normal distribution with mean f(h)  zo (1 + af (h)) and
standard deviation 1 + af (h), where zo and a are con-
stants that we must estimate to use this function. This
method seeks to correct for skewness as well as bias in
the bootstrap distribution.
abc methods
These were developed as approximations to the BCa
method that require much less computational effort.
Increasing availability of computing power reduces con-
cerns about computational effort, and so we do not
explore these methods in detail. Further details of these
methods can be found in Efron & Tibshirani (1993) or
Manly (2007).
This is by no means an exhaustive list of possible
methods for calculating conﬁdence intervals by boot-
strapping. For instance, Chernick & LaBudde (2011)
describe further methods called iterated bootstrap and
tilted bootstrap. Manly (2007) provides references to the
literature on a number of other methods. However, as
a generality, the methods described above are certainly
the easiest to implement, and also those most widely
used.
Survey of usage of this technique in the
literature
In order to survey the use of bootstrap methods to calcu-
late conﬁdence intervals, we examined 132 recent papers
(spanning the publication dates October 2010–September
2014) from the journals Journal of Animal Ecology, Ecol-
ogy and Behavioural Ecology (chosen because they allow
searching of the full text of papers for key terms) that use
bootstrapping to generate conﬁdence intervals. We found
papers by using the search term ‘bootstrap* AND conﬁ-
dence interval*’. Twenty-seven papers (20% of our sur-
vey) used the percentile method; 21 (16%) used BC, and 7
(5%) used BCa. None of these papers offered an explana-
tion for why the authors chose to use a particular
method. In the remaining 77 (58%) of papers, the method
used was not stated and could not be inferred from infor-
mation provided in the manuscript. Of these 132 papers,
51 used bootstrapping to generate a conﬁdence interval
for a measure of or difference in central tendency (e.g.
mean or median), 19 for a measure of dispersion (e.g. var-
iance of interquartile range), 27 for a measure of associa-
tion (e.g. correlation coefﬁcient, gradient of a line), and
35 for more complex composite parameters (e.g. species
diversity index).
An example to compare the different
techniques
As an example comparison of the different methods, we
evaluate the different methods in terms of the actual fre-
quency of occasions in which calculated 95% conﬁdence
intervals include the true population value of correlation
coefﬁcient for 10 000 bivariate random samples on the
basis of 10 000 bootstraps in each case. For each random
sample, we generate two samples (denoted by U1 and U2)
from populations that are Normal with mean zero and
standard deviation one, with the population value of the
Pearson product–moment correlation coefﬁcient between
them speciﬁed by a parameter q. We chose a sample size
of 20 since Taborsky (2010) found that that the average
sample size per treatment in laboratory experiments in the
study of behaviour was approximately 18, and the mean
sample size per treatment in our sample of papers describe
above was 23. For comparison, we repeated our analyses
with sample sizes of 10 and 100. Pearson’s correlation
coefﬁcient was chosen for illustrative purposes only, and
we are not seeking to make any inferences about the
properties of that measure in particular. For bivariate
normal data, there is a commonly used (non-bootstrap-
ping) method for calculating conﬁdence intervals (Fisher’s
transformation, which is used by the most popular R func-
tion for measuring association cor.test), and we can use
this as a comparator for the different bootstrapping meth-
ods. In our sample of 132 papers, correlation coefﬁcients
were
the
subject
of
conﬁdence
interval
construction
by bootstrapping in 21 (16%) of them, so it is also an
© 2015 The Authors. Journal of Animal Ecology © 2015 British Ecological Society, Journal of Animal Ecology, 84, 892–897
894
M.-T. Puth, M. Neuh€auser & G. D. Ruxton
 13652656, 2015, 4, Downloaded from https://besjournals.onlinelibrary.wiley.com/doi/10.1111/1365-2656.12382, Wiley Online Library on [31/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License
example that seems relevant to current research practice
in our ﬁeld.
We generate samples of bivariate data (U1, U2) with
speciﬁed (population level) correlation q using the method
of Berry & Mielke (2000): speciﬁcally
U1 ¼ X
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
ð1  q2Þ
q
þ Yq
and
U2 ¼ Y
where X and Y are independent identically distributed
univariate random variables drawn from N(0,1), and q is
the speciﬁed (population) correlation coefﬁcient. We per-
formed this for q = 00, 02 and 07 (Code valuable
through Dryad – see Puth 2015). Figure 1 provides exam-
ple conﬁdence intervals for the correlation coefﬁcient cal-
culated for the same sample of twenty pairs of values by
the six different methods and the fractions of conﬁdence
intervals from 10 000 replicate samples that included the
speciﬁed population value q. We obtained conﬁdence
intervals by the following six methods: BCa, BC, basic
method, percentile method, normal approximation and
studentized method.
We ﬁrst focus on the middle row of Fig. 1 for sample
sizes of 20. This shows that for our example case with a
small sample size, all of the bootstrap techniques excepted
studentized are liberal (producing conﬁdence intervals that
are on average too narrow to maintain the speciﬁed 95%
nominal level of coverage); however, this effect is rela-
tively minor for the BCa and BC methods. Our example
also illustrates that for a single sample, the six methods
can produce conﬁdence intervals that are quite different
from each other: both in size and level of asymmetry
about the point estimate from that sample. All these
effects can also be seen on the top row for sample sizes of
ten. It is not surprising that the smaller samples size leads
to generally larger conﬁdence intervals, but notice that
the conﬁdence interval for the studentized method is now
very strongly conservative (the conﬁdence interval is much
too large). Indeed, this conﬁdence interval (and those for
the normal and basic methods) can extend beyond the
range of values that are possible for Pearson’s correlation
coefﬁcient [1, 1]. Finally turning to the bottom row
(n = 100), the same effects can still be seen; all methods
tend to be liberal, although this effect is now relatively
minor, as are differences between methods.
Discussion
Our example shows that for the same sample, the six dif-
ferent methods for calculating conﬁdence intervals can
produce very substantially different conﬁdence intervals.
Hence, we would strongly recommend that when research-
ers present such conﬁdence intervals obtained by boot-
strapping, they explicitly state the method used. Our
survey of the literature suggests that this is not common
practice currently. Researchers should also state the num-
ber of bootstrap samples used in their calculations. We
generally use 10 000. Our previous research on randomi-
zation techniques more generally suggests that authors
Fig. 1. Bootstrap estimates of the conﬁdence intervals for the Pearson correlation coefﬁcient between two samples of size n = 10, 20 and
100, drawn from a population with ﬁxed correlation coefﬁcient q. For each of three values of q (00, 02 or 07), we ﬁrst drew a single
sample of twenty pairs of values then calculated and plotted the estimated correlation coefﬁcient and the 95% conﬁdence interval based
on that single sample, using six different bootstrap methods. We then drew 10 000 replicate samples and calculated 95% conﬁdence
intervals for each by all six methods (BC: bias corrected; BCa: bias corrected and accelerated, Perc: percentile method, Stud: studentized
method, Norm: normal method and Basic: basic method). For each method and value of q, we quote the fraction of these conﬁdence
intervals that enclosed the true population value (q) to the left of the associated single-sample example conﬁdence interval. We also
include for comparison conﬁdence intervals calculated by the non-bootstrapping method of Fisher’s transformation, which is the method
used by the most popular R function for measuring association (cor.test). The code used is provided as an electronic supplement.
© 2015 The Authors. Journal of Animal Ecology © 2015 British Ecological Society, Journal of Animal Ecology, 84, 892–897
Conﬁdence intervals by bootstrapping
895
 13652656, 2015, 4, Downloaded from https://besjournals.onlinelibrary.wiley.com/doi/10.1111/1365-2656.12382, Wiley Online Library on [31/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License
often do not specify the number of bootstrap samples
used, and amongst those that do, practice can be quite
varied. Speciﬁcally in a sample of 20 recent papers using
randomization techniques, we found seven used 10 000,
six used 1000, one each used 500, 250 and 100, and for
four papers insufﬁcient information was given to deter-
mine the number used (Ruxton & Neuh€auser 2013). Fur-
ther discussion of selection of an appropriate number of
bootstraps for calculating conﬁdence intervals can be
found on pp. 101–103 of Manly (2007) and pp. 50–53 of
Efron & Tibshirani (1993).
In our example, almost all the conﬁdence intervals had
coverage that was lower than the speciﬁed nominal 95%;
this is a general trait of bootstrap conﬁdence intervals
from relatively small sample sizes (Chernick & LaBudde
2010), and researchers should also bear this in mind when
interpreting calculated conﬁdence intervals. Carpenter &
Bithell (2000) emphasize that this problem may be more
acute for 99% conﬁdence intervals; hence, we would cau-
tion against using 99% conﬁdence intervals calculated by
bootstrapping unless the sample size is substantial (n = 50
as a minimum).
As regards which method to adopt, it is impossible to
identify a method that gives best performance in all situa-
tions, but we recommend BCa as the method that we
choose by default. BCa was speciﬁcally designed to give
reasonable performance across a broader range of situa-
tions than BC but to give similar performance where BC
does relatively well (Efron & Tibshirani 1993) and thus
can be favoured over BC for this reason. Efron (1987)
argues that BCa should be favoured over the studentized
methods because both have good accuracy (differences
from nominal coverage shrinking to zero quickly with
increasing sample size) but BCa tends to have shorter
interval lengths. In our example summarized in Fig. 1, the
studentized method can provide coverage that is higher
than the desired 095 and the conﬁdence intervals can be
very long. [DiCiccio & Efron (1996) warn that the ‘boot-
strap-t algorithm can be numerically unstable, resulting in
very long conﬁdence intervals’, see p. 199.] Karavarsamis
et al. (2013) compare the basic, normal, studentized and
percentile methods for the generation of conﬁdence inter-
vals for estimation of site occupancy and species detection
probabilities in species monitoring studies. They found
that the studentized method offered the most consistent
performance. Inspection of their data shows that this
method, as expected from our discussion above, consis-
tently and often substantially produced coverage higher
than the desired 095. Carpenter & Bithell (2000) provide
more extensive guidance on how to select the most appro-
priate method, but they highlight BCa as the most consis-
tently
effective
technique.
BCa
is
also
the
method
recommended by Crawley (2007).
Regarding software implementation, we would caution
against
selecting
the
‘all’
option
in
the
R
function
boot.ci
which
calculates
and
presents
the
conﬁdence
interval by all ﬁve methods available in that package.
Such
an
approach
risks
(even
unconsciously)
selecting the conﬁdence interval that ﬁts the researcher’s
expectation.
It should be remembered that for small sample sizes,
sometimes none of the methods work well. For example,
Manly (2007) demonstrated this for estimation of the var-
iance for samples of size 20 drawn from an exponential
distribution, and this is true generally for estimation of
higher moments from small samples drawn from very
skewed distributions. It is difﬁcult to offer clear guidance
on precisely when conﬁdence intervals based on bootstrap
resamples become unreliable in this way, but in truth this
is not an especial weakness of bootstrapping. For such
heavily skewed distributions, small samples can often be
quite unrepresentative of the underlying population and
any methodology will then struggle to accurately charac-
terize the population based on a single small sample. Sta-
tistics textbooks often suggest that n > 30 is sufﬁcient for
the mean to have a reasonably normal sampling distribu-
tion. Other statistics, such as the correlation coefﬁcient
used in our example, may require larger sample sizes, but
few, if any, require smaller. Chernick & LaBudde (2011)
warn about the potential for unreliability of bootstrap-
ping methods when sample sizes are less than n = 20. Fig-
ure 1
also
presents
an
alternative
non-bootstrapping
method especially designed for calculating the conﬁdence
interval for the product–moment correlation coefﬁcient.
For our example, this Fisher method (Fisher 1921; also
the method implemented by the most commonly used R
function for calculating correlation coefﬁcients cor.test)
provides coverage that is closer to the nominal level that
any of the bootstrapping methods considered. This occurs
because our simulated data are drawn from a bivariate
normal distribution; for other distributions, bootstrapping
might well be superior to the Fisher method. It should
also be remembered that even for large sample sizes, there
are some statistics for which bootstrapping does not pro-
vide a reliable way of estimating a conﬁdence interval.
Andrews
(2000)
provides
a
list
of
examples.
These
generally have in common estimation of a value that is
on or near the boundary of allowed values, for example a
situation where the true value of the statistic concerned is
zero or very close to zero, but negative values are
impossible. If estimating conﬁdence intervals in such a
situation, or if estimated bootstrap intervals appear odd,
then
Andrews
(2000)
offers
advice
on
alternative
techniques.
Acknowledgement
We thank Matthew Spencer and another anonymous reviewer for very
helpful comments.
Data accessibility
The
R code used to generate our results is available from the Dryad
Digital Repository http://dx.doi.org/10.5061/dryad.r390f (Puth, Neuha¨ user
& Ruxton 2015).
© 2015 The Authors. Journal of Animal Ecology © 2015 British Ecological Society, Journal of Animal Ecology, 84, 892–897
896
M.-T. Puth, M. Neuh€auser & G. D. Ruxton
 13652656, 2015, 4, Downloaded from https://besjournals.onlinelibrary.wiley.com/doi/10.1111/1365-2656.12382, Wiley Online Library on [31/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License
References
Andrews, D.W.K. (2000) Inconsistency of the bootstrap when a parameter
is on the boundary of the parameter space. Econometrica, 68, 399–405.
Berry, K. & Mielke, P. (2000) A Monte Carlo investigation of the Fisher
Z transformation for normal and nonnormal distributions. Psychologi-
cal Reports, 87, 1101–1114.
Carpenter, J. & Bithell, J. (2000) Bootstrap conﬁdence intervals: when,
which, what? A practical guide for medical statisticians. Statistics in
Medicine, 19, 1141–1164.
Chernick, M.R. & LaBudde, L.A. (2010) Revisiting qualms about boot-
strap conﬁdence intervals. American Journal of Mathematical and Man-
agement Sciences, 29, 437–456.
Chernick, M.R. & LaBudde, L.A. (2011) Bootstrap Methods with Applica-
tions to R. Wiley, New York.
Crawley, M.J. (2007) The R Book. Wiley, New York.
Davison, A.C. & Hinkley, D.V. (1997) Bootstrap Methods and Their Appli-
cation. Cambridge University Press, Cambridge.
DiCiccio, T.J. & Efron, B. (1996) Bootstrap conﬁdence intervals (with dis-
cussion). Statistical Science, 11, 189–228.
Efron, B. (1987) Better bootstrapping conﬁdence intervals (with discus-
sion). Journal of the American Statistical Society, 82, 171–200.
Efron, B. & Tibshirani, R.J. (1993) An Introduction to the Bootstrap.
Chapman & Hall, New York.
Fisher, R.A. (1921) On the probable error of a coefﬁcient of correlation
deduced from a small sample. Metron, 1, 3–32.
Karavarsamis, N., Robinson, A.P., Hepworth, G., Hamilton, A.J. &
Heard, G.W. (2013) Comparison of four bootstrap-based interval esti-
mators of species occupancy and detection probabilities. Australian &
New Zealand Journal of Statistics, 55, 235–252.
Manly, B.F.J. (2007) Randomisation, Bootstrap and Monte Carlo Methods
in Biology, 3rd edn. Chapman & Hall, New York.
Puth, M.-T., Neuha¨ user, M. & Ruxton, G.D. (2015) Data from: On the
variety of methods for calculating conﬁdence intervals by bootstrapping.
Dryad Digital Repository, doi:10.5061/dryad.r390f.
Ruxton, G.D. & Neuha¨ user, M. (2013) Improving the reporting of P-values
by randomisation methods. Methods in Ecology & Evolution, 4, 1033–1036.
Taborsky, M. (2010) Sample size in the study of behaviour. Ethology, 116,
185–202.
Received 10 October 2014; accepted 3 April 2015
Handling Editor: Dylan Childs
Supporting Information
Additional Supporting Information may be found in the online version
of this article.
Appendix S1. Comparison of different bootstrap methods.
© 2015 The Authors. Journal of Animal Ecology © 2015 British Ecological Society, Journal of Animal Ecology, 84, 892–897
Conﬁdence intervals by bootstrapping
897
 13652656, 2015, 4, Downloaded from https://besjournals.onlinelibrary.wiley.com/doi/10.1111/1365-2656.12382, Wiley Online Library on [31/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License
